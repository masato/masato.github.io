<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>masato&#39;s web site</title>
    <link>https://masato.github.io/</link>
    
    <image>
      <url>https://www.gravatar.com/avatar/0e86f5d7d8a396ffeff40fffe6c6d780</url>
      <title>masato&#39;s web site</title>
      <link>https://masato.github.io/</link>
    </image>
    
    <atom:link href="/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description></description>
    <pubDate>Sun, 27 Aug 2017 05:13:01 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>Apache FlinkとJava 8でセンサーデータをウィンドウ集計をする</title>
      <link>https://masato.github.io/2017/08/27/sensortag-apache-flink-java8/</link>
      <guid>https://masato.github.io/2017/08/27/sensortag-apache-flink-java8/</guid>
      <pubDate>Sun, 27 Aug 2017 05:13:01 GMT</pubDate>
      <description>
      
        SensorTagのセンサーデータをApache FlinkとScala APIを使いウィンドウ集計を試しました。Scala APIとなるべく同じようにJava 8 APIで書き直します。
      
      </description>
      
      
      <content:encoded><![CDATA[<p>　SensorTagのセンサーデータをApache FlinkとScala APIを使いウィンドウ集計を<a href="https://masato.github.io/2017/08/10/sensortag-apache-flink-scala/">試しました</a>。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/dev/scala_api_extensions.html">Scala API</a>となるべく同じように<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/dev/java8.html">Java 8 API</a>で書き直します。</p><span id="more"></span><h2 id="Mavenアーキタイプ"><a href="#Mavenアーキタイプ" class="headerlink" title="Mavenアーキタイプ"></a>Mavenアーキタイプ</h2><p>　<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/quickstart/java_api_quickstart.html">Sample Project using the Java API</a>にある<a href="https://mvnrepository.com/artifact/org.apache.flink/flink-quickstart-java">flink-quickstart-java</a>を使いMavenプロジェクトを作成します。Apache FlinkのバージョンはScalaの時と同じ<code>1.3.2</code>です。<code>groupId</code>や<code>package</code>は環境にあわせて変更してください。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ mkdir -p ~/java_apps &amp;&amp; <span class="built_in">cd</span> ~/java_apps</span><br><span class="line">$ mvn archetype:generate \</span><br><span class="line">    -DarchetypeGroupId=org.apache.flink \</span><br><span class="line">    -DarchetypeArtifactId=flink-quickstart-java \</span><br><span class="line">    -DarchetypeVersion=1.3.2 \</span><br><span class="line">    -DgroupId=streams-flink-java-examples \</span><br><span class="line">    -DartifactId=streams-flink-java-examples \</span><br><span class="line">    -Dversion=0.1 \</span><br><span class="line">    -Dpackage=com.github.masato.streams.flink \</span><br><span class="line">    -DinteractiveMode=<span class="literal">false</span></span><br></pre></td></tr></table></figure><p>　プラグインの<a href="https://maven.apache.org/plugins/maven-compiler-plugin/">maven-compiler-plugin</a>の設定をJava 8 (1.8)に変更します。また<a href="http://www.mojohaus.org/exec-maven-plugin/">exec-maven-plugin</a>を追加してMavenからFlinkアプリの<code>main()</code>を実行できるようにします。</p><figure class="highlight xml"><figcaption><span>pom.xml</span></figcaption><table><tr><td class="code"><pre><span class="line">    <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">...</span><br><span class="line">              <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                  <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">                  <span class="tag">&lt;<span class="name">target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line"></span><br><span class="line">              <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.codehaus.mojo<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>exec-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.5.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                  <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">id</span>&gt;</span>App<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                      <span class="tag">&lt;<span class="name">goal</span>&gt;</span>exec<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                  <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                  <span class="tag">&lt;<span class="name">executable</span>&gt;</span>java<span class="tag">&lt;/<span class="name">executable</span>&gt;</span></span><br><span class="line">                  <span class="tag">&lt;<span class="name">classpathScope</span>&gt;</span>compile<span class="tag">&lt;/<span class="name">classpathScope</span>&gt;</span></span><br><span class="line">                  <span class="tag">&lt;<span class="name">arguments</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">argument</span>&gt;</span>-cp<span class="tag">&lt;/<span class="name">argument</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">classpath</span>/&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">argument</span>&gt;</span>com.github.masato.streams.flink.WordCount<span class="tag">&lt;/<span class="name">argument</span>&gt;</span></span><br><span class="line">                  <span class="tag">&lt;/<span class="name">arguments</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure><p>　<a href="http://www.mojohaus.org/exec-maven-plugin/examples/example-exec-for-java-programs.html">execゴール</a>を実行します。<a href="https://github.com/apache/flink/blob/master/flink-quickstart/flink-quickstart-java/src/main/resources/archetype-resources/src/main/java/WordCount.java">WordCount</a>の例はテキストの単語を数えて標準出力します。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ mvn clean package <span class="built_in">exec</span>:<span class="built_in">exec</span>@App</span><br><span class="line">...</span><br><span class="line">(is,1)</span><br><span class="line">(a,1)</span><br><span class="line">(<span class="keyword">in</span>,1)</span><br><span class="line">(mind,1)</span><br><span class="line">(or,2)</span><br><span class="line">(against,1)</span><br><span class="line">(arms,1)</span><br><span class="line">(not,1)</span><br><span class="line">(sea,1)</span><br><span class="line">(the,3)</span><br><span class="line">(troubles,1)</span><br><span class="line">(fortune,1)</span><br><span class="line">(take,1)</span><br><span class="line">(to,4)</span><br><span class="line">(and,1)</span><br><span class="line">(arrows,1)</span><br><span class="line">(be,2)</span><br><span class="line">(nobler,1)</span><br><span class="line">(of,2)</span><br><span class="line">(slings,1)</span><br><span class="line">(suffer,1)</span><br><span class="line">(outrageous,1)</span><br><span class="line">(tis,1)</span><br><span class="line">(whether,1)</span><br><span class="line">(question,1)</span><br><span class="line">(that,1)</span><br></pre></td></tr></table></figure><h2 id="ウィンドウ集計"><a href="#ウィンドウ集計" class="headerlink" title="ウィンドウ集計"></a>ウィンドウ集計</h2><p>　<a href="https://mvnrepository.com/artifact/org.apache.flink/flink-quickstart-java">flink-quickstart-java</a>のアーキタイプが作成するJavaコードをすべて削除してから新しいコードを書いていきます。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ rm src/main/java/com/github/masato/streams/flink/*.java</span><br></pre></td></tr></table></figure><p>　<br>　ソースコードは<a href="https://github.com/masato/streams-flink-java-examples">リポジトリ</a>にもあります。Scalaで書いた<a href="https://github.com/masato/streams-flink-scala-examples/">例</a>は一つのファイルでしたがJavaの場合はわかりやすいようにクラスを分けました。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ tree streams-flink-java-examples</span><br><span class="line">streams-flink-java-examples</span><br><span class="line">├── pom.xml</span><br><span class="line">└── src</span><br><span class="line">    └── main</span><br><span class="line">        ├── java</span><br><span class="line">        │   └── com</span><br><span class="line">        │       └── github</span><br><span class="line">        │           └── masato</span><br><span class="line">        │               └── streams</span><br><span class="line">        │                   └── flink</span><br><span class="line">        │                       ├── Accumulator.java</span><br><span class="line">        │                       ├── Aggregate.java</span><br><span class="line">        │                       ├── App.java</span><br><span class="line">        │                       ├── Average.java</span><br><span class="line">        │                       └── Sensor.java</span><br><span class="line">        └── resources</span><br><span class="line">            └── log4j.properties</span><br></pre></td></tr></table></figure><h3 id="App-java"><a href="#App-java" class="headerlink" title="App.java"></a>App.java</h3><p> メインメソッドを実装したプログラムの全文です。Scalaで書いた例の<a href="https://github.com/masato/streams-flink-scala-examples/blob/master/src/main/scala/com/github/masato/streams/flink/App.scala">App.scala</a>と似ていますが<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/api/common/functions/AggregateFunction.html">AggregateFunction</a>と<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/streaming/api/functions/windowing/WindowFunction.html">WindowFunction</a>はそれぞれクラスにしました。</p><figure class="highlight java"><figcaption><span>App.java</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.github.masato.streams.flink;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Date;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"><span class="keyword">import</span> java.time.ZoneId;</span><br><span class="line"><span class="keyword">import</span> java.time.ZonedDateTime;</span><br><span class="line"><span class="keyword">import</span> java.time.format.DateTimeFormatter;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.TimeCharacteristic;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.source.SourceFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.timestamps.BoundedOutOfOrdernessTimestampExtractor;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.Time;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.windows.TimeWindow;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer010;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer010;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.util.serialization.JSONDeserializationSchema;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.util.serialization.SimpleStringSchema;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.fasterxml.jackson.databind.ObjectMapper;</span><br><span class="line"><span class="keyword">import</span> com.fasterxml.jackson.databind.node.ObjectNode;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">App</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> DateTimeFormatter fmt = DateTimeFormatter.ISO_OFFSET_DATE_TIME;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String bootstrapServers = System.getenv(<span class="string">&quot;BOOTSTRAP_SERVERS_CONFIG&quot;</span>);</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String groupId = System.getenv(<span class="string">&quot;GROUP_ID&quot;</span>);</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String sourceTopic = System.getenv(<span class="string">&quot;SOURCE_TOPIC&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String sinkTopic = System.getenv(<span class="string">&quot;SINK_TOPIC&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.setProperty(<span class="string">&quot;bootstrap.servers&quot;</span>, bootstrapServers);</span><br><span class="line">        props.setProperty(<span class="string">&quot;group.id&quot;</span>, groupId);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> StreamExecutionEnvironment env =</span><br><span class="line">            StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> DataStream&lt;ObjectNode&gt; events =</span><br><span class="line">                                env.addSource(<span class="keyword">new</span> FlinkKafkaConsumer010&lt;&gt;(</span><br><span class="line">                                  sourceTopic,</span><br><span class="line">                                  <span class="keyword">new</span> JSONDeserializationSchema(),</span><br><span class="line">                                  props)).name(<span class="string">&quot;events&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> SingleOutputStreamOperator&lt;ObjectNode&gt; timestamped =</span><br><span class="line">            events</span><br><span class="line">            .assignTimestampsAndWatermarks(</span><br><span class="line">                <span class="keyword">new</span> BoundedOutOfOrdernessTimestampExtractor&lt;ObjectNode&gt;(Time.seconds(<span class="number">10</span>)) &#123;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">extractTimestamp</span><span class="params">(ObjectNode element)</span> </span>&#123;</span><br><span class="line">                        <span class="keyword">return</span> element.get(<span class="string">&quot;time&quot;</span>).asLong() * <span class="number">1000</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line"></span><br><span class="line">        timestamped</span><br><span class="line">            .map((v) -&gt; &#123;</span><br><span class="line">                    String key =  v.get(<span class="string">&quot;bid&quot;</span>).asText();</span><br><span class="line">                    <span class="keyword">double</span> ambient = v.get(<span class="string">&quot;ambient&quot;</span>).asDouble();</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">new</span> Sensor(key, ambient);</span><br><span class="line">            &#125;)</span><br><span class="line">            .keyBy(v -&gt; v.key)</span><br><span class="line">            .timeWindow(Time.seconds(<span class="number">60</span>))</span><br><span class="line">            .aggregate(<span class="keyword">new</span> Aggregate(), <span class="keyword">new</span> Average())</span><br><span class="line">            .map((v) -&gt; &#123;</span><br><span class="line">                    ZonedDateTime zdt =</span><br><span class="line">                        <span class="keyword">new</span> Date(v.time).toInstant().atZone(ZoneId.systemDefault());</span><br><span class="line">                    String time = fmt.format(zdt);</span><br><span class="line"></span><br><span class="line">                    Map&lt;String, Object&gt; payload = <span class="keyword">new</span> HashMap&lt;String, Object&gt;();</span><br><span class="line">                    payload.put(<span class="string">&quot;time&quot;</span>, time);</span><br><span class="line">                    payload.put(<span class="string">&quot;bid&quot;</span>, v.bid);</span><br><span class="line">                    payload.put(<span class="string">&quot;ambient&quot;</span>, v.sum);</span><br><span class="line"></span><br><span class="line">                    String retval = <span class="keyword">new</span> ObjectMapper().writeValueAsString(payload);</span><br><span class="line">                    System.out.println(retval);</span><br><span class="line">                    <span class="keyword">return</span> retval;</span><br><span class="line">                &#125;)</span><br><span class="line">            .addSink(<span class="keyword">new</span> FlinkKafkaProducer010&lt;String&gt;(</span><br><span class="line">                         bootstrapServers,</span><br><span class="line">                         sinkTopic,</span><br><span class="line">                         <span class="keyword">new</span> SimpleStringSchema())</span><br><span class="line">                     ).name(<span class="string">&quot;kafka&quot;</span>);</span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Sensor-java"><a href="#Sensor-java" class="headerlink" title="Sensor.java"></a>Sensor.java</h3><p>　ScalaではストリームのセンサーデータはBDアドレスをキーにScalaのTupleを作成しました。</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">timestamped</span><br><span class="line">  .map &#123; v =&gt;</span><br><span class="line">    <span class="keyword">val</span> key =  v.get(<span class="string">&quot;bid&quot;</span>).asText</span><br><span class="line">    <span class="keyword">val</span> ambient = v.get(<span class="string">&quot;ambient&quot;</span>).asDouble</span><br><span class="line">    (key, ambient)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>　Java 8の場合でもScalaのように<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/api/java/tuple/Tuple2.html">Tuple2</a>が使えます。しかし<a href="https://brewing.codes/2017/01/31/using-apache-flink-with-java-8/">Using Apache Flink with Java 8</a>の解説にあるようにEclipse JDTでコンパイルが必要です。または<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/streaming/api/datastream/SingleOutputStreamOperator.html#returns-org.apache.flink.api.common.typeinfo.TypeInformation-">returns()</a>に<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/api/java/typeutils/TupleTypeInfo.html">TupleTypeInfo</a>で要素のタイプヒントをJavaクラスで指定しないとエラーになります。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">.map((v) -&gt; &#123;</span><br><span class="line">    <span class="keyword">double</span> ambient = v.get(<span class="string">&quot;value&quot;</span>).get(<span class="string">&quot;ambient&quot;</span>).asDouble();</span><br><span class="line">    String key =  v.get(<span class="string">&quot;sensor&quot;</span>).get(<span class="string">&quot;bid&quot;</span>).asText();</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;&gt;(key, ambient);</span><br><span class="line">&#125;)</span><br><span class="line">.returns(<span class="keyword">new</span> TupleTypeInfo&lt;&gt;(TypeInformation.of(String.class),</span><br><span class="line">                             TypeInformation.of(Double.class)))</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>　ちょっと面倒なので普通のPOJOを利用したほうが簡単です。</p><figure class="highlight java"><figcaption><span>Sensor.java</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.github.masato.streams.flink;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Sensor</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> String key;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">double</span> ambient;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Sensor</span><span class="params">(String key, <span class="keyword">double</span> ambient)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.key = key;</span><br><span class="line">        <span class="keyword">this</span>.ambient = ambient;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Aggregate-java"><a href="#Aggregate-java" class="headerlink" title="Aggregate.java"></a>Aggregate.java</h3><p>　<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/api/common/functions/AggregateFunction.html">AggregateFunction</a>インタフェースを実装します。Scalaと違いAccumulatorはcaseクラスではありませんがそれ以外はほぼ同じです。</p><figure class="highlight java"><figcaption><span>Aggregate.java</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.github.masato.streams.flink;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple2;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.AggregateFunction;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Aggregate</span> <span class="keyword">implements</span> <span class="title">AggregateFunction</span>&lt;<span class="title">Sensor</span>, <span class="title">Accumulator</span>, <span class="title">Accumulator</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">3355966737412029618L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Accumulator <span class="title">createAccumulator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Accumulator(<span class="number">0L</span>, <span class="string">&quot;&quot;</span>, <span class="number">0.0</span>, <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Accumulator <span class="title">merge</span><span class="params">(Accumulator a, Accumulator b)</span> </span>&#123;</span><br><span class="line">        a.count += b.count;</span><br><span class="line">        a.sum += b.sum;</span><br><span class="line">        <span class="keyword">return</span> a;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(Sensor value, Accumulator acc)</span> </span>&#123;</span><br><span class="line">        acc.sum += value.ambient;</span><br><span class="line">        acc.count++;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Accumulator <span class="title">getResult</span><span class="params">(Accumulator acc)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> acc;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Average-java"><a href="#Average-java" class="headerlink" title="Average.java"></a>Average.java</h3><p>　<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/streaming/api/functions/windowing/WindowFunction.html">WindowFunction</a>の実装です。</p><figure class="highlight java"><figcaption><span>Average.java</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.github.masato.streams.flink;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.windows.TimeWindow;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.windowing.WindowFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Average</span> <span class="keyword">implements</span> <span class="title">WindowFunction</span>&lt;<span class="title">Accumulator</span>,</span></span><br><span class="line"><span class="class">                                               <span class="title">Accumulator</span>, <span class="title">String</span>, <span class="title">TimeWindow</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">5532466889638450746L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">apply</span><span class="params">(String key,</span></span></span><br><span class="line"><span class="function"><span class="params">                      TimeWindow window,</span></span></span><br><span class="line"><span class="function"><span class="params">                      Iterable&lt;Accumulator&gt; input,</span></span></span><br><span class="line"><span class="function"><span class="params">                      Collector&lt;Accumulator&gt; out)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        Accumulator in = input.iterator().next();</span><br><span class="line">        out.collect(<span class="keyword">new</span> Accumulator(window.getEnd(), key, in.sum/in.count, in.count));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>　Scalaの場合WindowFunctionの<code>apply()</code>実装は<code>aggregate</code>には直接書いてみました。</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">.aggregate(<span class="keyword">new</span> <span class="type">Aggregate</span>(),</span><br><span class="line">  ( key: <span class="type">String</span>,</span><br><span class="line">    window: <span class="type">TimeWindow</span>,</span><br><span class="line">    input: <span class="type">Iterable</span>[<span class="type">Accumulator</span>],</span><br><span class="line">    out: <span class="type">Collector</span>[<span class="type">Accumulator</span>] ) =&gt; &#123;</span><br><span class="line">      <span class="keyword">var</span> in = input.iterator.next()</span><br><span class="line">      out.collect(<span class="type">Accumulator</span>(window.getEnd, key, in.sum/in.count, in.count))</span><br><span class="line">    &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h3 id="pom-xml"><a href="#pom-xml" class="headerlink" title="pom.xml"></a>pom.xml</h3><p>　ストリームのSourceはKafkaを利用します。接続情報は<a href="http://www.mojohaus.org/exec-maven-plugin/">exec-maven-plugin</a>の環境変数に設定します。SensorTagとRaspberry Pi 3の準備、Kafkaクラスタの構築は<a href="https://masato.github.io/2017/07/28/sensortag-kafka-python-spark-streaming-2/">こちら</a>を参考にしてください。</p><figure class="highlight xml"><figcaption><span>pom.xml</span></figcaption><table><tr><td class="code"><pre><span class="line">    <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">...</span><br><span class="line">              <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                  <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">                  <span class="tag">&lt;<span class="name">target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line"></span><br><span class="line">              <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.codehaus.mojo<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>exec-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.5.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                  <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">id</span>&gt;</span>App<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                      <span class="tag">&lt;<span class="name">goal</span>&gt;</span>exec<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                  <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                  <span class="tag">&lt;<span class="name">executable</span>&gt;</span>java<span class="tag">&lt;/<span class="name">executable</span>&gt;</span></span><br><span class="line">                  <span class="tag">&lt;<span class="name">classpathScope</span>&gt;</span>compile<span class="tag">&lt;/<span class="name">classpathScope</span>&gt;</span></span><br><span class="line">                  <span class="tag">&lt;<span class="name">arguments</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">argument</span>&gt;</span>-cp<span class="tag">&lt;/<span class="name">argument</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">classpath</span>/&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">argument</span>&gt;</span>com.github.masato.streams.flink.App<span class="tag">&lt;/<span class="name">argument</span>&gt;</span></span><br><span class="line">                  <span class="tag">&lt;/<span class="name">arguments</span>&gt;</span></span><br><span class="line">                  <span class="tag">&lt;<span class="name">environmentVariables</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">APPLICATION_ID_CONFIG</span>&gt;</span>sensortag<span class="tag">&lt;/<span class="name">APPLICATION_ID_CONFIG</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">BOOTSTRAP_SERVERS_CONFIG</span>&gt;</span>confluent:9092<span class="tag">&lt;/<span class="name">BOOTSTRAP_SERVERS_CONFIG</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">SOURCE_TOPIC</span>&gt;</span>sensortag<span class="tag">&lt;/<span class="name">SOURCE_TOPIC</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">SINK_TOPIC</span>&gt;</span>sensortag-sink<span class="tag">&lt;/<span class="name">SINK_TOPIC</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">GROUP_ID</span>&gt;</span>flinkGroup<span class="tag">&lt;/<span class="name">GROUP_ID</span>&gt;</span></span><br><span class="line">                  <span class="tag">&lt;/<span class="name">environmentVariables</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="実行"><a href="#実行" class="headerlink" title="実行"></a>実行</h3><p>　Raspberry Pi 3からSensorTagのデータをKafkaに送信したあとにexec-maven-pluginのexecゴールを実行します。</p><figure class="highlight mel"><table><tr><td class="code"><pre><span class="line">$ mvn clean install <span class="keyword">exec</span>:<span class="keyword">exec</span>@App</span><br></pre></td></tr></table></figure><p>　周囲温度(ambient)を60秒のタンブリングウィンドウで集計した平均値が標準出力されました。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;<span class="string">&quot;ambient&quot;</span>:28.395833333333332,<span class="string">&quot;time&quot;</span>:<span class="string">&quot;2017-08-28T11:57:00+09:00&quot;</span>,<span class="string">&quot;bid&quot;</span>:<span class="string">&quot;B0:B4:48:BD:DA:03&quot;</span>&#125;</span><br><span class="line">&#123;<span class="string">&quot;ambient&quot;</span>:28.44375,<span class="string">&quot;time&quot;</span>:<span class="string">&quot;2017-08-28T11:58:00+09:00&quot;</span>,<span class="string">&quot;bid&quot;</span>:<span class="string">&quot;B0:B4:48:BD:DA:03&quot;</span>&#125;</span><br><span class="line">&#123;<span class="string">&quot;ambient&quot;</span>:28.46875,<span class="string">&quot;time&quot;</span>:<span class="string">&quot;2017-08-28T11:59:00+09:00&quot;</span>,<span class="string">&quot;bid&quot;</span>:<span class="string">&quot;B0:B4:48:BD:DA:03&quot;</span>&#125;</span><br><span class="line">&#123;<span class="string">&quot;ambient&quot;</span>:28.5,<span class="string">&quot;time&quot;</span>:<span class="string">&quot;2017-08-28T12:00:00+09:00&quot;</span>,<span class="string">&quot;bid&quot;</span>:<span class="string">&quot;B0:B4:48:BD:DA:03&quot;</span>&#125;</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      <comments>https://masato.github.io/2017/08/27/sensortag-apache-flink-java8/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Apache FlinkとScalaでセンサーデータをウィンドウ集計をする</title>
      <link>https://masato.github.io/2017/08/10/sensortag-apache-flink-scala/</link>
      <guid>https://masato.github.io/2017/08/10/sensortag-apache-flink-scala/</guid>
      <pubDate>Thu, 10 Aug 2017 05:38:25 GMT</pubDate>
      <description>
      
        Spark Streaming、Kafka Streamsに続いてストリーム処理フレームワークのApache Flinkを試します。Spark StreamingはPython、Kafka StreamsはJavaで書いたのでApache FlinkはScalaで書いてみようと思います。
      
      </description>
      
      
      <content:encoded><![CDATA[<p>　<a href="https://masato.github.io/2017/08/02/sensortag-kafka-python-spark-streaming-6/">Spark Streaming</a>、<a href="https://masato.github.io/2017/08/08/sensortag-kafka-streams/">Kafka Streams</a>に続いてストリーム処理フレームワークの<a href="https://flink.apache.org/">Apache Flink</a>を試します。Spark StreamingはPython、Kafka StreamsはJavaで書いたのでApache FlinkはScalaで書いてみようと思います。</p><span id="more"></span><p>　Apache FlinkもKafkaと同様にScalaで書かれています。Scalaに特徴的な後方互換性を重視せずアグレッシブな開発をしています。そのためネットで検索できる情報もどんどん古くなりAPIもDeprecatedやPublicEvolvingになりがちで初学者には少し入りづらい状況です。なかなか学習用の良い記事が見つかりませんでしたが、センサーデータのウィンドウ集計の書き方は<a href="http://blog.scottlogic.com/2017/02/07/the-rise-of-big-data-streaming.html">THE RISE OF BIG DATA STREAMING</a>を参考にさせていただきました。</p><h2 id="プロジェクトテンプレート"><a href="#プロジェクトテンプレート" class="headerlink" title="プロジェクトテンプレート"></a>プロジェクトテンプレート</h2><p>　Apache Flinkのプロジェクトは<a href="https://github.com/tillrohrmann/flink-project">A flink project template using Scala and SBT</a>をテンプレートにすると便利です。最初にテンプレートのWordCountを例に使い方を確認します。テンプレートをcloneします。</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">$ cd ~/scala_apps</span><br><span class="line">$ git clone https:<span class="regexp">//gi</span>thub.com<span class="regexp">/tillrohrmann/</span>flink-project.git</span><br></pre></td></tr></table></figure><p>　いくつか例がありますがここではWordCount.scalaを使います。</p><figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">$ tree flink-project</span><br><span class="line">flink-project/</span><br><span class="line">├── build.sbt</span><br><span class="line">├── idea.sbt</span><br><span class="line">├── project</span><br><span class="line">│   ├── assembly.sbt</span><br><span class="line">│   └── build.properties</span><br><span class="line">├── README</span><br><span class="line">└── <span class="attribute">src</span></span><br><span class="line">    └── main</span><br><span class="line">        ├── resources</span><br><span class="line">        │   └── log4j.properties</span><br><span class="line">        └── scala</span><br><span class="line">            └── org</span><br><span class="line">                └── example</span><br><span class="line">                    ├── Job.scala</span><br><span class="line">                    ├── SocketTextStreamWordCount.scala</span><br><span class="line">                    └── WordCount.scala</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>　<a href="http://ensime.org/">ENSIME</a>を使う場合は<a href="https://masato.github.io/2017/08/09/emacs-ensime-sdkman/">こちら</a>を参考にしてプロジェクトに<code>.ensime</code>ファイルを作成してEmacsから<code>M-x ensime</code>してください。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> ~/scala_apps/flink-project</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sbt</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> ensimeConfig</span></span><br></pre></td></tr></table></figure><p>　WordCount.scalaのコードです。例のテキストに含まれる英単語をカウントします。</p><figure class="highlight scala"><figcaption><span>WordCount.scala</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.example</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">WordCount</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">ExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> text = env.fromElements(<span class="string">&quot;To be, or not to be,--that is the question:--&quot;</span>,</span><br><span class="line">      <span class="string">&quot;Whether &#x27;tis nobler in the mind to suffer&quot;</span>, <span class="string">&quot;The slings and arrows of outrageous fortune&quot;</span>,</span><br><span class="line">      <span class="string">&quot;Or to take arms against a sea of troubles,&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> counts = text.flatMap &#123; _.toLowerCase.split(<span class="string">&quot;\\W+&quot;</span>) &#125;</span><br><span class="line">      .map &#123; (_, <span class="number">1</span>) &#125;</span><br><span class="line">      .groupBy(<span class="number">0</span>)</span><br><span class="line">      .sum(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    counts.print()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>　プロジェクトのディレクトリからsbtのrunコマンドを実行します。mainメソッドを実装したクラスがいくつかあるのでWordCountの<code>3</code>を入力します。</p><figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">$ cd ~/scala_apps/flink-project</span><br><span class="line">$ sbt</span><br><span class="line">&gt; run</span><br><span class="line">Multiple <span class="selector-tag">main</span> classes detected, select one to run:</span><br><span class="line"></span><br><span class="line"> <span class="selector-attr">[1]</span> org<span class="selector-class">.example</span>.Job</span><br><span class="line"> <span class="selector-attr">[2]</span> org<span class="selector-class">.example</span>.SocketTextStreamWordCount</span><br><span class="line"> <span class="selector-attr">[3]</span> org<span class="selector-class">.example</span>.WordCount</span><br><span class="line"></span><br><span class="line">Enter number:<span class="number">3</span></span><br></pre></td></tr></table></figure><p>　実行すると以下のようにテキストに含まれる英単語を数えて出力します。</p><figure class="highlight clojure"><table><tr><td class="code"><pre><span class="line">(<span class="name">a</span>,<span class="number">1</span>)</span><br><span class="line">(<span class="name">fortune</span>,<span class="number">1</span>)</span><br><span class="line">(<span class="name">in</span>,<span class="number">1</span>)</span><br><span class="line">(<span class="name">mind</span>,<span class="number">1</span>)</span><br><span class="line">(<span class="name"><span class="builtin-name">or</span></span>,<span class="number">2</span>)</span><br><span class="line">(<span class="name">question</span>,<span class="number">1</span>)</span><br><span class="line">(<span class="name">slings</span>,<span class="number">1</span>)</span><br><span class="line">(<span class="name">suffer</span>,<span class="number">1</span>)</span><br><span class="line">(<span class="name"><span class="builtin-name">take</span></span>,<span class="number">1</span>)</span><br><span class="line">(<span class="name">that</span>,<span class="number">1</span>)</span><br><span class="line">(<span class="name">to</span>,<span class="number">4</span>)</span><br></pre></td></tr></table></figure><p>　テキストデータは<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/api/scala/ExecutionEnvironment.html">ExecutionEnvironment</a>から<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/api/scala/ExecutionEnvironment.html#fromElements-scala.collection.Seq-scala.reflect.ClassTag-org.apache.flink.api.common.typeinfo.TypeInformation-">fromElements</a>して作成した<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/api/java/operators/DataSource.html">DataSource</a>です。</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> env = <span class="type">ExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> text = env.fromElements(<span class="string">&quot;To be, or not to be,--that is the question:--&quot;</span>,</span><br><span class="line">  <span class="string">&quot;Whether &#x27;tis nobler in the mind to suffer&quot;</span>, <span class="string">&quot;The slings and arrows of outrageous fortune&quot;</span>,</span><br><span class="line">  <span class="string">&quot;Or to take arms against a sea of troubles,&quot;</span>)</span><br></pre></td></tr></table></figure><p>　Apach FlinkのScalaではコードを短く書ける反面でアンダースコアや<code>map</code>や<code>groupBy</code>に登場する1や0が何を指しているのかわかりにくいことがあります。Apache FlinkのTupleはfieldで指定する場合は<code>zero indexed</code>なので順番に<code>0, 1</code>となります。</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> counts = text.flatMap &#123; _.toLowerCase.split(<span class="string">&quot;\\W+&quot;</span>) &#125;</span><br><span class="line">  .map &#123; (_, <span class="number">1</span>) &#125;</span><br><span class="line">  .groupBy(<span class="number">0</span>)</span><br><span class="line">  .sum(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>　テキストデータを<code>flatMap</code>で正規表現を使い単語に区切り<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/api/scala/DataSet.html">DataSet</a>を作成します。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/api/scala/DataSet.html#map-scala.Function1-org.apache.flink.api.common.typeinfo.TypeInformation-scala.reflect.ClassTag-">map()</a>で単語(<code>_</code>)と数(<code>1</code>)でTupleの<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/api/scala/DataSet.html">DataSet</a>を作成します。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/api/scala/DataSet.html#groupBy-scala.collection.Seq-">groupBy()</a>はfieldの<code>0</code>を指定して単語でグループ化した<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/api/scala/GroupedDataSet.html">GroupedDataSet</a>を作成します。最後に<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/api/scala/GroupedDataSet.html#sum-int-">sum()</a>の引数にfieldの<code>1</code>を指定して単語と単語の合計数をTupleにした<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/api/scala/AggregateDataSet.html">AggregateDataSet</a>を作成します。</p><h2 id="ウィンドウ集計"><a href="#ウィンドウ集計" class="headerlink" title="ウィンドウ集計"></a>ウィンドウ集計</h2><p>　このテンプレートプロジェクトを使いセンサーデータを60秒のタンブリングウィンドウで集計して周囲温度(ambient)の平均値を計算するプログラムを書きます。KafkaをSourceにするので<a href="https://masato.github.io/2017/07/28/sensortag-kafka-python-spark-streaming-2/">こちら</a>を参考にRaspberry Pi 3からSensorTagのデータをKafkaに送信します。</p><figure class="highlight livescript"><table><tr><td class="code"><pre><span class="line">Raspberry Pi <span class="number">3</span> -&gt; Source <span class="function"><span class="params">(Kafka)</span> -&gt;</span> ストリーム処理 -&gt; Sink (Kafka)</span><br></pre></td></tr></table></figure><p>　テンプレートプロジェクトをcloneした後に既存のファイルを削除します。</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">$ cd ~/scala_apps</span><br><span class="line">$ git clone https:<span class="regexp">//gi</span>thub.com<span class="regexp">/tillrohrmann/</span>flink-project.git streams-flink-scala-examples</span><br><span class="line">$ cd streams-flink-scala-examples</span><br><span class="line">$ rm -fr src<span class="regexp">/main/</span>scala<span class="regexp">/org/</span></span><br></pre></td></tr></table></figure><p>　Scalaのパッケージディレクトリを作成します。</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">$ mkdir -p src<span class="regexp">/main/</span>scala<span class="regexp">/com/gi</span>thub<span class="regexp">/masato/</span>streams/flink</span><br></pre></td></tr></table></figure><h3 id="build-sbt"><a href="#build-sbt" class="headerlink" title="build.sbt"></a>build.sbt</h3><p>　Kafkaは<a href="https://masato.github.io/2017/08/02/kafka-treasuredata-bridge-docker-compose/">こちら</a>と同様に<a href="https://hub.docker.com/r/landoop/fast-data-dev/">landoop/fast-data-dev</a>のDockerイメージを利用します。バージョンは<code>0.10.2.1</code>です。Kafka 0.10に対応したパッケージを追加します。</p><figure class="highlight scala"><figcaption><span>build.sbt</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> flinkVersion = <span class="string">&quot;1.3.2&quot;</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">val</span> flinkDependencies = <span class="type">Seq</span>(</span><br><span class="line">  <span class="string">&quot;org.apache.flink&quot;</span> %% <span class="string">&quot;flink-scala&quot;</span> % flinkVersion % <span class="string">&quot;provided&quot;</span>,</span><br><span class="line">  <span class="string">&quot;org.apache.flink&quot;</span> %% <span class="string">&quot;flink-streaming-scala&quot;</span> % flinkVersion % <span class="string">&quot;provided&quot;</span>,</span><br><span class="line">  <span class="string">&quot;org.apache.flink&quot;</span> %% <span class="string">&quot;flink-connector-kafka-0.10&quot;</span> % flinkVersion)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> otherDependencies = <span class="type">Seq</span>(</span><br><span class="line">   <span class="string">&quot;com.typesafe&quot;</span> % <span class="string">&quot;config&quot;</span> % <span class="string">&quot;1.3.1&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">lazy</span> <span class="keyword">val</span> root = (project in file(<span class="string">&quot;.&quot;</span>)).</span><br><span class="line">  settings(</span><br><span class="line">    libraryDependencies ++= flinkDependencies,</span><br><span class="line">    libraryDependencies ++= otherDependencies</span><br><span class="line">  )</span><br><span class="line">   </span><br><span class="line">mainClass in assembly := <span class="type">Some</span>(<span class="string">&quot;com.github.masato.streams.flink.App&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="App-scala"><a href="#App-scala" class="headerlink" title="App.scala"></a>App.scala</h3><p>　メインメソッドを実装したプログラムの全文です。Kafkaへの接続情報などは<a href="https://typesafehub.github.io/config/">config</a>を使い設定ファイルに定義します。ソースコードは<a href="https://github.com/masato/streams-flink-scala-examples">リポジトリ</a>にもあります。</p><figure class="highlight scala"><figcaption><span>App.scala</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.github.masato.streams.flink</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.<span class="type">Properties</span></span><br><span class="line"><span class="keyword">import</span> java.time.<span class="type">ZoneId</span>;</span><br><span class="line"><span class="keyword">import</span> java.time.format.<span class="type">DateTimeFormatter</span></span><br><span class="line"><span class="keyword">import</span> java.util.<span class="type">Date</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.<span class="type">TimeCharacteristic</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.<span class="type">IngestionTimeExtractor</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.timestamps.<span class="type">BoundedOutOfOrdernessTimestampExtractor</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.<span class="type">Time</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.windows.<span class="type">TimeWindow</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.kafka.&#123;<span class="type">FlinkKafkaConsumer010</span>,<span class="type">FlinkKafkaProducer010</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.util.serialization.&#123;<span class="type">JSONDeserializationSchema</span>,<span class="type">SimpleStringSchema</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.<span class="type">AggregateFunction</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.<span class="type">Collector</span></span><br><span class="line"><span class="keyword">import</span> com.fasterxml.jackson.databind.node.<span class="type">ObjectNode</span></span><br><span class="line"><span class="keyword">import</span> scala.util.parsing.json.<span class="type">JSONObject</span></span><br><span class="line"><span class="keyword">import</span> com.typesafe.config.<span class="type">ConfigFactory</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Accumulator</span>(<span class="params">time: <span class="type">Long</span>, bid: <span class="type">String</span>, var sum: <span class="type">Double</span>, var count: <span class="type">Int</span></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">class</span> <span class="title">Aggregate</span> <span class="keyword">extends</span> <span class="title">AggregateFunction</span>[(<span class="type">String</span>, <span class="type">Double</span>), <span class="type">Accumulator</span>,<span class="type">Accumulator</span>] </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">createAccumulator</span></span>(): <span class="type">Accumulator</span> = &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="type">Accumulator</span>(<span class="number">0</span>L, <span class="string">&quot;&quot;</span>, <span class="number">0.0</span>, <span class="number">0</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(a: <span class="type">Accumulator</span>, b: <span class="type">Accumulator</span>): <span class="type">Accumulator</span> = &#123;</span><br><span class="line">    a.sum += b.sum</span><br><span class="line">    a.count += b.count</span><br><span class="line">    <span class="keyword">return</span> a</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">add</span></span>(value: (<span class="type">String</span>, <span class="type">Double</span>), acc: <span class="type">Accumulator</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    acc.sum += value._2</span><br><span class="line">    acc.count += <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getResult</span></span>(acc: <span class="type">Accumulator</span>): <span class="type">Accumulator</span> = &#123;</span><br><span class="line">    <span class="keyword">return</span> acc</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">App</span> </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> fmt = <span class="type">DateTimeFormatter</span>.<span class="type">ISO_OFFSET_DATE_TIME</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> conf = <span class="type">ConfigFactory</span>.load()</span><br><span class="line">  <span class="keyword">val</span> bootstrapServers = conf.getString(<span class="string">&quot;app.bootstrap-servers&quot;</span>)</span><br><span class="line">  <span class="keyword">val</span> groupId = conf.getString(<span class="string">&quot;app.group-id&quot;</span>)</span><br><span class="line">  <span class="keyword">val</span> sourceTopic = conf.getString(<span class="string">&quot;app.source-topic&quot;</span>)</span><br><span class="line">  <span class="keyword">val</span> sinkTopic = conf.getString(<span class="string">&quot;app.sink-topic&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> props = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line">    props.setProperty(<span class="string">&quot;bootstrap.servers&quot;</span>, bootstrapServers)</span><br><span class="line">    props.setProperty(<span class="string">&quot;group.id&quot;</span>, groupId)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> source = <span class="keyword">new</span> <span class="type">FlinkKafkaConsumer010</span>[<span class="type">ObjectNode</span>](</span><br><span class="line">      sourceTopic, <span class="keyword">new</span> <span class="type">JSONDeserializationSchema</span>(), props)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> events = env.addSource(source).name(<span class="string">&quot;events&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> timestamped = events.assignTimestampsAndWatermarks(</span><br><span class="line">      <span class="keyword">new</span> <span class="type">BoundedOutOfOrdernessTimestampExtractor</span>[<span class="type">ObjectNode</span>](<span class="type">Time</span>.seconds(<span class="number">10</span>)) &#123;</span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">extractTimestamp</span></span>(element: <span class="type">ObjectNode</span>): <span class="type">Long</span> = element.get(<span class="string">&quot;time&quot;</span>).asLong * <span class="number">1000</span></span><br><span class="line">      &#125;)</span><br><span class="line"></span><br><span class="line">    timestamped</span><br><span class="line">      .map &#123; v =&gt;</span><br><span class="line">        <span class="keyword">val</span> key =  v.get(<span class="string">&quot;bid&quot;</span>).asText</span><br><span class="line">        <span class="keyword">val</span> ambient = v.get(<span class="string">&quot;ambient&quot;</span>).asDouble</span><br><span class="line">        (key, ambient)</span><br><span class="line">      &#125;</span><br><span class="line">      .keyBy(v =&gt; v._1)</span><br><span class="line">      .timeWindow(<span class="type">Time</span>.seconds(<span class="number">60</span>))</span><br><span class="line">      .aggregate(<span class="keyword">new</span> <span class="type">Aggregate</span>(),</span><br><span class="line">        ( key: <span class="type">String</span>,</span><br><span class="line">          window: <span class="type">TimeWindow</span>,</span><br><span class="line">          input: <span class="type">Iterable</span>[<span class="type">Accumulator</span>],</span><br><span class="line">          out: <span class="type">Collector</span>[<span class="type">Accumulator</span>] ) =&gt; &#123;</span><br><span class="line">            <span class="keyword">var</span> in = input.iterator.next()</span><br><span class="line">            out.collect(<span class="type">Accumulator</span>(window.getEnd, key, in.sum/in.count, in.count))</span><br><span class="line">          &#125;</span><br><span class="line">      )</span><br><span class="line">      .map &#123; v =&gt;</span><br><span class="line">        <span class="keyword">val</span> zdt = <span class="keyword">new</span> <span class="type">Date</span>(v.time).toInstant().atZone(<span class="type">ZoneId</span>.systemDefault())</span><br><span class="line">        <span class="keyword">val</span> time = fmt.format(zdt)</span><br><span class="line">        <span class="keyword">val</span> json = <span class="type">Map</span>(<span class="string">&quot;time&quot;</span> -&gt; time, <span class="string">&quot;bid&quot;</span> -&gt; v.bid, <span class="string">&quot;ambient&quot;</span> -&gt; v.sum)</span><br><span class="line">        <span class="keyword">val</span> retval = <span class="type">JSONObject</span>(json).toString()</span><br><span class="line">        println(retval)</span><br><span class="line">        retval</span><br><span class="line">      &#125;</span><br><span class="line">      .addSink(<span class="keyword">new</span> <span class="type">FlinkKafkaProducer010</span>[<span class="type">String</span>](</span><br><span class="line">        bootstrapServers,</span><br><span class="line">        sinkTopic,</span><br><span class="line">        <span class="keyword">new</span> <span class="type">SimpleStringSchema</span>)</span><br><span class="line">      ).name(<span class="string">&quot;kafka&quot;</span>)</span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>　main()の処理を順番にみていきます。最初にKafkaに接続する設定を行います。接続するKafkaが0.10のため<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumer010.html">FlinkKafkaConsumer010</a>を使います。Raspberry Pi 3から届くセンサーデータは以下のようなJSONフォーマットです。</p><figure class="highlight 1c"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;bid&#x27;: &#x27;B0:B4:48:BE:5E:00&#x27;, &#x27;time&#x27;: <span class="number">1503527847</span>, &#x27;humidity&#x27;: <span class="number">26.55792236328125</span>, &#x27;objecttemp&#x27;: <span class="number">22.3125</span>, &#x27;ambient&#x27;: <span class="number">26.375</span>, &#x27;rh&#x27;: <span class="number">76.983642578125</span>&#125;</span><br></pre></td></tr></table></figure><p>　<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/streaming/util/serialization/JSONDeserializationSchema.html">JSONDeserializationSchema</a>でデシリアライズします。</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> props = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line">props.setProperty(<span class="string">&quot;bootstrap.servers&quot;</span>, bootstrapServers)</span><br><span class="line">props.setProperty(<span class="string">&quot;group.id&quot;</span>, groupId)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> source = <span class="keyword">new</span> <span class="type">FlinkKafkaConsumer010</span>[<span class="type">ObjectNode</span>](</span><br><span class="line">  sourceTopic, <span class="keyword">new</span> <span class="type">JSONDeserializationSchema</span>(), props)</span><br></pre></td></tr></table></figure><p>　Apache Flinkの時間モデルはイベント時間 (TimeCharacteristic.EventTime)に設定しています。センサーデータの<code>time</code>フィールドをタイムスタンプとウォーターマークに使います。</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> events = env.addSource(source).name(<span class="string">&quot;events&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> timestamped = events.assignTimestampsAndWatermarks(</span><br><span class="line">  <span class="keyword">new</span> <span class="type">BoundedOutOfOrdernessTimestampExtractor</span>[<span class="type">ObjectNode</span>](<span class="type">Time</span>.seconds(<span class="number">10</span>)) &#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">extractTimestamp</span></span>(element: <span class="type">ObjectNode</span>): <span class="type">Long</span> = element.get(<span class="string">&quot;time&quot;</span>).asLong * <span class="number">1000</span></span><br><span class="line">  &#125;)</span><br></pre></td></tr></table></figure><p>　センサーからはいくつかのデータが取得できていますがここでは周囲温度(ambient)の値だけ利用します。<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/api/scala/DataSet.html#map-scala.Function1-org.apache.flink.api.common.typeinfo.TypeInformation-scala.reflect.ClassTag-">map()</a>でSensorTagのBDアドレスをキーにして新しいTupleを作成します。</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">timestamped</span><br><span class="line">  .map &#123; v =&gt;</span><br><span class="line">    <span class="keyword">val</span> key =  v.get(<span class="string">&quot;bid&quot;</span>).asText</span><br><span class="line">    <span class="keyword">val</span> ambient = v.get(<span class="string">&quot;ambient&quot;</span>).asDouble</span><br><span class="line">    (key, ambient)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>　<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/streaming/api/datastream/DataStream.html">DataStream</a>の<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/streaming/api/scala/DataStream.html#keyBy-scala.collection.Seq-">keyBy()</a>にTupleのインデックス<code>1</code>を指定してBDアドレスをキーにした<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/streaming/api/scala/KeyedStream.html">KeyedStream</a>を作成します。</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">.keyBy(v =&gt; v._1)</span><br></pre></td></tr></table></figure><p>　<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/streaming/api/datastream/KeyedStream.html#timeWindow-org.apache.flink.streaming.api.windowing.time.Time-">timeWindow()</a>で60秒に設定したタンブリングウィンドウの<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/streaming/api/datastream/WindowedStream.html">WindowedStream</a>を作成します。</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">.timeWindow(<span class="type">Time</span>.seconds(<span class="number">60</span>))</span><br></pre></td></tr></table></figure><p>　バージョン1.3では<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/streaming/api/datastream/WindowedStream.html#apply-R-org.apache.flink.api.common.functions.FoldFunction-org.apache.flink.streaming.api.functions.windowing.WindowFunction-">apply()</a>はDeprecatedになっています。以前は以下のように書けました。</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">.apply(</span><br><span class="line">  (<span class="number">0</span>L, <span class="string">&quot;&quot;</span>, <span class="number">0.0</span>, <span class="number">0</span>),</span><br><span class="line">  (acc: (<span class="type">Long</span>, <span class="type">String</span>, <span class="type">Double</span>, <span class="type">Int</span>),</span><br><span class="line">   v: (<span class="type">String</span>, <span class="type">Double</span>)) =&gt; &#123; (<span class="number">0</span>L, v._1, acc._3 + v._2, acc._4 + <span class="number">1</span>) &#125;,</span><br><span class="line">  ( window: <span class="type">TimeWindow</span>,</span><br><span class="line">    counts: <span class="type">Iterable</span>[(<span class="type">Long</span>, <span class="type">String</span>, <span class="type">Double</span>, <span class="type">Int</span>)],</span><br><span class="line">    out: <span class="type">Collector</span>[(<span class="type">Long</span>, <span class="type">String</span>, <span class="type">Double</span>, <span class="type">Int</span>)] ) =&gt; &#123;</span><br><span class="line">      <span class="keyword">var</span> count = counts.iterator.next()</span><br><span class="line">      out.collect((window.getEnd, count._2, count._3/count._4, count._4))</span><br><span class="line">    &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>　さらに<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/streaming/api/datastream/WindowedStream.html#fold-ACC-org.apache.flink.api.common.functions.FoldFunction-org.apache.flink.streaming.api.functions.windowing.WindowFunction-">fold()</a>もDeprecatedなので推奨されている<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/streaming/api/datastream/WindowedStream.html#aggregate-org.apache.flink.api.common.functions.AggregateFunction-org.apache.flink.streaming.api.functions.windowing.WindowFunction-">aggregate()</a>を使ってみます。<code>Aggregate</code>は<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/api/common/functions/AggregateFunction.html">AggregateFunction</a>を実装しています。<code>apply()</code>の例のようにTupleを使っても良いですがcaseクラスにすると少し読みやすくなります。</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">.aggregate(<span class="keyword">new</span> <span class="type">Aggregate</span>(),</span><br><span class="line">  ( key: <span class="type">String</span>,</span><br><span class="line">    window: <span class="type">TimeWindow</span>,</span><br><span class="line">    input: <span class="type">Iterable</span>[<span class="type">Accumulator</span>],</span><br><span class="line">    out: <span class="type">Collector</span>[<span class="type">Accumulator</span>] ) =&gt; &#123;</span><br><span class="line">      <span class="keyword">var</span> in = input.iterator.next()</span><br><span class="line">      out.collect(<span class="type">Accumulator</span>(window.getEnd, key, in.sum/in.count, in.count))</span><br><span class="line">    &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>　外部システムと連携しやすいようにデータストリームはUNIXタイムはタイムゾーンをつけたISO-8601にフォーマットしたJSON文字列に<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/api/java/org/apache/flink/streaming/api/datastream/DataStream.html#map-org.apache.flink.api.common.functions.MapFunction-">map()</a>します。ここではデバッグ用にJSON文字列は標準出力しています。</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">.map &#123; v =&gt;</span><br><span class="line">  <span class="keyword">val</span> zdt = <span class="keyword">new</span> <span class="type">Date</span>(v.time).toInstant().atZone(<span class="type">ZoneId</span>.systemDefault())</span><br><span class="line">  <span class="keyword">val</span> time = fmt.format(zdt)</span><br><span class="line">  <span class="keyword">val</span> json = <span class="type">Map</span>(<span class="string">&quot;time&quot;</span> -&gt; time, <span class="string">&quot;bid&quot;</span> -&gt; v.bid, <span class="string">&quot;ambient&quot;</span> -&gt; v.sum)</span><br><span class="line">  <span class="keyword">val</span> retval = <span class="type">JSONObject</span>(json).toString()</span><br><span class="line">  println(retval)</span><br><span class="line">  retval</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>　最後にデータストリームをKafkaにSinkします。<code>name(&quot;kafka&quot;)</code>のようにSinkに名前をつけると実行時のログに表示されます。</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">  .addSink(<span class="keyword">new</span> <span class="type">FlinkKafkaProducer010</span>[<span class="type">String</span>](</span><br><span class="line">    bootstrapServers,</span><br><span class="line">    sinkTopic,</span><br><span class="line">    <span class="keyword">new</span> <span class="type">SimpleStringSchema</span>)</span><br><span class="line">  ).name(<span class="string">&quot;kafka&quot;</span>)</span><br><span class="line">env.execute()</span><br></pre></td></tr></table></figure><h3 id="sbtのrun"><a href="#sbtのrun" class="headerlink" title="sbtのrun"></a>sbtのrun</h3><p>　プロジェクトに移動してsbtのrunコマンドを実行します。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> ~/scala_apps/streams-flink-scala-examples</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sbt</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> run</span></span><br></pre></td></tr></table></figure><p>　周囲温度(ambient)を60秒のタンブリングウィンドウで集計した平均値が標準出力されました。</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;<span class="attr">&quot;time&quot;</span> : <span class="string">&quot;2017-08-24T08:10:00+09:00&quot;</span>, <span class="attr">&quot;bid&quot;</span> : <span class="string">&quot;B0:B4:48:BE:5E:00&quot;</span>, <span class="attr">&quot;ambient&quot;</span> : <span class="number">26.203125</span>&#125;</span><br><span class="line">&#123;<span class="attr">&quot;time&quot;</span> : <span class="string">&quot;2017-08-24T08:11:00+09:00&quot;</span>, <span class="attr">&quot;bid&quot;</span> : <span class="string">&quot;B0:B4:48:BE:5E:00&quot;</span>, <span class="attr">&quot;ambient&quot;</span> : <span class="number">26.234375</span>&#125;</span><br><span class="line">&#123;<span class="attr">&quot;time&quot;</span> : <span class="string">&quot;2017-08-24T08:12:00+09:00&quot;</span>, <span class="attr">&quot;bid&quot;</span> : <span class="string">&quot;B0:B4:48:BE:5E:00&quot;</span>, <span class="attr">&quot;ambient&quot;</span> : <span class="number">26.26875</span>&#125;</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      <comments>https://masato.github.io/2017/08/10/sensortag-apache-flink-scala/#disqus_thread</comments>
    </item>
    
    <item>
      <title>SDKMAN!とENSIMEとEmacsでScalaの開発環境構築</title>
      <link>https://masato.github.io/2017/08/09/emacs-ensime-sdkman/</link>
      <guid>https://masato.github.io/2017/08/09/emacs-ensime-sdkman/</guid>
      <pubDate>Tue, 08 Aug 2017 23:45:32 GMT</pubDate>
      <description>
      
        EclimでJavaの開発環境構築をしました。同様にちょっとしたScalaのアプリを書きたい時にEclipseやIntelliJ IDEAを起動するのも重たいのでいつものEmacsでScalaの開発環境を構築します。
      
      </description>
      
      
      <content:encoded><![CDATA[<p>　<a href="https://github.com/emacs-eclim/emacs-eclim">Eclim</a>で<a href="https://masato.github.io/2017/08/04/emacs-eclim-java/">Javaの開発環境構築</a>をしました。同様にちょっとしたScalaのアプリを書きたい時にEclipseやIntelliJ IDEAを起動するのも重たいのでいつものEmacsでScalaの開発環境を構築します。</p><span id="more"></span><h2 id="開発用の仮想マシン"><a href="#開発用の仮想マシン" class="headerlink" title="開発用の仮想マシン"></a>開発用の仮想マシン</h2><p>　クラウド上にUbuntu 16.04.3の仮想マシンを用意してパッケージを更新しておきます。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get update &amp;&amp; sudo apt-get dist-upgrade -y</span><br></pre></td></tr></table></figure><h2 id="SDKMAN"><a href="#SDKMAN" class="headerlink" title="SDKMAN!"></a>SDKMAN!</h2><p>　<a href="http://sdkman.io/">SDKMAN!</a>は<a href="https://gradle.org/">Gradle</a>や<a href="http://www.scala-sbt.org/">sbt</a>などJVM言語のSDK管理ツールです。最近ではJavaのバージョン管理もできるようになりました。</p><p>　ワンライナーでSDKMAN!をインストールします。</p><figure class="highlight elixir"><table><tr><td class="code"><pre><span class="line"><span class="variable">$ </span>curl -s get.sdkman.io | <span class="regexp">/bin/bash</span></span><br><span class="line"><span class="variable">$ </span>sdk version</span><br><span class="line">SDKMAN <span class="number">5.5</span>.<span class="number">9</span>+<span class="number">231</span></span><br></pre></td></tr></table></figure><h3 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h3><p>　SDKMAN!を使ってインストールできるJavaのバージョンを一覧します。</p><figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line">$ sdk list java</span><br><span class="line">================================================================================</span><br><span class="line">Available Java Versions</span><br><span class="line">================================================================================</span><br><span class="line"><span class="code">     8u141-oracle</span></span><br><span class="line"><span class="code">     8u131-zulu</span></span><br><span class="line"><span class="code">     7u141-zulu</span></span><br><span class="line"><span class="code">     6u93-zulu</span></span><br></pre></td></tr></table></figure><p>　OpenJDKベースの<a href="http://www.azul.com/downloads/zulu/">Zulu</a>の8を使います。</p><figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">$ sdk <span class="keyword">install </span><span class="keyword">java </span><span class="number">8</span>u131-zulu</span><br></pre></td></tr></table></figure><p>　シェルを起動し直して<code>$JAVA_HOME</code>環境変数を確認します。</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">$ echo <span class="variable">$JAVA_HOME</span></span><br><span class="line"><span class="regexp">/home/</span>cloud-user<span class="regexp">/.sdkman/</span>candidates<span class="regexp">/java/</span>current</span><br></pre></td></tr></table></figure><h3 id="Scalaとsbt"><a href="#Scalaとsbt" class="headerlink" title="Scalaとsbt"></a>Scalaとsbt</h3><p>　Scalaのインストール可能なバージョンです。</p><figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line">$ sdk list scala</span><br><span class="line"></span><br><span class="line">================================================================================</span><br><span class="line">Available Scala Versions</span><br><span class="line">================================================================================</span><br><span class="line"><span class="code">     2.12.3</span></span><br><span class="line"><span class="code">     2.12.2</span></span><br><span class="line"><span class="code">     2.12.1</span></span><br><span class="line"><span class="code">     2.12.0</span></span><br><span class="line"><span class="code">     2.11.8</span></span><br><span class="line"><span class="code">     2.11.7</span></span><br><span class="line"><span class="code">     2.11.6</span></span><br><span class="line"><span class="code">     2.11.5</span></span><br><span class="line"><span class="code">     2.11.4</span></span><br><span class="line"><span class="code">     2.11.3</span></span><br><span class="line"><span class="code">     2.11.2</span></span><br><span class="line"><span class="code">     2.11.1</span></span><br><span class="line"><span class="code">     2.11.0</span></span><br></pre></td></tr></table></figure><p>　Scalaを最新の<code>2.12.3</code>をインストールします。</p><figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">$ sdk <span class="keyword">install </span><span class="keyword">scala </span><span class="number">2</span>.<span class="number">12</span>.<span class="number">3</span></span><br></pre></td></tr></table></figure><p>　続いてsbtです。バージョンを指定しない場合は最新がインストールされます。</p><figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">$ sdk <span class="keyword">install </span><span class="keyword">sbt</span></span><br><span class="line"><span class="keyword">$ </span>sdk current <span class="keyword">sbt</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line"><span class="keyword">Using </span><span class="keyword">sbt </span>version <span class="number">0</span>.<span class="number">13</span>.<span class="number">15</span></span><br></pre></td></tr></table></figure><h2 id="Emacs"><a href="#Emacs" class="headerlink" title="Emacs"></a>Emacs</h2><p>　Emacs24とCaskをインストールします。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get install emacs24-nox emacs24-el -y</span><br><span class="line">$ emacs --version</span><br><span class="line">GNU Emacs 24.5.1</span><br></pre></td></tr></table></figure><p>　パッケージ管理の<a href="http://cask.github.io/">Cask</a>です。インストールする時にGitとPythonが必要です。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get install git python -y</span><br><span class="line">$ curl -fsSL https://raw.githubusercontent.com/cask/cask/master/go | python</span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">&#x27;export PATH=&quot;$HOME/.cask/bin:$PATH&quot;&#x27;</span> &gt;&gt; ~/.bashrc</span><br><span class="line">$ <span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure><p>　<code>~/.emacs.d</code>ディレクトリに以下のような設定ファイルを用意します。</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">$ tree ~<span class="regexp">/.emacs.d/</span></span><br><span class="line"><span class="regexp">/home/</span>cloud-user<span class="regexp">/.emacs.d/</span></span><br><span class="line">├── Cask</span><br><span class="line">└── init.el</span><br></pre></td></tr></table></figure><p>　init.elは<a href="https://github.com/emacs-jp/init-loader">init-loader</a>で分割したい場合は<a href="https://masato.github.io/2017/08/04/emacs-eclim-java/">前回</a>の設定を確認してください。</p><ul><li>~/.emacs.d/init.el</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(require &#39;cask &quot;~&#x2F;.cask&#x2F;cask.el&quot;)</span><br><span class="line">(cask-initialize)</span><br></pre></td></tr></table></figure><p>　Caskにインストールするパッケージを記述します。</p><ul><li>~/.emacs.d/Cask</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(source gnu)</span><br><span class="line">(source melpa)</span><br><span class="line"></span><br><span class="line">(depends-on &quot;cask&quot;)</span><br><span class="line"></span><br><span class="line">;; ENSIME</span><br><span class="line">(depends-on &quot;ensime&quot;)</span><br></pre></td></tr></table></figure><p>　<code>~/.emacs.d</code>ディレクトリに移動してパッケージをインストールします。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> ~/.emacs.d</span><br><span class="line">$ cask install</span><br></pre></td></tr></table></figure><h2 id="ユーザーごとの設定"><a href="#ユーザーごとの設定" class="headerlink" title="ユーザーごとの設定"></a>ユーザーごとの設定</h2><p>　sbtプラグインの<a href="http://ensime.org/build_tools/sbt/">sbt-ensime</a>はユーザー単位にインストールします。プラグインのディレクトリがない場合は作成します。</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">$ mkdir -p ~<span class="regexp">/.sbt/</span><span class="number">0.13</span><span class="regexp">/plugins/</span></span><br></pre></td></tr></table></figure><h3 id="plugins-sbt"><a href="#plugins-sbt" class="headerlink" title="plugins.sbt"></a>plugins.sbt</h3><p>　sbtプラグインの<a href="http://ensime.org/build_tools/sbt/">sbt-ensime</a>をインストールします。ホームの<code>~/.sbt</code>にplugins.sbtを作成します。</p><ul><li>~/.sbt/0.13/plugins/plugins.sbt</li></ul><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">addSbtPlugin(<span class="string">&quot;org.ensime&quot;</span> % <span class="string">&quot;sbt-ensime&quot;</span> % <span class="string">&quot;1.12.14&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="global-sbt"><a href="#global-sbt" class="headerlink" title="global.sbt"></a>global.sbt</h3><p>　sbt-ensimeプラグインの設定を記述します。</p><ul><li>~/.sbt/0.13/global.sbt</li></ul><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.ensime.<span class="type">EnsimeKeys</span>._</span><br><span class="line"></span><br><span class="line">ensimeIgnoreMissingDirectories := <span class="literal">true</span></span><br><span class="line">cancelable in <span class="type">Global</span> := <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>　カスタマイズの内容は以下を参考にしました。</p><ul><li><p><code>scala_2.11</code>ディレクトリを作成しない<br><a href="https://stackoverflow.com/questions/41070767/ensimeconfig-creates-directories-java-and-scala-2-11-which-i-dont-need">ensimeConfig creates directories java and scala-2.11, which I don’t need</a></p></li><li><p><code>C-c</code>でプロセスをキャンセルする<br><a href="http://ensime.org/build_tools/sbt/#cancel-processes">Cancel Proceses</a></p></li></ul><h2 id="プロジェクトごとの設定"><a href="#プロジェクトごとの設定" class="headerlink" title="プロジェクトごとの設定"></a>プロジェクトごとの設定</h2><p>　簡単なsbtプロジェクトを作成してEmacsからENSIMEを利用してみます。</p><figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line">$ mkdir -p ~<span class="regexp">/scala_apps/</span>spike &amp;&amp; cd ~<span class="regexp">/scala_apps/</span>spike</span><br><span class="line">$ cd ~<span class="regexp">/scala_apps/</span>spike</span><br><span class="line">$ mkdir -p src<span class="regexp">/&#123;main,test&#125;/</span>&#123;java,resources,scala&#125;</span><br><span class="line">$ mkdir lib <span class="keyword">project</span> target</span><br></pre></td></tr></table></figure><h3 id="build-sbt"><a href="#build-sbt" class="headerlink" title="build.sbt"></a>build.sbt</h3><p>　プロジェクト定義をbuild.sbtに書きます。ScalaのバージョンはSDKMAN!でインストールした<code>2.12.3</code>から<code>2.11.8</code>に変えてみました。</p><ul><li>~/scala_apps/spike/build.sbt</li></ul><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">name := <span class="string">&quot;Spike&quot;</span></span><br><span class="line">version := <span class="string">&quot;0.1&quot;</span></span><br><span class="line">scalaVersion := <span class="string">&quot;2.11.8&quot;</span></span><br></pre></td></tr></table></figure><h3 id="ensime"><a href="#ensime" class="headerlink" title=".ensime"></a>.ensime</h3><p>　プロジェクトのトップディレクトリでsbtを起動します。<code>ensimeConfig</code>コマンドを実行して<code>.ensime</code>ファイルを作成します。</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">$ cd ~/scala_apps/spike</span><br><span class="line">$ sbt </span><br><span class="line">&gt; ensimeConfig</span><br><span class="line">[<span class="builtin-name">info</span>] ENSIME update.</span><br><span class="line">[<span class="builtin-name">info</span>] Updating &#123;file:/home/cloud-user/scala_apps/spike/&#125;spike<span class="built_in">..</span>.</span><br><span class="line">[<span class="builtin-name">info</span>] Resolving jline#jline;2.12.1 <span class="built_in">..</span>.</span><br><span class="line">[<span class="builtin-name">info</span>] Done updating.</span><br><span class="line">[<span class="builtin-name">info</span>] Resolving org.scala-lang#scala-reflect;2.11.8 <span class="built_in">..</span>.</span><br><span class="line">[<span class="builtin-name">info</span>] ENSIME processing spike (Spike)</span><br></pre></td></tr></table></figure><h2 id="ENSIMEの使い方"><a href="#ENSIMEの使い方" class="headerlink" title="ENSIMEの使い方"></a>ENSIMEの使い方</h2><p>　作成したScalaプロジェクトに簡単なHello Worldのコードを書きます。</p><h3 id="起動"><a href="#起動" class="headerlink" title="起動"></a>起動</h3><p>　<code>.ensime</code>ファイルがあるプロジェクトのトップディレクトリでEmacsを開きます。ENSIMEサーバーの起動には少し時間がかかります。</p><figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">M-x ensime</span></span><br></pre></td></tr></table></figure><p>　ミニバッファにメッセージが出るとサーバーの起動終了です。</p><figure class="highlight livecodeserver"><table><tr><td class="code"><pre><span class="line">ENSIME ready. May <span class="keyword">the</span> source be <span class="keyword">with</span> you, always.</span><br></pre></td></tr></table></figure><h3 id="HelloWorld-scala"><a href="#HelloWorld-scala" class="headerlink" title="HelloWorld.scala"></a>HelloWorld.scala</h3><p> mainメソッドを実装したScalaのコードを書きます。</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">HelloWorld</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    println(<span class="string">&quot;Hello World!&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="scala-mode"><a href="#scala-mode" class="headerlink" title="scala-mode"></a>scala-mode</h3><p>　<a href="http://ensime.org/editors/emacs/scala-mode/">scala-mode</a>はENSIMEをインストールすると自動的に使えます。個別インストールも可能です。Scalaのコードを書く場合の基本的なモードです。例えばEmacsからScala REPLを起動してみます。キーバインドの意味は<code>control を押しながらc、v、controlを離してz</code>です。</p><figure class="highlight mathematica"><table><tr><td class="code"><pre><span class="line"><span class="built_in">C</span><span class="operator">-</span><span class="variable">c</span> <span class="built_in">C</span><span class="operator">-</span><span class="variable">v</span> <span class="variable">z</span></span><br></pre></td></tr></table></figure><p>　プロジェクトのbuild.sbtに定義した<code>2.11.8</code>のREPLが起動しました。</p><figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">Welcome</span> to Scala <span class="number">2</span>.<span class="number">11</span>.<span class="number">8</span> (OpenJDK <span class="number">64</span>-Bit Server VM, Java <span class="number">1</span>.<span class="number">8</span>.<span class="number">0</span>_<span class="number">131</span>).</span><br><span class="line"><span class="attribute">Type</span> in expressions for evaluation. Or try :help.</span><br><span class="line"></span><br><span class="line"><span class="attribute">scala</span>&gt;</span><br></pre></td></tr></table></figure><h3 id="sbt-mode"><a href="#sbt-mode" class="headerlink" title="sbt-mode"></a>sbt-mode</h3><p>　<a href="http://ensime.org/editors/emacs/sbt-mode/">sbt-mode</a>も自動的に使えます。このモードではEmacsからsbtを操作するときに使います。sbtのセッションを起動します。</p><figure class="highlight crmsh"><table><tr><td class="code"><pre><span class="line">M-x sbt-<span class="literal">start</span></span><br></pre></td></tr></table></figure><p>　runコマンドはプロジェクトのmainメソッドをプログラムを実行します。Hello worldが表示されました。</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">&gt; run</span><br><span class="line">[<span class="builtin-name">info</span>] Running HelloWorld</span><br><span class="line">Hello World!</span><br><span class="line">[success] Total time: 0 s, completed Aug 9, 2017 9:07:09 AM</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      <comments>https://masato.github.io/2017/08/09/emacs-ensime-sdkman/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Kafka StreamsでSensorTagをウィンドウ集計をする</title>
      <link>https://masato.github.io/2017/08/08/sensortag-kafka-streams/</link>
      <guid>https://masato.github.io/2017/08/08/sensortag-kafka-streams/</guid>
      <pubDate>Tue, 08 Aug 2017 01:44:19 GMT</pubDate>
      <description>
      
        PySpark StreamingでSensorTagのデータをJupyterを動作環境にしてウィンドウ集計を試しました。ストリーム処理のフレームワークは他にもいくつかありますが次はKafka Streamsを使ってみます。Sparkと違いこちらはクラスタではなくライブラリです。現在のところ開発言語は公式にはJavaのみサポートしています。
      
      </description>
      
      
      <content:encoded><![CDATA[<p>　PySpark StreamingでSensorTagのデータをJupyterを動作環境にして<a href="https://masato.github.io/2017/08/02/sensortag-kafka-python-spark-streaming-6/">ウィンドウ集計を試しました</a>。ストリーム処理のフレームワークは他にもいくつかありますが次は<a href="http://docs.confluent.io/current/streams/index.html">Kafka Streams</a>を使ってみます。Sparkと違いこちらはクラスタではなくライブラリです。現在のところ開発言語は公式にはJavaのみサポートしています。</p><span id="more"></span><h2 id="Java環境"><a href="#Java環境" class="headerlink" title="Java環境"></a>Java環境</h2><p>　Ubuntu 16.04に構築した<a href="https://masato.github.io/2017/08/04/emacs-eclim-java/">Eclim</a>をMavenでコードを書いていきます。</p><h2 id="プロジェクト"><a href="#プロジェクト" class="headerlink" title="プロジェクト"></a>プロジェクト</h2><p>　プロジェクトのディレクトリに以下のファイルを作成します。完全なコードはこちらの<a href="https://github.com/masato/streams-kafka-examples">リポジトリ</a>にあります。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$  tree</span><br><span class="line">.</span><br><span class="line">├── pom.xml</span><br><span class="line">└── src</span><br><span class="line">    └── main</span><br><span class="line">        ├── java</span><br><span class="line">        │   └── com</span><br><span class="line">        │       └── github</span><br><span class="line">        │           └── masato</span><br><span class="line">        │               └── streams</span><br><span class="line">        │                   └── kafka</span><br><span class="line">        │                       ├── App.java</span><br><span class="line">        │                       ├── SensorSumDeserializer.java</span><br><span class="line">        │                       ├── SensorSum.java</span><br><span class="line">        │                       └── SensorSumSerializer.java</span><br><span class="line">        └── resources</span><br><span class="line">            └── logback.xml</span><br><span class="line"></span><br><span class="line">9 directories, 7 files</span><br></pre></td></tr></table></figure><h2 id="App-java"><a href="#App-java" class="headerlink" title="App.java"></a>App.java</h2><p>　いくつかのパートにわけてコードの説明をします。</p><h3 id="定数"><a href="#定数" class="headerlink" title="定数"></a>定数</h3><p>　トピック名などはpom.xmlに定義した環境変数から取得します。<code>WINDOWS_MINUTES</code>はウィンドウ集計をする間隔です。<code>COMMIT_MINUTES</code>は後述するようにKafkaがキャッシュを自動的にコミットする間隔です。ここでは分で指定します。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">App</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(App.class);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String SOURCE_TOPIC = System.getenv(<span class="string">&quot;SOURCE_TOPIC&quot;</span>);</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String SINK_TOPIC = System.getenv(<span class="string">&quot;SINK_TOPIC&quot;</span>);</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> WINDOWS_MINUTES = <span class="number">2L</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> COMMIT_MINUTES = <span class="number">3L</span>;</span><br></pre></td></tr></table></figure><h3 id="シリアライゼーション"><a href="#シリアライゼーション" class="headerlink" title="シリアライゼーション"></a>シリアライゼーション</h3><p>　レコードのシリアライザとデシリアライザを作成します。Kafka Streamsアプリでは処理の中間結果をトピックに保存してフローを実装していきます。レコードをトピックから読むときのデシリアライザ、書くときのシリアライザの2つをまとめてSerDeを定義します。SerDeはトピックのキーと値の型ごとに必要です。</p><ul><li><p>jsonSerde<br>SensorTagのレコードはキーは文字列、値は<a href="http://wiki.fasterxml.com/JacksonHome">Jackson</a>の<a href="https://fasterxml.github.io/jackson-databind/javadoc/2.8/com/fasterxml/jackson/databind/JsonNode.html">JsonNode</a>オブジェクトです。</p></li><li><p>sensorSumSerde<br><code>SenroSum</code>はカスタムで作成した周囲温度 (ambient)とウィンドウ集計の状態を保持するクラスです。</p></li><li><p>stringSerde<br>デフォルトのString用のSerDeです。今回メッセージのキーはすべて<code>String</code>です。</p></li><li><p>doubleSerde<br>デフォルトのdouble用のSerDeです。SensorTagの周囲温度 (ambient)は<code>double</code>でウィンドウ集計します。</p></li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> Serializer&lt;JsonNode&gt; jsonSerializer = <span class="keyword">new</span> JsonSerializer();</span><br><span class="line">    <span class="keyword">final</span> Deserializer&lt;JsonNode&gt; jsonDeserializer = <span class="keyword">new</span> JsonDeserializer();</span><br><span class="line">    <span class="keyword">final</span> Serde&lt;JsonNode&gt; jsonSerde =</span><br><span class="line">        Serdes.serdeFrom(jsonSerializer, jsonDeserializer);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> Serializer&lt;SensorSum&gt; sensorSumSerializer =</span><br><span class="line">        <span class="keyword">new</span> SensorSumSerializer();</span><br><span class="line">    <span class="keyword">final</span> Deserializer&lt;SensorSum&gt; sensorSumDeserializer =</span><br><span class="line">        <span class="keyword">new</span> SensorSumDeserializer();</span><br><span class="line">    <span class="keyword">final</span> Serde&lt;SensorSum&gt; sensorSumSerde =</span><br><span class="line">        Serdes.serdeFrom(sensorSumSerializer,</span><br><span class="line">                         sensorSumDeserializer);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> Serde&lt;String&gt; stringSerde = Serdes.String();</span><br><span class="line">    <span class="keyword">final</span> Serde&lt;Double&gt; doubleSerde = Serdes.Double();</span><br></pre></td></tr></table></figure><h3 id="KStreamの作成"><a href="#KStreamの作成" class="headerlink" title="KStreamの作成"></a>KStreamの作成</h3><p>　最初に<a href="https://kafka.apache.org/0102/javadoc/org/apache/kafka/streams/kstream/KStreamBuilder.html">KStreamBuilder</a>の<code>stream()</code>を呼び<a href="https://kafka.apache.org/0102/javadoc/org/apache/kafka/streams/kstream/KStream.html">KStream</a>を作成します。トピックのキーは文字列、値はJsonNodeのSerDeを指定します。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> KStreamBuilder builder = <span class="keyword">new</span> KStreamBuilder();</span><br><span class="line"></span><br><span class="line">LOG.info(<span class="string">&quot;Starting Sorting Job&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">final</span> KStream&lt;String, JsonNode&gt; source =</span><br><span class="line">    builder.stream(stringSerde, jsonSerde, SOURCE_TOPIC);</span><br></pre></td></tr></table></figure><h3 id="KGroupedStreamを作成"><a href="#KGroupedStreamを作成" class="headerlink" title="KGroupedStreamを作成"></a>KGroupedStreamを作成</h3><p>　SensorTagのメッセージはRaspberry Pi 3からJSON文字列でKafkaのトピックに届きます。</p><figure class="highlight"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;bid&#x27;: &#x27;B0:B4:48:BE:5E:00&#x27;, &#x27;time&#x27;: 1502152524, &#x27;humidity&#x27;: 27.26287841796875, &#x27;objecttemp&#x27;: 21.1875, &#x27;ambient&#x27;: 27.03125, &#x27;rh&#x27;: 75.311279296875&#125;</span><br></pre></td></tr></table></figure><p>　KStreamのレコードはキーと値を持つ<a href="https://kafka.apache.org/0102/javadoc/org/apache/kafka/streams/KeyValue.html">KeyValue</a>オブジェクトです。例では周囲温度 (ambient)の平均値だけウィンドウ集計するため<code>map()</code>を呼びキーと周囲温度のペアだけ持つ新しいKStreamを作成します。</p><p>　次に<code>groupByKey()</code>を呼びキーでグループ化して<a href="https://kafka.apache.org/0102/javadoc/org/apache/kafka/streams/kstream/KGroupedStream.html">KGroupedStream</a>を作成します。レコードはキーは文字列、値は周囲温度の<code>double</code>になっているのでそれぞれのSerDeを指定します。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> KGroupedStream&lt;String, Double&gt; sensors =</span><br><span class="line">    source</span><br><span class="line">    .map((k, v) -&gt; &#123;</span><br><span class="line">            <span class="keyword">double</span> ambient = v.get(<span class="string">&quot;ambient&quot;</span>).asDouble();</span><br><span class="line">            <span class="keyword">return</span> KeyValue.pair(k, ambient);</span><br><span class="line">        &#125;)</span><br><span class="line">    .groupByKey(stringSerde, doubleSerde);</span><br></pre></td></tr></table></figure><h3 id="KStramからKTableを作成"><a href="#KStramからKTableを作成" class="headerlink" title="KStramからKTableを作成"></a>KStramからKTableを作成</h3><p>　KGroupedStreamの<code>aggregate()</code>を呼び<a href="https://kafka.apache.org/0102/javadoc/org/apache/kafka/streams/kstream/KTable.html">KTable</a>を作成します。KTableはキーごとに指定されたウィンドウ間隔でレコードの合計値とレコード数の状態を保持します。</p><p>　<code>aggregate()</code>の第1引数の<a href="https://kafka.apache.org/0102/javadoc/org/apache/kafka/streams/kstream/Initializer.html">Initializer</a>ではストリームの集約で使うアグリゲータの初期化を行います。ここでウィンドウ集計の状態を保持する<code>SensorSum</code>の初期化を行います。第2引数でアグリゲータを実装します。現在のレコードのキーと値、1つ前のレコード処理で作成した<code>SensorSum</code>が渡されます。データの到着ごとに合計値とレコード数を加算して新しい<code>SensorSum</code>を返します。第３引数は2分ウィンドウの<a href="http://apache.mesi.com.ar/kafka/0.10.2.0/javadoc/org/apache/kafka/streams/kstream/TimeWindows.html">TimeWindows</a>を定義します。第4引数は<code>SensorSum</code>のSerDe、第5引数は状態を保持するトピック名を渡します。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> KTable&lt;Windowed&lt;String&gt;, SensorSum&gt; sensorAgg =</span><br><span class="line">    sensors</span><br><span class="line">    .aggregate(() -&gt; <span class="keyword">new</span> SensorSum(<span class="number">0D</span>, <span class="number">0</span>)</span><br><span class="line">               , (aggKey, value, agg) -&gt; <span class="keyword">new</span> SensorSum(agg.sum + value, agg.count + <span class="number">1</span>)</span><br><span class="line">               , TimeWindows.of(TimeUnit.MINUTES.toMillis(WINDOWS_MINUTES))</span><br><span class="line">               , sensorSumSerde,</span><br><span class="line">               <span class="string">&quot;sensorSum&quot;</span>);</span><br></pre></td></tr></table></figure><h3 id="KTableからKStramを作成"><a href="#KTableからKStramを作成" class="headerlink" title="KTableからKStramを作成"></a>KTableからKStramを作成</h3><p>　KTableの<code>mapValues()</code>で平均値を計算します。合計値をレコード数で除算した平均値は<code>Double</code>レコードの新しいKTableです。ここから<code>toStream()</code>を呼びKStreamを作成します。レコードはタイムスタンプ、キー、平均値のJSON文字列にフォーマットしてストリームに出力します。タイムスタンプは異なるシステム間でデータ交換がしやすいようにISO 8601にしています。最後に指定したトピックへレコードを保存して終了です。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> DateTimeFormatter fmt =</span><br><span class="line">    DateTimeFormatter.ISO_OFFSET_DATE_TIME;</span><br><span class="line"></span><br><span class="line">sensorAgg</span><br><span class="line">    .&lt;Double&gt;mapValues((v) -&gt; ((<span class="keyword">double</span>) v.sum / v.count))</span><br><span class="line">    .toStream()</span><br><span class="line">    .map((key, avg) -&gt; &#123;</span><br><span class="line">            <span class="keyword">long</span> end = key.window().end();</span><br><span class="line">            ZonedDateTime zdt =</span><br><span class="line">                <span class="keyword">new</span> Date(end).toInstant()</span><br><span class="line">                .atZone(ZoneId.systemDefault());</span><br><span class="line">            String time = fmt.format(zdt);</span><br><span class="line">            String bid = key.key();</span><br><span class="line">            String retval =</span><br><span class="line">                String.format(<span class="string">&quot;&#123;\&quot;time\&quot;: \&quot;%s\&quot;, \&quot;bid\&quot;: \&quot;%s\&quot;, \&quot;ambient\&quot;: %f&#125;&quot;</span>,</span><br><span class="line">                              time, bid, avg);</span><br><span class="line">            LOG.info(retval);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> KeyValue&lt;String,String&gt;(bid, retval);</span><br><span class="line">     &#125;)</span><br><span class="line">    .to(SINK_TOPIC);</span><br></pre></td></tr></table></figure><h3 id="Kafka-Streamsの開始"><a href="#Kafka-Streamsの開始" class="headerlink" title="Kafka Streamsの開始"></a>Kafka Streamsの開始</h3><p>　<a href="https://kafka.apache.org/0102/javadoc/org/apache/kafka/streams/KafkaStreams.html">KafkaStreams</a>を設定オブジェクトとビルダーから作成してKafka Streamsアプリを開始します。また<code>SIGTERM</code>でKafka Streamを停止するようにシャットダウンフックに登録しておきます。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> StreamsConfig config = <span class="keyword">new</span> StreamsConfig(getProperties());</span><br><span class="line"><span class="keyword">final</span> KafkaStreams streams = <span class="keyword">new</span> KafkaStreams(builder, config);</span><br><span class="line">streams.start();</span><br><span class="line"></span><br><span class="line">Runtime.getRuntime().addShutdownHook(<span class="keyword">new</span> Thread(streams::close));</span><br></pre></td></tr></table></figure><h3 id="Kafka-Streamsの設定とタイムアウトについて"><a href="#Kafka-Streamsの設定とタイムアウトについて" class="headerlink" title="Kafka Streamsの設定とタイムアウトについて"></a>Kafka Streamsの設定とタイムアウトについて</h3><p>　環境変数などからKafka Streamsの設定で使う<code>Properties</code>を作成します。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Properties <span class="title">getProperties</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">    props.put(StreamsConfig.APPLICATION_ID_CONFIG,</span><br><span class="line">              System.getenv(<span class="string">&quot;APPLICATION_ID_CONFIG&quot;</span>));</span><br><span class="line">    props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG,</span><br><span class="line">              System.getenv(<span class="string">&quot;BOOTSTRAP_SERVERS_CONFIG&quot;</span>));</span><br><span class="line">    props.put(StreamsConfig.KEY_SERDE_CLASS_CONFIG,</span><br><span class="line">              Serdes.String().getClass().getName());</span><br><span class="line">    props.put(StreamsConfig.VALUE_SERDE_CLASS_CONFIG,</span><br><span class="line">              Serdes.String().getClass().getName());</span><br><span class="line">    props.put(StreamsConfig.TIMESTAMP_EXTRACTOR_CLASS_CONFIG,</span><br><span class="line">              WallclockTimestampExtractor.class.getName());</span><br><span class="line">    props.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG,</span><br><span class="line">              TimeUnit.MINUTES.toMillis(COMMIT_MINUTES));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> props;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="COMMIT-INTERVAL-MS-CONFIG"><a href="#COMMIT-INTERVAL-MS-CONFIG" class="headerlink" title="COMMIT_INTERVAL_MS_CONFIG"></a>COMMIT_INTERVAL_MS_CONFIG</h3><p>　最初は<a href="https://kafka.apache.org/0102/javadoc/org/apache/kafka/streams/StreamsConfig.html#COMMIT_INTERVAL_MS_CONFIG">StreamsConfig.COMMIT_INTERVAL_MS_CONFIG</a>は変更していませんでした。レコードをトピック保存する前にKStreamのmap()でログを出力しています。2分ウィンドウ間隔の集計結果を最後に1回だけ出力をさせたかったのですが、4-5回不特定に重複する結果になりました。</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">&#123;&quot;time&quot;: &quot;2017-08-08T10:34:00+09:00&quot;, &quot;bid&quot;: &quot;B0:B4:48:BE:5E:00&quot;, &quot;ambient&quot;: 27.343750&#125;</span><br><span class="line">&#123;&quot;time&quot;: &quot;2017-08-08T10:34:00+09:00&quot;, &quot;bid&quot;: &quot;B0:B4:48:BE:5E:00&quot;, &quot;ambient&quot;: 27.385417&#125;</span><br><span class="line">&#123;&quot;time&quot;: &quot;2017-08-08T10:34:00+09:00&quot;, &quot;bid&quot;: &quot;B0:B4:48:BE:5E:00&quot;, &quot;ambient&quot;: 27.410156&#125;</span><br><span class="line">&#123;&quot;time&quot;: &quot;2017-08-08T10:34:00+09:00&quot;, &quot;bid&quot;: &quot;B0:B4:48:BE:5E:00&quot;, &quot;ambient&quot;: 27.440341&#125;</span><br><span class="line">&#123;&quot;time&quot;: &quot;2017-08-08T10:34:00+09:00&quot;, &quot;bid&quot;: &quot;B0:B4:48:BE:5E:00&quot;, &quot;ambient&quot;: 27.450521&#125;</span><br><span class="line">&#123;&quot;time&quot;: &quot;2017-08-08T10:36:00+09:00&quot;, &quot;bid&quot;: &quot;B0:B4:48:BE:5E:00&quot;, &quot;ambient&quot;: 27.562500&#125;</span><br><span class="line">&#123;&quot;time&quot;: &quot;2017-08-08T10:36:00+09:00&quot;, &quot;bid&quot;: &quot;B0:B4:48:BE:5E:00&quot;, &quot;ambient&quot;: 27.562500&#125;</span><br></pre></td></tr></table></figure><p>　以下の記事を参考にすると、これはKTableの変更履歴 (changelog stream)という特徴から期待される動作のようです。KTableにウィンドウ集計の最終結果という状態はなく、キャッシュに更新された値は一定の間隔でコミットされます。KStreamへ<code>toStream()</code>したあとに<code>transform()</code>や<code>process()</code>を使いレコードの重複を除去するコードを自分で実装する必要があるようです。</p><p>　レコードの重複を完全に除去することはできませんが<code>StreamsConfig.COMMIT_INTERVAL_MS_CONFIG</code>の値を大きくすることでキャッシュがコミットされる回数を減らすことができます。<a href="http://docs.confluent.io/3.2.1/streams/developer-guide.html#optional-configuration-parameters">デフォルト値</a>は30秒が指定されています。</p><ul><li><a href="https://stackoverflow.com/questions/38935904/how-to-send-final-kafka-streams-aggregation-result-of-a-time-windowed-ktable">How to send final kafka-streams aggregation result of a time windowed KTable?</a></li><li><a href="http://users.kafka.apache.narkive.com/iFqyaD4p/immutable-record-with-kafka-stream">Immutable Record with Kafka Stream</a></li><li><a href="https://stackoverflow.com/questions/39232395/kafka-kstreams-processing-timeouts">Kafka KStreams - processing timeouts</a></li><li><a href="https://balamaci.ro/kafka-streams-for-stream-processing/">Kafka Streams for Stream processing A few words about how Kafka works.</a></li><li><a href="http://docs.confluent.io/3.1.2/streams/developer-guide.html#memory-management">Memory management</a></li></ul><h2 id="その他のクラス"><a href="#その他のクラス" class="headerlink" title="その他のクラス"></a>その他のクラス</h2><p>　モデル (SensorSum.java)、シリアライザ (SensorSumSerializer.java)、デシリアライザ (SensorSumDeserializer)のクラスを用意します。シリアライザは<code>serialize()</code>を実装して<code>SensorSum</code>のプロパティをバイト配列に変換します。byteバッファに周囲温度合計値の<code>Double</code>の8バイトと、レコード数の<code>Integer</code>の4バイト分を割り当て使います。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">byte</span>[] serialize(String topic, SensorSum data) &#123;</span><br><span class="line">    ByteBuffer buffer = ByteBuffer.allocate(<span class="number">8</span> + <span class="number">4</span>);</span><br><span class="line">    buffer.putDouble(data.sum);</span><br><span class="line">    buffer.putInt(data.count);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> buffer.array();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="実行"><a href="#実行" class="headerlink" title="実行"></a>実行</h2><p>　<a href="http://www.mojohaus.org/exec-maven-plugin/">Exec Maven Plugin</a>からKafka Streamsを実行します。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ mvn clean install <span class="built_in">exec</span>:<span class="built_in">exec</span>@json</span><br></pre></td></tr></table></figure><p>　ウィンドウ間隔が2分、キャッシュのコミット間隔を3分に指定してみました。やはり何回か重複した出力はありますが重複した出力を減らすことができました。</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">&#123;&quot;time&quot;: &quot;2017-08-08T11:32:00+09:00&quot;, &quot;bid&quot;: &quot;B0:B4:48:BE:5E:00&quot;, &quot;ambient&quot;: 27.414773&#125;</span><br><span class="line">&#123;&quot;time&quot;: &quot;2017-08-08T11:34:00+09:00&quot;, &quot;bid&quot;: &quot;B0:B4:48:BE:5E:00&quot;, &quot;ambient&quot;: 27.414063&#125;</span><br><span class="line">&#123;&quot;time&quot;: &quot;2017-08-08T11:36:00+09:00&quot;, &quot;bid&quot;: &quot;B0:B4:48:BE:5E:00&quot;, &quot;ambient&quot;: 27.453125&#125;</span><br><span class="line">&#123;&quot;time&quot;: &quot;2017-08-08T11:36:00+09:00&quot;, &quot;bid&quot;: &quot;B0:B4:48:BE:5E:00&quot;, &quot;ambient&quot;: 27.476563&#125;</span><br><span class="line">&#123;&quot;time&quot;: &quot;2017-08-08T11:38:00+09:00&quot;, &quot;bid&quot;: &quot;B0:B4:48:BE:5E:00&quot;, &quot;ambient&quot;: 27.546875&#125;</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      <comments>https://masato.github.io/2017/08/08/sensortag-kafka-streams/#disqus_thread</comments>
    </item>
    
    <item>
      <title>EclimでJavaもEmacsからコーディングする</title>
      <link>https://masato.github.io/2017/08/04/emacs-eclim-java/</link>
      <guid>https://masato.github.io/2017/08/04/emacs-eclim-java/</guid>
      <pubDate>Fri, 04 Aug 2017 00:32:05 GMT</pubDate>
      <description>
      
        Java開発ではローカルのWindowsやmacOSのIntelliJ IDEAやEclipseなどのIDEを利用しますが、Node.jsやPythonなどスクリプト言語の開発はVimやEmacsのエディタという方も多いと思います。Eclimを使うとJavaも同じようにエディタから開発をすることができます。クラウドの仮想マシンに開発環境を構築すればローカルの設定依存せずターミナルからSSH接続していつでも同じ開発ができます。
      
      </description>
      
      
      <content:encoded><![CDATA[<p>　Java開発ではローカルのWindowsやmacOSのIntelliJ IDEAやEclipseなどのIDEを利用しますが、Node.jsやPythonなどスクリプト言語の開発はVimやEmacsのエディタという方も多いと思います。Eclimを使うとJavaも同じようにエディタから開発をすることができます。クラウドの仮想マシンに開発環境を構築すればローカルの設定依存せずターミナルからSSH接続していつでも同じ開発ができます。</p><span id="more"></span><h2 id="仮想マシン"><a href="#仮想マシン" class="headerlink" title="仮想マシン"></a>仮想マシン</h2><p>　クラウドに仮想マシンを用意します。今回はUbuntu 16.04 LTS (Xenial Xerus)にJavaの開発環境を構築します。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ cat /etc/os-release</span><br><span class="line">NAME=<span class="string">&quot;Ubuntu&quot;</span></span><br><span class="line">VERSION=<span class="string">&quot;16.04.3 LTS (Xenial Xerus)&quot;</span></span><br><span class="line">ID=ubuntu</span><br><span class="line">ID_LIKE=debian</span><br><span class="line">PRETTY_NAME=<span class="string">&quot;Ubuntu 16.04.3 LTS&quot;</span></span><br><span class="line">VERSION_ID=<span class="string">&quot;16.04&quot;</span></span><br><span class="line">HOME_URL=<span class="string">&quot;http://www.ubuntu.com/&quot;</span></span><br><span class="line">SUPPORT_URL=<span class="string">&quot;http://help.ubuntu.com/&quot;</span></span><br><span class="line">BUG_REPORT_URL=<span class="string">&quot;http://bugs.launchpad.net/ubuntu/&quot;</span></span><br><span class="line">VERSION_CODENAME=xenial</span><br><span class="line">UBUNTU_CODENAME=xenial</span><br></pre></td></tr></table></figure><p>　パッケージを更新しておきます。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get update &amp;&amp; sudo apt-get dist-upgrade -y</span><br></pre></td></tr></table></figure><h2 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h2><p>　Java 8のSDKをインストールします。OpenJDK以外でも構いません。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get install openjdk-8-jdk -y</span><br><span class="line">$ java -version</span><br><span class="line">openjdk version <span class="string">&quot;1.8.0_131&quot;</span></span><br><span class="line">OpenJDK Runtime Environment (build 1.8.0_131-8u131-b11-2ubuntu1.16.04.3-b11)</span><br><span class="line">OpenJDK 64-Bit Server VM (build 25.131-b11, mixed mode)</span><br></pre></td></tr></table></figure><h2 id="Eclipse-Oxygen"><a href="#Eclipse-Oxygen" class="headerlink" title="Eclipse Oxygen"></a>Eclipse Oxygen</h2><p>　EclimはEclipseに接続してエディタからEclipseの一部の機能を使えるようにします。2017年6月にリリースされた<a href="https://www.eclipse.org/oxygen/">Eclipse Oxygen (4.7)</a>をダウンロードします。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ wget http://ftp.yz.yamagata-u.ac.jp/pub/eclipse/technology/epp/downloads/release/oxygen/R/eclipse-java-oxygen-R-linux-gtk-x86_64.tar.gz</span><br><span class="line">$ tar zxvf eclipse-java-oxygen-R-linux-gtk-x86_64.tar.gz</span><br><span class="line">$ sudo mv eclipse /opt/</span><br></pre></td></tr></table></figure><h2 id="Emacs"><a href="#Emacs" class="headerlink" title="Emacs"></a>Emacs</h2><p>　Emacs24をインストールします。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get install emacs24-nox emacs24-el -y</span><br><span class="line">$ emacs --version</span><br><span class="line">GNU Emacs 24.5.1</span><br></pre></td></tr></table></figure><h3 id="Cask"><a href="#Cask" class="headerlink" title="Cask"></a>Cask</h3><p>　Emacsパッケージ管理の<a href="http://cask.github.io/">Cask</a>です。インストールにはGitとPythonが必要です。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get install git python -y</span><br><span class="line">$ curl -fsSL https://raw.githubusercontent.com/cask/cask/master/go | python</span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">&#x27;export PATH=&quot;$HOME/.cask/bin:$PATH&quot;&#x27;</span> &gt;&gt; ~/.bashrc</span><br><span class="line">$ <span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure><p>　<code>~/.emacs.d</code>ディレクトリに以下のような設定ファイルを用意します。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ tree ~/.emacs.d</span><br><span class="line">├── Cask</span><br><span class="line">├── init.el</span><br><span class="line">└── inits</span><br><span class="line">    ├── 00-keybindings.el</span><br><span class="line">    ├── 01-menu.el</span><br><span class="line">    ├── 02-files.el</span><br><span class="line">    └── 08-eclim.el</span><br></pre></td></tr></table></figure><p>　<code>init.el</code>は<a href="https://github.com/emacs-jp/init-loader">init-loader</a>を使いファイルを分割します。<code>~/.emacs.d/inits/08-eclim.el</code>以外はお好みで利用してください。</p><ul><li>~/.emacs.d/init.el</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(require &#39;cask &quot;~&#x2F;.cask&#x2F;cask.el&quot;)</span><br><span class="line">(cask-initialize)</span><br><span class="line"></span><br><span class="line">(require &#39;init-loader)</span><br><span class="line">(setq init-loader-show-log-after-init nil)</span><br><span class="line">(init-loader-load &quot;~&#x2F;.emacs.d&#x2F;inits&quot;)</span><br></pre></td></tr></table></figure><p>　Caskにインストールするパッケージを記述します。Java開発用に<a href="https://github.com/emacs-eclim/emacs-eclim">eclim</a>と<a href="https://github.com/senny/emacs-eclim/blob/master/company-emacs-eclim.el">company-emacs-eclim</a>をインストールします。</p><ul><li>~/.emacs.d/Cask</li></ul><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">(source gnu)</span><br><span class="line">(source melpa)</span><br><span class="line"></span><br><span class="line">(<span class="keyword">depends</span>-<span class="keyword">on</span> &quot;cask&quot;)</span><br><span class="line">(<span class="keyword">depends</span>-<span class="keyword">on</span> &quot;init-loader&quot;)</span><br><span class="line"></span><br><span class="line">;; java</span><br><span class="line">(<span class="keyword">depends</span>-<span class="keyword">on</span> &quot;eclim&quot;)</span><br><span class="line">(<span class="keyword">depends</span>-<span class="keyword">on</span> &quot;company-emacs-eclim&quot;)</span><br></pre></td></tr></table></figure><p>　Eclimの設定は<a href="https://github.com/emacs-eclim/emacs-eclim/blob/master/README.md">README</a>に従います。ポップアップダイアログとコード補完機能は<a href="https://github.com/company-mode/company-mode">company-mode</a>を使います。</p><ul><li>~/.emacs.d/inits/08-eclim-el</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(require &#39;eclim)</span><br><span class="line"></span><br><span class="line">;; enable eclim-mode globally</span><br><span class="line">(setq eclimd-autostart t)</span><br><span class="line">(global-eclim-mode)</span><br><span class="line"></span><br><span class="line">;; Eclipse installation</span><br><span class="line">(custom-set-variables</span><br><span class="line">  &#39;(eclim-eclipse-dirs &#39;(&quot;&#x2F;opt&#x2F;eclipse&#x2F;eclipse&quot;))</span><br><span class="line">  &#39;(eclim-executable &quot;&#x2F;opt&#x2F;eclipse&#x2F;eclim&quot;))</span><br><span class="line"></span><br><span class="line">;; Displaying compilation error messages in the echo area</span><br><span class="line">(setq help-at-pt-display-when-idle t)</span><br><span class="line">(setq help-at-pt-timer-delay 0.1)</span><br><span class="line">(help-at-pt-set-timer)</span><br><span class="line"></span><br><span class="line">;; Configuring company-mode</span><br><span class="line">(require &#39;company)</span><br><span class="line">(require &#39;company-emacs-eclim)</span><br><span class="line">(company-emacs-eclim-setup)</span><br><span class="line">(global-company-mode t)</span><br></pre></td></tr></table></figure><p>　以下は必須ではありませんがEmacsでよく使う設定です。<code>C-h</code>でバックスペースのキーバインドを変更します。</p><ul><li>~/.emacs.d/inits/00-keybindings.el</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(define-key global-map &quot;\C-h&quot; &#39;delete-backward-char)</span><br><span class="line">(define-key global-map &quot;\M-?&quot; &#39;help-for-help)</span><br></pre></td></tr></table></figure><p>　Emacsのメニューを非表示にします。</p><ul><li>~/.emacs.d/inits/01-menu.el</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(menu-bar-mode 0)</span><br></pre></td></tr></table></figure><p>　行末の空白削除、バックアップを作らない、タブ設定などです。</p><ul><li>~/.emacs.d/inits/02-files.el</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(when (boundp &#39;show-trailing-whitespace)</span><br><span class="line">      (setq-default show-trailing-whitespace t))</span><br><span class="line"></span><br><span class="line">(add-hook &#39;before-save-hook &#39;delete-trailing-whitespace)</span><br><span class="line"></span><br><span class="line">(setq backup-inhibited t)</span><br><span class="line">(setq next-line-add-newlines nil)</span><br><span class="line">(setq-default tab-width 4 indent-tabs-mode nil)</span><br><span class="line"></span><br><span class="line">(setq default-major-mode &#39;text-mode)</span><br></pre></td></tr></table></figure><p>　最後に<code>cask</code>コマンドを実行してパッケージをインストールします。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> ~/.emacs.d</span><br><span class="line">$ cask install</span><br></pre></td></tr></table></figure><h2 id="Eclim"><a href="#Eclim" class="headerlink" title="Eclim"></a>Eclim</h2><p> <a href="http://eclim.org/install.html#install-headless">Installing on a headless server</a>にあるようにXサーバーが必要なEclipseをヘッドレスで利用するため仮想フレームバッファの<a href="https://www.x.org/releases/X11R7.7/doc/man/man1/Xvfb.1.xhtml">Xvfb</a>をインストールします。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get install xvfb build-essential -y</span><br></pre></td></tr></table></figure><p>　Eclipseのディレクトリに移動してEclimをインストールします。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /opt/eclipse</span><br><span class="line">$ wget https://github.com/ervandew/eclim/releases/download/2.7.0/eclim_2.7.0.jar</span><br><span class="line">$ java -Dvim.files=<span class="variable">$HOME</span>/.vim -Declipse.home=<span class="string">&quot;/opt/eclipse&quot;</span> -jar eclim_2.7.0.jar install</span><br></pre></td></tr></table></figure><p>　 Xvfbとeclimdを起動します。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ Xvfb :1 -screen 0 1024x768x24 &amp;</span><br><span class="line">$ DISPLAY=:1 /opt/eclipse/eclimd -b</span><br></pre></td></tr></table></figure><h2 id="サンプルプロジェクト"><a href="#サンプルプロジェクト" class="headerlink" title="サンプルプロジェクト"></a>サンプルプロジェクト</h2><p>　<a href="http://maven.apache.org/archetypes/maven-archetype-quickstart/">maven-archetype-quickstart</a>のアーキタイプからサンプルプロジェクトを作成しEclimの動作確認をします。最初に<a href="http://sdkman.io/">SDKMAN!</a>から<a href="https://maven.apache.org/">Maven</a>をインストールします。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ curl -s get.sdkman.io | /bin/bash</span><br><span class="line">$ <span class="built_in">source</span> ~/.sdkman/bin/sdkman-init.sh</span><br><span class="line">$ sdk install maven</span><br><span class="line">...</span><br><span class="line">Setting maven 3.5.0 as default.</span><br></pre></td></tr></table></figure><p>　適当なディレクトリで<code>mvn archetype:generate</code>を実行します。Eclipseの設定ファイルも<code>mvn eclipse:eclipse</code>で作成します。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ mkdir ~/java_apps &amp;&amp; <span class="built_in">cd</span> ~/java_apps</span><br><span class="line">$ mvn archetype:generate \</span><br><span class="line">  -DarchetypeArtifactId=maven-archetype-quickstart \</span><br><span class="line">  -DinteractiveMode=<span class="literal">false</span> \</span><br><span class="line">  -DgroupId=com.example \</span><br><span class="line">  -DartifactId=spike</span><br><span class="line">$ <span class="built_in">cd</span> spike</span><br><span class="line">$ mvn eclipse:eclipse</span><br></pre></td></tr></table></figure><p>　Emacsを起動します。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ emacs</span><br></pre></td></tr></table></figure><p>　アーキタイプから生成したプロジェクトをEclipseにインポートします。</p><figure class="highlight elm"><table><tr><td class="code"><pre><span class="line"><span class="type">M</span>-x eclim-project-<span class="keyword">import</span></span><br></pre></td></tr></table></figure><p>　ミニバッファでProject Directoryを聞かれるのでプロジェクトのディレクトリを指定します。</p><figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line"><span class="keyword">Project</span> Directory: ~<span class="regexp">/java_apps/</span>spike/</span><br></pre></td></tr></table></figure><p>　<code>Hello world!</code>に日付を追加しました。</p><ul><li>~/java_apps/spike/src/main/java/com/example/App.java</li></ul><figure class="highlight java"><figcaption><span>~/java_apps/spike/src/main/java/com/example/App.java</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.example;</span><br><span class="line"><span class="keyword">import</span> java.util.Date;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Hello world!</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">App</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">( String[] args )</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        Date date = <span class="keyword">new</span> Date();</span><br><span class="line">        System.out.println( <span class="string">&quot;Hello World!: &quot;</span> + date.getMinutes());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>　<code>date.get</code>まで入力するとポッップアップとミニバッファに候補が表示されます。カーソルで<code>getMinutes</code>を選択してエンターを押します。</p><p><img src="/2017/08/03/emacs-eclim-java/eclim.png" alt="eclim.png"></p><p>　<code>C-x C-s</code>でファイルを保存すると<code>Eclim reports 0 errors, 1 warnings.</code>と表示されます。<code>getMinutes</code>にアンダーラインが引かれそこにカーソルを移動するとミニバッファにエラーメッセージが出ます。Hello worldなのでここでは無視します。</p><p><img src="/2017/08/03/emacs-eclim-java/eclim2.png" alt="eclim2.png"></p><p>　mainメソッドがあるJavaファイルをバッファに表示して<code>eclim-run-class</code>を実行するとコンパイルとmainメソッドが走ります。</p><figure class="highlight applescript"><table><tr><td class="code"><pre><span class="line">M-x eclim-<span class="built_in">run</span>-<span class="built_in">class</span></span><br></pre></td></tr></table></figure><p><img src="/2017/08/03/emacs-eclim-java/eclim3.png" alt="eclim3.png"></p>]]></content:encoded>
      
      <comments>https://masato.github.io/2017/08/04/emacs-eclim-java/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Yahoo!ジオコーダAPIとTurf.jsで住所からポリゴンを計算してgeojson.ioに描画する</title>
      <link>https://masato.github.io/2017/08/04/yahoo-geocoder-turfjs-polygon/</link>
      <guid>https://masato.github.io/2017/08/04/yahoo-geocoder-turfjs-polygon/</guid>
      <pubDate>Thu, 03 Aug 2017 22:26:07 GMT</pubDate>
      <description>
      
        Yahoo!ジオコーダAPIで住所文字列から座標情報を取得し、Turf.jsを使いポリゴンを計算します。最後にGeoJSONにフォーマットしてgeojson.ioに描画してみます。
      
      </description>
      
      
      <content:encoded><![CDATA[<p>　<a href="https://developer.yahoo.co.jp/webapi/map/openlocalplatform/v1/geocoder.html">Yahoo!ジオコーダAPI</a>で住所文字列から座標情報を取得し、<a href="http://turfjs.org/">Turf.js</a>を使いポリゴンを計算します。最後にGeoJSONにフォーマットして<a href="http://geojson.io/">geojson.io</a>に描画してみます。</p><span id="more"></span><h2 id="GIS-地理情報システム-用語"><a href="#GIS-地理情報システム-用語" class="headerlink" title="GIS(地理情報システム)用語"></a>GIS(地理情報システム)用語</h2><ul><li><a href="http://geojson.org/">GeoJSON</a></li></ul><p>　地理空間データの標準フォーマットです。<a href="https://www.google.co.jp/maps">Google Maps</a>や<a href="https://www.mapbox.com/">Mapbox</a>、<a href="https://www.mapquest.com/">MapQuest</a>など多くのWeb地図サービスで利用できます。</p><ul><li>座標情報 (Coordinates)<br>経度 (Longitude)、緯度 (Latitude)の順に並びます。</li></ul><p>　以下は<a href="http://www.pasco.co.jp/">株式会社パスコ</a>による<a href="http://www.pasco.co.jp/recommend/word/word022/">用語集</a>を参照します。</p><ul><li>ポイント (Point)<blockquote><p>長さや幅のない対象物を指します。<br>地図表示の例としては、信号、山頂点、気象観測点、などがあげられます。</p></blockquote></li></ul><ul><li>ポリゴン (Polygon)<blockquote><p>境界線を表わす線の終点を始点に一致させ、閉領域を作った面など、地図上で一つの地域を表す多辺図形を一般的にポリゴンと呼びます。<br>地図表示の例としては、運動場などがあげられます。</p></blockquote></li></ul><p>　Mapboxではポイントとポリゴンはこのように表現されます。</p><p><img src="/2017/08/04/yahoo-geocoder-turfjs-polygon/circle.png" alt="circle.png"></p><h2 id="Yahoo-ジオコーダAPI"><a href="#Yahoo-ジオコーダAPI" class="headerlink" title="Yahoo!ジオコーダAPI"></a>Yahoo!ジオコーダAPI</h2><p>　<a href="https://developer.yahoo.co.jp/webapi/map/openlocalplatform/v1/geocoder.html">Yahoo!ジオコーダAPI</a>はYahoo!JAPANが開発している<a href="https://developer.yahoo.co.jp/webapi/map/">YOLP</a>の地図・地域情報APIの一つです。住所文字列から座標情報(経度、緯度)を取得できます。特に明記はないのですが住所文字列は正規化もしてくれ、<code>1丁目8番1号</code>や<code>１－８－１</code>、<code>１丁目8-1</code>などの揺らぎにもしっかり対応しているようです。</p><p>　最初にYahoo! JAPANのWebサービスを利用するために必要なアプリケーションIDを「<a href="https://www.yahoo-help.jp/app/answers/detail/p/537/a_id/43398">アプリケーションIDを登録する</a>」を参考にして取得しておきます。</p><h2 id="Turf-js"><a href="#Turf-js" class="headerlink" title="Turf.js"></a>Turf.js</h2><p>　<a href="http://turfjs.org/">Turf.js</a>は地理空間分析用のJavaScriptライブラリです。たくさんの地理空間分析<a href="http://turfjs.org/docs/">API</a>が用意されています。<a href="http://turfjs.org/docs/#circle">circle</a>メソッドを使い座標情報からポリゴンを計算します。</p><h2 id="geojson-io"><a href="#geojson-io" class="headerlink" title="geojson.io"></a>geojson.io</h2><p>　<a href="http://geojson.io/">geojson.io</a>はブラウザ上で簡単にGeoJSONを編集して地図に描画できるWebサービスです。Mapboxがオープンソースで<a href="https://github.com/mapbox/geojson.io">開発</a>しています。Node.jsのコードからGeoJSONを出力し<a href="https://github.com/mapbox/geojsonio-cli">geojsonio-cli</a>を通して使います。</p><h2 id="サンプルプロジェクト"><a href="#サンプルプロジェクト" class="headerlink" title="サンプルプロジェクト"></a>サンプルプロジェクト</h2><p>　package.jsonを用意して<code>npm install</code>します。</p><figure class="highlight json"><figcaption><span>package.json</span></figcaption><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;ygeocode-sample&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;description&quot;</span>: <span class="string">&quot;ygeocode-sample&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;version&quot;</span>: <span class="string">&quot;0.0.1&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;private&quot;</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">&quot;scripts&quot;</span>: &#123;</span><br><span class="line">    <span class="attr">&quot;start&quot;</span>: <span class="string">&quot;node index.js | geojsonio&quot;</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">&quot;dependencies&quot;</span>: &#123;</span><br><span class="line">    <span class="attr">&quot;@turf/turf&quot;</span>: <span class="string">&quot;^4.6.1&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;geojsonio-cli&quot;</span>: <span class="string">&quot;^0.2.3&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;request&quot;</span>: <span class="string">&quot;^2.81.0&quot;</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>　簡単なNode.jsのスクリプトを書きます。変数は環境に応じて変更してください。</p><ul><li><p>appId<br>Yahoo! JAPANのWebサービスのアプリケーションID</p></li><li><p>query<br>ポリゴンを計算する住所文字列、サンプルはヤフオクドームの住所</p></li></ul><p>　以下の<a href="http://turfjs.org/docs/#circle">circle</a>メソッドの引数はドキュメントに詳細な説明があります。</p><ul><li><p>radius<br>ポリゴンの半径</p></li><li><p>steps<br>ポリゴンを描画するステップ数</p></li><li><p>units<br>半径の単位</p></li></ul><figure class="highlight js"><figcaption><span>index.js</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="meta">&#x27;use strict&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> request = <span class="built_in">require</span>(<span class="string">&#x27;request&#x27;</span>);</span><br><span class="line"><span class="keyword">const</span> turf = <span class="built_in">require</span>(<span class="string">&#x27;@turf/turf&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> baseUrl = <span class="string">&#x27;https://map.yahooapis.jp/geocode/V1/geoCoder&#x27;</span>;</span><br><span class="line"><span class="keyword">const</span> appId = <span class="string">&#x27;&lt;YOUR APP ID&gt;&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> query = <span class="string">&#x27;福岡市中央区地行浜2丁目2番2号&#x27;</span>;</span><br><span class="line"><span class="keyword">const</span> radius = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">const</span> steps = <span class="number">60</span>;</span><br><span class="line"><span class="keyword">const</span> units = <span class="string">&#x27;kilometers&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> qs = &#123; <span class="attr">appid</span>:appId,</span><br><span class="line">             query:query,</span><br><span class="line">             output:<span class="string">&#x27;json&#x27;</span>&#125;;</span><br><span class="line"></span><br><span class="line">request.get(&#123; <span class="attr">url</span>:baseUrl, <span class="attr">qs</span>:qs, <span class="attr">json</span>:<span class="literal">true</span> &#125;, <span class="function">(<span class="params">err, response, body</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">const</span> features = body.Feature;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (features.length &lt; <span class="number">1</span>) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> feature = features[<span class="number">0</span>];</span><br><span class="line">  <span class="keyword">const</span> feature = features[<span class="number">0</span>];</span><br><span class="line">  <span class="keyword">const</span> address = feature.Property.Address;</span><br><span class="line">  <span class="keyword">const</span> coord = feature.Geometry.Coordinates.split(<span class="string">&#x27;,&#x27;</span>);</span><br><span class="line">  <span class="keyword">const</span> center = &#123; <span class="attr">type</span>:<span class="string">&#x27;Feature&#x27;</span>,</span><br><span class="line">                   properties: &#123;&#125;,</span><br><span class="line">                   geometry: &#123;</span><br><span class="line">                     coordinates: coord.map(<span class="function">(<span class="params">v</span>) =&gt;</span> <span class="built_in">parseFloat</span>(v)),</span><br><span class="line">                     type: <span class="string">&#x27;Point&#x27;</span></span><br><span class="line">                   &#125;</span><br><span class="line">                 &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> properties = &#123; <span class="attr">address</span>:address &#125;;</span><br><span class="line">  <span class="keyword">const</span> polygon = turf.circle(center, radius, steps, units, properties);</span><br><span class="line">  <span class="keyword">const</span> geojson = &#123;</span><br><span class="line">    type: <span class="string">&#x27;FeatureCollection&#x27;</span>,</span><br><span class="line">    features: [center, polygon]</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">console</span>.log(<span class="built_in">JSON</span>.stringify(geojson));</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>　プログラムを実行するとFeatureCollectionタイプのGeoJSONが出力されます。</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;<span class="attr">&quot;type&quot;</span>:<span class="string">&quot;FeatureCollection&quot;</span>,<span class="attr">&quot;features&quot;</span>:[&#123;<span class="attr">&quot;type&quot;</span>:<span class="string">&quot;Feature&quot;</span>,<span class="attr">&quot;properties&quot;</span>:&#123;&#125;,<span class="attr">&quot;geometry&quot;</span>:&#123;<span class="attr">&quot;coordinates&quot;</span>:[<span class="number">130.36213488</span>,<span class="number">33.59540143</span>],<span class="attr">&quot;type&quot;</span>:<span class="string">&quot;Point&quot;</span>&#125;&#125;,&#123;<span class="attr">&quot;type&quot;</span>:<span class="string">&quot;Feature&quot;</span>,<span class="attr">&quot;properties&quot;</span>:&#123;<span class="attr">&quot;address&quot;</span>:<span class="string">&quot;福岡県福岡市中央区地行浜2丁目2-2&quot;</span>&#125;,<span class="attr">&quot;geometry&quot;</span>:&#123;<span class="attr">&quot;type&quot;</span>:<span class="string">&quot;Polygon&quot;</span>,<span class="attr">&quot;coordinates&quot;</span>:[[[<span class="number">130.36213488</span>,<span class="number">33.60439182377266</span>],[<span class="number">130.36326319720803</span>,<span class="number">33.60434256833447</span>],[<span class="number">130.36437914850492</span>,<span class="number">33.60419534184053</span>],[<span class="number">130.36547050363063</span>,<span class="number">33.60395175783102</span>],[<span class="number">130.36652530213368</span>,<span class="number">33.60361448586572</span>],[<span class="number">130.3675319845582</span>,<span class="number">33.603187222240585</span>],[<span class="number">130.3684795192171</span>,<span class="number">33.602674649443514</span>],[<span class="number">130.36935752315605</span>,<span class="number">33.60208238479515</span>],[<span class="number">130.37015637598037</span>,<span class="number">33.60141691884032</span>],[<span class="number">130.3708673252925</span>,<span class="number">33.600685544167646</span>],[<span class="number">130.37148258258514</span>,<span class="number">33.59989627544021</span>],[<span class="number">130.3719954085387</span>,<span class="number">33.59905776151671</span>],[<span class="number">130.37240018679</span>,<span class="number">33.598179190628684</span>],[<span class="number">130.37269248536725</span>,<span class="number">33.5972701896556</span>],[<span class="number">130.37286910512242</span>,<span class="number">33.596340718603905</span>],[<span class="number">130.3729281146359</span>,<span class="number">33.59540096144804</span>],[<span class="number">130.37286887121738</span>,<span class="number">33.59446121453118</span>],[<span class="number">130.37269202777998</span>,<span class="number">33.593531773748936</span>],[<span class="number">130.3723995255192</span>,<span class="number">33.59262282175287</span>],[<span class="number">130.3719945724851</span>,<span class="number">33.59174431640888</span>],[<span class="number">130.3714816082883</span>,<span class="number">33.59090588173187</span>],[<span class="number">130.37086625533385</span>,<span class="number">33.59011670248989</span>],[<span class="number">130.3701552571223</span>,<span class="number">33.5893854236307</span>],[<span class="number">130.36935640429795</span>,<span class="number">33.58872005562991</span>],[<span class="number">130.36847844925842</span>,<span class="number">33.58812788679505</span>],[<span class="number">130.3675310102614</span>,<span class="number">33.58761540348344</span>],[<span class="number">130.36652446608005</span>,<span class="number">33.58718821910479</span>],[<span class="number">130.36546984235983</span>,<span class="number">33.586851012683525</span>],[<span class="number">130.36437869091762</span>,<span class="number">33.58660747765104</span>],[<span class="number">130.363262963303</span>,<span class="number">33.58646028142657</span>],[<span class="number">130.36213488</span>,<span class="number">33.58641103622736</span>],[<span class="number">130.36100679669704</span>,<span class="number">33.58646028142657</span>],[<span class="number">130.3598910690824</span>,<span class="number">33.58660747765104</span>],[<span class="number">130.3587999176402</span>,<span class="number">33.586851012683525</span>],[<span class="number">130.35774529391998</span>,<span class="number">33.58718821910479</span>],[<span class="number">130.35673874973867</span>,<span class="number">33.58761540348344</span>],[<span class="number">130.3557913107416</span>,<span class="number">33.58812788679505</span>],[<span class="number">130.35491335570208</span>,<span class="number">33.58872005562991</span>],[<span class="number">130.35411450287774</span>,<span class="number">33.5893854236307</span>],[<span class="number">130.35340350466618</span>,<span class="number">33.59011670248989</span>],[<span class="number">130.35278815171174</span>,<span class="number">33.59090588173187</span>],[<span class="number">130.35227518751492</span>,<span class="number">33.59174431640888</span>],[<span class="number">130.35187023448083</span>,<span class="number">33.59262282175287</span>],[<span class="number">130.35157773222005</span>,<span class="number">33.593531773748936</span>],[<span class="number">130.35140088878265</span>,<span class="number">33.59446121453118</span>],[<span class="number">130.35134164536413</span>,<span class="number">33.59540096144804</span>],[<span class="number">130.3514006548776</span>,<span class="number">33.596340718603905</span>],[<span class="number">130.35157727463277</span>,<span class="number">33.5972701896556</span>],[<span class="number">130.35186957321002</span>,<span class="number">33.598179190628684</span>],[<span class="number">130.35227435146135</span>,<span class="number">33.59905776151671</span>],[<span class="number">130.35278717741488</span>,<span class="number">33.59989627544021</span>],[<span class="number">130.35340243470753</span>,<span class="number">33.600685544167646</span>],[<span class="number">130.35411338401966</span>,<span class="number">33.60141691884032</span>],[<span class="number">130.35491223684397</span>,<span class="number">33.60208238479515</span>],[<span class="number">130.35579024078297</span>,<span class="number">33.602674649443514</span>],[<span class="number">130.35673777544181</span>,<span class="number">33.603187222240585</span>],[<span class="number">130.35774445786635</span>,<span class="number">33.60361448586572</span>],[<span class="number">130.3587992563694</span>,<span class="number">33.60395175783102</span>],[<span class="number">130.3598906114951</span>,<span class="number">33.60419534184053</span>],[<span class="number">130.361006562792</span>,<span class="number">33.60434256833447</span>],[<span class="number">130.36213488</span>,<span class="number">33.60439182377266</span>]]]&#125;&#125;]&#125;</span><br></pre></td></tr></table></figure><p>　GeoJSONを<a href="http://geojson.io/">geojson.io</a>のエディタに貼り付けるか、<a href="https://github.com/mapbox/geojsonio-cli">geojsonio-cli</a>にパイプするブラウザでgeojson.ioのページが直接開きます。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ npm start</span><br></pre></td></tr></table></figure><p>　ヤフオクドームのポイントを中心に半径500メートルのポリンゴンが描画されました。</p><p><img src="/2017/08/04/yahoo-geocoder-turfjs-polygon/polygon.png" alt="polygon.png"></p>]]></content:encoded>
      
      <comments>https://masato.github.io/2017/08/04/yahoo-geocoder-turfjs-polygon/#disqus_thread</comments>
    </item>
    
    <item>
      <title>KafkaからTreasure DataにブリッジするDocker Compose</title>
      <link>https://masato.github.io/2017/08/02/kafka-treasuredata-bridge-docker-compose/</link>
      <guid>https://masato.github.io/2017/08/02/kafka-treasuredata-bridge-docker-compose/</guid>
      <pubDate>Wed, 02 Aug 2017 03:24:03 GMT</pubDate>
      <description>
      
        td-agentコンテナとKafka Consumerコンテナを使いKafkaからTreasure DataへブリッジするDocker Composeサービスを起動します。別のポストではPySpark Streamingのウィンドウ集計した結果をKafkaのトピックに出力するコードを書きました。このストリーム処理はデータパイプラインの前処理やエンリッチメントに相当します。後続にビッグデータのバッチ処理を想定してTreasure Dataに保存します。
      
      </description>
      
      
      <content:encoded><![CDATA[<p>　td-agentコンテナとKafka Consumerコンテナを使いKafkaから<a href="https://www.treasuredata.co.jp/">Treasure Data</a>へブリッジするDocker Composeサービスを起動します。<a href="https://masato.github.io/2017/08/02/sensortag-kafka-python-spark-streaming-6/">別のポスト</a>ではPySpark Streamingのウィンドウ集計した結果をKafkaのトピックに出力するコードを書きました。このストリーム処理はデータパイプラインの前処理やエンリッチメントに相当します。後続にビッグデータのバッチ処理を想定してTreasure Dataに保存します。</p><span id="more"></span><h2 id="Docker-Compose"><a href="#Docker-Compose" class="headerlink" title="Docker Compose"></a>Docker Compose</h2><p>　最初に今回作成するプロジェクトのディレクトリ構成です。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ tree -a</span><br><span class="line">.</span><br><span class="line">├── docker-compose.yml</span><br><span class="line">├── .env</span><br><span class="line">├── .gitignore</span><br><span class="line">├── kafka-bridge</span><br><span class="line">│   ├── Dockerfile</span><br><span class="line">│   ├── fluentd-consumer.properties</span><br><span class="line">│   └── log4j.properties</span><br><span class="line">└── td-agent2</span><br><span class="line">    ├── Dockerfile</span><br><span class="line">    └── td-agent.conf</span><br><span class="line"></span><br><span class="line">2 directories, 9 files</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="docker-compose-yml"><a href="#docker-compose-yml" class="headerlink" title="docker-compose.yml"></a>docker-compose.yml</h3><p>　td-agentとKafka ConsumerサービスはそれぞれDockefileを書いてビルドします。Kafkaは<a href="https://hub.docker.com/r/landoop/fast-data-dev/">landoop/fast-data-dev</a>を利用します。<a href="https://www.confluent.io/product/confluent-open-source/">Confluent Open Source</a>を同梱しているためKafkaとZooKeeperも起動します。</p><figure class="highlight yaml"><figcaption><span>docker-compose.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;2&#x27;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">kafka-stack:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">landoop/fast-data-dev</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">FORWARDLOGS=0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">RUNTESTS=0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ADV_HOST=&lt;仮想マシンのパブリックIPアドレス&gt;</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">3030</span><span class="string">:3030</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">9092</span><span class="string">:9092</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">2181</span><span class="string">:2181</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">8081</span><span class="string">:8081</span></span><br><span class="line">  <span class="attr">td-agent2:</span></span><br><span class="line">    <span class="attr">build:</span> <span class="string">./td-agent2</span></span><br><span class="line">    <span class="attr">env_file:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./.env</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">24224</span><span class="string">:24224</span></span><br><span class="line">  <span class="attr">kafka-bridge:</span></span><br><span class="line">    <span class="attr">build:</span> <span class="string">./kafka-bridge</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">td-agent</span></span><br></pre></td></tr></table></figure><h3 id="env"><a href="#env" class="headerlink" title=".env"></a>.env</h3><p>　Treasure Dataの接続情報は環境変数ファイルの<code>.env</code>に記述しDocker Composeから読み込みます。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TD_API_KEY&#x3D;&lt;YOUR API KEY&gt;</span><br><span class="line">TD_ENDPOINT&#x3D;&lt;TD ENDPOINT&gt;</span><br></pre></td></tr></table></figure><h2 id="td-agent2"><a href="#td-agent2" class="headerlink" title="td-agent2"></a>td-agent2</h2><p>　td-agentのDockerイメージを作成します。</p><h3 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a>Dockerfile</h3><p>　<a href="https://docs.treasuredata.com/articles/td-agent">Overview of Server-Side Agent (td-agent)</a>のインストール手順に従います。<a href="https://toolbelt.treasuredata.com/sh/install-ubuntu-xenial-td-agent2.sh">install-ubuntu-xenial-td-agent2.sh</a>の中ではsudoも必要です。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM ubuntu:xenial</span><br><span class="line"></span><br><span class="line">RUN apt-get update &amp;&amp; apt-get install sudo curl -y</span><br><span class="line">RUN curl -L https:&#x2F;&#x2F;toolbelt.treasuredata.com&#x2F;sh&#x2F;install-ubuntu-xenial-td-agent2.sh | sh</span><br><span class="line">RUN apt-get clean &amp;&amp; rm -rf &#x2F;var&#x2F;lib&#x2F;apt&#x2F;lists&#x2F;* &#x2F;tmp&#x2F;* &#x2F;var&#x2F;tmp&#x2F;*</span><br><span class="line"></span><br><span class="line">ADD td-agent.conf &#x2F;etc&#x2F;td-agent&#x2F;</span><br><span class="line">EXPOSE 24224</span><br><span class="line">CMD [&quot;&#x2F;usr&#x2F;sbin&#x2F;td-agent&quot;]</span><br></pre></td></tr></table></figure><h3 id="td-agent-conf"><a href="#td-agent-conf" class="headerlink" title="td-agent.conf"></a>td-agent.conf</h3><p>　td-agent.confは環境変数を<a href="https://docs.fluentd.org/v0.12/articles/faq#how-can-i-use-environment-variables-to-configure-parameters-dynamically">参照</a>することができます。Treasure Dataへの接続情報を<code>.env</code>ファイルから取得します。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;match td.*.*&gt;</span><br><span class="line">  @type tdlog</span><br><span class="line">  endpoint &quot;#&#123;ENV[&#39;TD_ENDPOINT&#39;]&#125;&quot;</span><br><span class="line">  apikey &quot;#&#123;ENV[&#39;TD_API_KEY&#39;]&#125;&quot;</span><br><span class="line">  auto_create_table</span><br><span class="line">  buffer_type file</span><br><span class="line">  buffer_path &#x2F;var&#x2F;log&#x2F;td-agent&#x2F;buffer&#x2F;td</span><br><span class="line">  use_ssl true</span><br><span class="line">  num_threads 8</span><br><span class="line">&lt;&#x2F;match&gt;</span><br><span class="line"></span><br><span class="line">&lt;source&gt;</span><br><span class="line">  @type forward</span><br><span class="line">&lt;&#x2F;source&gt;</span><br></pre></td></tr></table></figure><h2 id="kafka-fluentd-consumer"><a href="#kafka-fluentd-consumer" class="headerlink" title="kafka-fluentd-consumer"></a>kafka-fluentd-consumer</h2><p>　KafkaからTreasure Dataへのブリッジには<a href="https://github.com/treasure-data/kafka-fluentd-consumer">kafka-fluentd-consumer</a>のJarを利用します。</p><h3 id="Dockerfile-1"><a href="#Dockerfile-1" class="headerlink" title="Dockerfile"></a>Dockerfile</h3><p> コンパイル済の<a href="https://github.com/treasure-data/kafka-fluentd-consumer/releases/download/v0.3.1/kafka-fluentd-consumer-0.3.1-all.jar">kafka-fluentd-consumer-0.3.1-all.jar</a>をダウンロードします。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM java:8-jre</span><br><span class="line">ARG KAFKA_FLUENTD_CONSUMER_VERSION&#x3D;0.3.1</span><br><span class="line"></span><br><span class="line">WORKDIR &#x2F;app</span><br><span class="line"></span><br><span class="line">RUN wget -q -O kafka-fluentd-consumer-all.jar https:&#x2F;&#x2F;github.com&#x2F;treasure-data&#x2F;kafka-fluentd-consumer&#x2F;releases&#x2F;download&#x2F;v$KAFKA_FLUENTD_CONSUMER_VERSION&#x2F;kafka-fluentd-consumer-$KAFKA_FLUENTD_CONSUMER_VERSION-all.jar</span><br><span class="line"></span><br><span class="line">ADD log4j.properties .</span><br><span class="line">ADD fluentd-consumer.properties .</span><br><span class="line"></span><br><span class="line">CMD [&quot;java&quot;, &quot;-Dlog4j.configuration&#x3D;file:&#x2F;&#x2F;&#x2F;app&#x2F;log4j.properties&quot;, &quot;-jar&quot;, &quot;kafka-fluentd-consumer-all.jar&quot;, &quot;fluentd-consumer.properties&quot;]</span><br></pre></td></tr></table></figure><h3 id="fluentd-consumer-properties"><a href="#fluentd-consumer-properties" class="headerlink" title="fluentd-consumer.properties"></a>fluentd-consumer.properties</h3><p>　<a href="https://github.com/treasure-data/kafka-fluentd-consumer/blob/master/config/fluentd-consumer.properties">デフォルト</a>の設定から以下を変更します。<code>fluentd.connect</code>と<code>zookeeper.connect</code>はdocker-compose.ymlを使う場合はそれぞれサービス名を指定します。</p><ul><li>fluentd.connect=&lt;td-agentのホスト名&gt;:24224</li><li>fluentd.tag.prefix=td.&lt;データベース名&gt;.</li><li>fluentd.consumer.topics=&lt;トピック名&gt;</li><li>zookeeper.connect=&lt;ZooKeeperのホスト名&gt;:2181</li><li>group.id=&lt;コンシューマグループ名&gt;</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Fluentd instance destinations.</span><br><span class="line">fluentd.connect&#x3D;td-agent2:24224</span><br><span class="line"></span><br><span class="line"># Dynamic event tag with topic name. </span><br><span class="line">fluentd.tag.prefix&#x3D;td.sensortag_dev.</span><br><span class="line"></span><br><span class="line"># Consumed topics. </span><br><span class="line">fluentd.consumer.topics&#x3D;sensortag-sink</span><br><span class="line"></span><br><span class="line"># The number of threads per consumer streams</span><br><span class="line">fluentd.consumer.threads&#x3D;1</span><br><span class="line"></span><br><span class="line"># The path for backup un-flushed events during shutdown.</span><br><span class="line">fluentd.consumer.backup.dir&#x3D;&#x2F;tmp&#x2F;fluentd-consumer-backup&#x2F;</span><br><span class="line"></span><br><span class="line"># Kafka Consumer related parameters</span><br><span class="line">zookeeper.connect&#x3D;kafka-stack:2181</span><br><span class="line">group.id&#x3D;my-sensortag-sink-group</span><br><span class="line">zookeeper.session.timeout.ms&#x3D;400</span><br><span class="line">zookeeper.sync.time.ms&#x3D;200</span><br><span class="line">auto.commit.interval.ms&#x3D;1000</span><br></pre></td></tr></table></figure><h3 id="log4j-properties"><a href="#log4j-properties" class="headerlink" title="log4j.properties"></a>log4j.properties</h3><p>　<a href="https://github.com/treasure-data/kafka-fluentd-consumer/blob/master/config/log4j.properties">log4j.properties</a>はデフォルトのまま使います。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># log4j logging configuration.</span><br><span class="line"># This is based on Pinterest&#39;s secor</span><br><span class="line"></span><br><span class="line"># root logger.</span><br><span class="line">log4j.rootLogger&#x3D;DEBUG, ROLLINGFILE</span><br><span class="line"></span><br><span class="line">log4j.appender.ROLLINGFILE &#x3D; org.apache.log4j.RollingFileAppender</span><br><span class="line">log4j.appender.ROLLINGFILE.Threshold&#x3D;INFO</span><br><span class="line">log4j.appender.ROLLINGFILE.File&#x3D;&#x2F;tmp&#x2F;fluentd-consumer.log</span><br><span class="line"># keep log files up to 1G</span><br><span class="line">log4j.appender.ROLLINGFILE.MaxFileSize&#x3D;20MB</span><br><span class="line">log4j.appender.ROLLINGFILE.MaxBackupIndex&#x3D;50</span><br><span class="line">log4j.appender.ROLLINGFILE.layout&#x3D;org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.ROLLINGFILE.layout.ConversionPattern&#x3D;%d&#123;ISO8601&#125; [%t] (%C:%L) %-5p %m%n</span><br></pre></td></tr></table></figure><h2 id="動作確認"><a href="#動作確認" class="headerlink" title="動作確認"></a>動作確認</h2><p>　Docker Composeのサービスを起動します。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker-compose up -d</span><br></pre></td></tr></table></figure><p>　td-agentのバージョンを確認します。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker-compose <span class="built_in">exec</span> td-agent2 td-agent --version</span><br><span class="line">td-agent 0.12.35</span><br></pre></td></tr></table></figure><p>　Spark Streamingを使ったウィンドウ集計の<a href="https://masato.github.io/2017/08/02/sensortag-kafka-python-spark-streaming-6/">サンプル</a>のように<code>fluentd.consumer.topics</code>に指定したtopicへJSONフォーマットでデータを送信します。</p><p>　テストとして<code>kafka-console-producer</code>から直接JSONを送信してみます。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker-compose <span class="built_in">exec</span> kafka-stack kafka-console-producer \</span><br><span class="line">    --broker-list localhost:9092 \</span><br><span class="line">    --topic sensortag-sink</span><br></pre></td></tr></table></figure><p>　コマンドを実行後の待機状態でJSON文字列を入力します。</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;<span class="attr">&quot;bid&quot;</span>: <span class="string">&quot;B0:B4:48:BD:DA:03&quot;</span>, <span class="attr">&quot;time&quot;</span>: <span class="number">1501654353</span>, <span class="attr">&quot;humidity&quot;</span>: <span class="number">27.152099609375</span>, <span class="attr">&quot;objecttemp&quot;</span>: <span class="number">21.6875</span>, <span class="attr">&quot;ambient&quot;</span>: <span class="number">27.09375</span>, <span class="attr">&quot;rh&quot;</span>: <span class="number">78.4423828125</span>&#125;</span><br></pre></td></tr></table></figure><p>　td-agentはファイルバッファを作成してデフォルトでは5分間隔でTreasure Dataへデータがアップロードします。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker-compose <span class="built_in">exec</span> td-agent2 ls /var/<span class="built_in">log</span>/td-agent/buffer</span><br><span class="line">td.sensortag_dev.sensortag_sink.b555bf24951c65554.log</span><br></pre></td></tr></table></figure><p><img src="/2017/08/02/kafka-treasuredata-bridge-docker-compose/treasuredata.png" alt="treasuredata.png"></p>]]></content:encoded>
      
      <comments>https://masato.github.io/2017/08/02/kafka-treasuredata-bridge-docker-compose/#disqus_thread</comments>
    </item>
    
    <item>
      <title>PythonとSensorTag, Kafka, Spark Streamingのストリーム処理 - Part 6: JupyterからPySpark Streamingのウィンドウ集計をする</title>
      <link>https://masato.github.io/2017/08/02/sensortag-kafka-python-spark-streaming-6/</link>
      <guid>https://masato.github.io/2017/08/02/sensortag-kafka-python-spark-streaming-6/</guid>
      <pubDate>Tue, 01 Aug 2017 23:01:51 GMT</pubDate>
      <description>
      
        ようやくタイトルのコードを実行する準備ができました。SensorTagのデータをKafkaに送信してPySpark Streamingのウィンドウ集計をします。JupyterをPythonのインタラクティブな実行環境に使います。
      
      </description>
      
      
      <content:encoded><![CDATA[<p>　ようやくタイトルのコードを実行する準備ができました。SensorTagのデータをKafkaに送信してPySpark Streamingのウィンドウ集計します。JupyterをPythonのインタラクティブな実行環境に使います。</p><span id="more"></span><h2 id="準備"><a href="#準備" class="headerlink" title="準備"></a>準備</h2><p>　これまでに用意したPythonスクリプトとKafka、Sparkのクラスタを使います。</p><ul><li><a href="https://masato.github.io/2017/07/28/sensortag-kafka-python-spark-streaming-2/">Part 2</a>で書いたRaspberry Pi 3からSensorTagのデータをJSONフォーマットでKafkaに送信するスクリプトと<a href="https://www.confluent.io/product/confluent-open-source/">Confluent Open Source</a>クラスタ</li><li><a href="https://masato.github.io/2017/08/01/sensortag-kafka-python-spark-streaming-5/">Part 5</a>で構築した<a href="https://spark.apache.org/docs/2.1.1/spark-standalone.html">Spark Standalone Cluster</a>と<a href="http://jupyter.org/">Jupyter</a></li></ul><h2 id="Notebook"><a href="#Notebook" class="headerlink" title="Notebook"></a>Notebook</h2><p>　JupyterのNotebookにインタラクティブにコードを実行して確認していきます。以下のパラグラフはそれぞれセルに相当します。WebブラウザからJupyterを開き右上の<code>New</code>ボタンから<code>Python 3</code>を選択します。</p><ul><li>http://&lt;仮想マシンのパブリックIPアドレス&gt;:8888</li></ul><h3 id="PYSPARK-SUBMIT-ARGS"><a href="#PYSPARK-SUBMIT-ARGS" class="headerlink" title="PYSPARK_SUBMIT_ARGS"></a>PYSPARK_SUBMIT_ARGS</h3><p>　ScalaのJarファイルはバージョンの指定がかなり厳密です。<a href="https://spark.apache.org/docs/2.1.1/streaming-kafka-integration.html">Spark Streaming + Kafka Integration Guide</a>によるとSpark StreamingからKafkaに接続するためのJarファイルは2つあります。Kafkaのバージョンが<code>0.8.2.1</code>以上の<a href="https://spark.apache.org/docs/2.1.1/streaming-kafka-0-8-integration.html">spark-streaming-kafka-0-8</a>と、<code>0.10</code>以上の<a href="https://spark.apache.org/docs/2.1.1/streaming-kafka-0-10-integration.html">spark-streaming-kafka-0-10</a>です。今回利用しているKafkaのバージョンは<code>0.10.2.1</code>ですがPythonをサポートしている<code>spark-streaming-kafka-0-8</code>を使います。</p><p>　パッケージ名はspark-streaming-kafka-<code>&lt;Kafkaのバージョン&gt;</code>_<code>&lt;Scalaのバージョン&gt;</code>:<code>&lt;Sparkのバージョン&gt;</code>のようにそれぞれのバージョンを表しています。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&#x27;PYSPARK_SUBMIT_ARGS&#x27;</span>] = <span class="string">&#x27;--packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.1.1 pyspark-shell&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="マジックコマンド"><a href="#マジックコマンド" class="headerlink" title="マジックコマンド"></a>マジックコマンド</h3><p>　<a href="https://github.com/dpkp/kafka-python">kafka-python</a>パッケージをインストールします。Jupyterの<a href="http://ipython.readthedocs.io/en/stable/interactive/magics.html">マジックコマンド</a>を使います。</p><figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">!pip <span class="keyword">install</span> kafka-python</span><br></pre></td></tr></table></figure><h3 id="import"><a href="#import" class="headerlink" title="import"></a>import</h3><p>　Spark StreamingとKafkaに必要なパッケージをimportします。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> pytz</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"><span class="keyword">from</span> pyspark.streaming <span class="keyword">import</span> StreamingContext</span><br><span class="line"><span class="keyword">from</span> pyspark.streaming.kafka <span class="keyword">import</span> KafkaUtils</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession, Row</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> kafka <span class="keyword">import</span> KafkaProducer</span><br></pre></td></tr></table></figure><h3 id="Sparkのコンテキスト"><a href="#Sparkのコンテキスト" class="headerlink" title="Sparkのコンテキスト"></a>Sparkのコンテキスト</h3><p>　Spark 2.xになってからSparkのコンテキストがわかりにくくなっていますが、SparkSession.builderをエントリポイントにします。StreamingContextは1分のバッチ間隔で作成します。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">spark = (</span><br><span class="line">    SparkSession</span><br><span class="line">        .builder</span><br><span class="line">        .getOrCreate()</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">sc = spark.sparkContext</span><br><span class="line">ssc = StreamingContext(sc, <span class="number">60</span>)</span><br></pre></td></tr></table></figure><h3 id="Kafka-Producer"><a href="#Kafka-Producer" class="headerlink" title="Kafka Producer"></a>Kafka Producer</h3><p> Kafkaブローカーのリスト、入力と出力のトピック名を定義します。ウインドウ集計した結果はKafkaのトピックに出力するためproducerも作成します。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">brokers = <span class="string">&quot;&lt;Kafka BrokerのIPアドレス&gt;:9092&quot;</span></span><br><span class="line">sourceTopic = <span class="string">&quot;sensortag&quot;</span></span><br><span class="line">sinkTopic = <span class="string">&quot;sensortag-sink&quot;</span></span><br><span class="line"></span><br><span class="line">producer = KafkaProducer(bootstrap_servers=brokers,</span><br><span class="line">                         value_serializer=<span class="keyword">lambda</span> v: json.dumps(v).encode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br></pre></td></tr></table></figure><h3 id="ウィンドウ集計"><a href="#ウィンドウ集計" class="headerlink" title="ウィンドウ集計"></a>ウィンドウ集計</h3><p>　今回のスクリプトのメインの処理をする関数です。KafkaのJSONを変換したRDDにStructTypeのスキーマを適用してDataFrameを作成します。DataFrameのウインドウ集計関数を使い2分ウインドウで周囲温度(ambient)と湿度(rh)の平均値を計算します。</p><p>　またDataFrameは処理の途中でタイムゾーンを削除しているためウィンドウ集計の結果がわかりやすいように<code>Asia/Tokyo</code>タイムゾーンをつけています。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">windowAverage</span>(<span class="params">rdd</span>):</span></span><br><span class="line">    schema = StructType([</span><br><span class="line">        StructField(<span class="string">&#x27;ambient&#x27;</span>, DoubleType(), <span class="literal">True</span>),</span><br><span class="line">        StructField(<span class="string">&#x27;bid&#x27;</span>, StringType(), <span class="literal">True</span>),</span><br><span class="line">        StructField(<span class="string">&#x27;humidity&#x27;</span>, DoubleType(), <span class="literal">True</span>),</span><br><span class="line">        StructField(<span class="string">&#x27;objecttemp&#x27;</span>, DoubleType(), <span class="literal">True</span>),</span><br><span class="line">        StructField(<span class="string">&#x27;rh&#x27;</span>, DoubleType(), <span class="literal">True</span>),</span><br><span class="line">        StructField(<span class="string">&#x27;time&#x27;</span>, TimestampType(), <span class="literal">True</span>),</span><br><span class="line">    ])</span><br><span class="line">        </span><br><span class="line">    streamingInputDF = spark.createDataFrame(</span><br><span class="line">        rdd, schema=schema</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&#x27;1分バッチのDataFrame&#x27;</span>)</span><br><span class="line">    streamingInputDF.show(truncate=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    averageDF = (</span><br><span class="line">        streamingInputDF</span><br><span class="line">            .groupBy(</span><br><span class="line">                streamingInputDF.bid,</span><br><span class="line">                window(<span class="string">&quot;time&quot;</span>, <span class="string">&quot;2 minute&quot;</span>))</span><br><span class="line">            .avg(<span class="string">&quot;ambient&quot;</span>,<span class="string">&quot;rh&quot;</span>)   </span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    sinkRDD = averageDF.rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: &#123;<span class="string">&#x27;bid&#x27;</span>: x[<span class="number">0</span>], </span><br><span class="line">                                            <span class="string">&#x27;time&#x27;</span>: pytz.utc.localize(x[<span class="number">1</span>][<span class="string">&#x27;end&#x27;</span>]).astimezone(pytz.timezone(<span class="string">&#x27;Asia/Tokyo&#x27;</span>)).isoformat(), </span><br><span class="line">                                            <span class="string">&#x27;ambient&#x27;</span>: x[<span class="number">2</span>], </span><br><span class="line">                                            <span class="string">&#x27;rh&#x27;</span>: x[<span class="number">3</span>]&#125;)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> sinkRDD.isEmpty():</span><br><span class="line">        print(<span class="string">&#x27;2分ウィンドウの平均値&#x27;</span>)</span><br><span class="line">        sinkList = sinkRDD.collect()</span><br><span class="line">        print(sinkList)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> sink <span class="keyword">in</span> sinkList:</span><br><span class="line">            producer.send(sinkTopic, sink)</span><br></pre></td></tr></table></figure><h3 id="Kafkaのストリーム作成"><a href="#Kafkaのストリーム作成" class="headerlink" title="Kafkaのストリーム作成"></a>Kafkaのストリーム作成</h3><p>　Kafka BrokerのIPアドレスとRaspberry Pi 3からSensorTagのJSON文字列を送信するトピックを指定します。JSON文字列を1行ずつデシリアライズして<a href="http://spark.apache.org/docs/2.1.1/api/python/pyspark.sql.html#pyspark.sql.Row">pyspark.sql.Row</a>を作成します。<code>time</code>フィールドはUNIXタイムスタンプからPythonのdatetimeに変換しタイムゾーンを削除します。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">kafkaStream = KafkaUtils.createDirectStream(</span><br><span class="line">    ssc, [sourceTopic], &#123;<span class="string">&quot;metadata.broker.list&quot;</span>:brokers&#125;)</span><br><span class="line"></span><br><span class="line">rowStream = (</span><br><span class="line">    kafkaStream</span><br><span class="line">        .<span class="built_in">map</span>(<span class="keyword">lambda</span> line: json.loads(line[<span class="number">1</span>]))</span><br><span class="line">        .<span class="built_in">map</span>(<span class="keyword">lambda</span> x: Row(</span><br><span class="line">            ambient=x[<span class="string">&#x27;ambient&#x27;</span>],</span><br><span class="line">            bid=x[<span class="string">&#x27;bid&#x27;</span>],</span><br><span class="line">            humidity=x[<span class="string">&#x27;humidity&#x27;</span>],</span><br><span class="line">            objecttemp=x[<span class="string">&#x27;objecttemp&#x27;</span>],</span><br><span class="line">            rh=x[<span class="string">&#x27;rh&#x27;</span>],</span><br><span class="line">            time=datetime.fromtimestamp(x[<span class="string">&#x27;time&#x27;</span>]).replace(tzinfo=<span class="literal">None</span>),</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">rowStream.foreachRDD(windowAverage)</span><br></pre></td></tr></table></figure><h3 id="StreamingContextの開始"><a href="#StreamingContextの開始" class="headerlink" title="StreamingContextの開始"></a>StreamingContextの開始</h3><p>　最後にStreamingContextを開始してプログラムが停止するまで待機します。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ssc.start()</span><br><span class="line">ssc.awaitTermination()</span><br></pre></td></tr></table></figure><h2 id="スクリプトの実行"><a href="#スクリプトの実行" class="headerlink" title="スクリプトの実行"></a>スクリプトの実行</h2><p> Raspberry Pi 3から<a href="https://masato.github.io/2017/07/28/sensortag-kafka-python-spark-streaming-2/">Part 2</a>で書いたPythonスクリプトを実行します。</p><h3 id="出力結果"><a href="#出力結果" class="headerlink" title="出力結果"></a>出力結果</h3><p>　以下の様な出力が表示されます。DataFrameの出力ではタイムゾーンがないのに対し、ウィンドウ集計の結果にはタイムゾーンが付与されています。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">1分バッチのDataFrame</span><br><span class="line">+--------+-----------------+-----------------+----------+---------------+---------------------+</span><br><span class="line">|ambient |bid              |humidity         |objecttemp|rh             |time                 |</span><br><span class="line">+--------+-----------------+-----------------+----------+---------------+---------------------+</span><br><span class="line">|28.78125|B0:B4:48:BD:DA:03|28.72314453125   |22.96875  |75.714111328125|2017-08-01 23:44:03.0|</span><br><span class="line">|28.78125|B0:B4:48:BD:DA:03|28.72314453125   |22.90625  |75.714111328125|2017-08-01 23:44:13.0|</span><br><span class="line">|28.75   |B0:B4:48:BD:DA:03|28.72314453125   |22.875    |75.616455078125|2017-08-01 23:44:23.0|</span><br><span class="line">|28.75   |B0:B4:48:BD:DA:03|28.69293212890625|23.15625  |75.616455078125|2017-08-01 23:44:34.0|</span><br><span class="line">|28.75   |B0:B4:48:BD:DA:03|28.7030029296875 |23.03125  |75.616455078125|2017-08-01 23:44:44.0|</span><br><span class="line">|28.75   |B0:B4:48:BD:DA:03|28.69293212890625|23.125    |75.616455078125|2017-08-01 23:44:55.0|</span><br><span class="line">+--------+-----------------+-----------------+----------+---------------+---------------------+</span><br><span class="line"></span><br><span class="line">2分ウィンドウの平均値</span><br><span class="line">[&#123;<span class="string">&#x27;bid&#x27;</span>: <span class="string">&#x27;B0:B4:48:BD:DA:03&#x27;</span>, <span class="string">&#x27;time&#x27;</span>: <span class="string">&#x27;2017-08-02T08:46:00+09:00&#x27;</span>, <span class="string">&#x27;ambient&#x27;</span>: 28.760416666666668, <span class="string">&#x27;rh&#x27;</span>: 75.64900716145833&#125;]</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      <comments>https://masato.github.io/2017/08/02/sensortag-kafka-python-spark-streaming-6/#disqus_thread</comments>
    </item>
    
    <item>
      <title>PythonとSensorTag, Kafka, Spark Streamingのストリーム処理 - Part 5: Apache Toree でJupyterからSparkに接続する</title>
      <link>https://masato.github.io/2017/08/01/sensortag-kafka-python-spark-streaming-5/</link>
      <guid>https://masato.github.io/2017/08/01/sensortag-kafka-python-spark-streaming-5/</guid>
      <pubDate>Tue, 01 Aug 2017 00:05:19 GMT</pubDate>
      <description>
      
        Sparkクラスタを用意していくつかサンプルコードを書いていこうと思います。Pythonのデータ分析や機械学習の実行環境としてJupyterは多くの方が利用していると思います。Apache ToreeでSparkアプリも同じようにJupyterからインタラクティブに書くことが目的です。ブラウザから実行できるScalaのREPLしてもJupyterを使うことができます。
      
      </description>
      
      
      <content:encoded><![CDATA[<p>　Sparkクラスタを用意していくつかサンプルコードを書いていこうと思います。Pythonのデータ分析や機械学習の実行環境としてJupyterは多くの方が利用していると思います。<a href="https://toree.apache.org/">Apache Toree</a>でSparkアプリも同じようにJupyterからインタラクティブに書くことが目的です。ブラウザから実行できるScalaのREPLしてもJupyterを使うことができます。</p><span id="more"></span><h2 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h2><p>　SparkクラスタをDocker Composeで構築します。Docker HubとGitHubに多くのSpark Standalone Cluster用のイメージとdocker-compose.ymlが公開されています。</p><ul><li><a href="https://github.com/Semantive/docker-spark">semantive/spark</a></li><li><a href="https://github.com/maltefiala/docker--jupyter-pyspark">produktion/jupyter-pyspark</a></li><li><a href="https://github.com/gettyimages/docker-spark/">gettyimages/docker-spark</a></li></ul><p>　いくつか試しましたが<a href="https://github.com/Semantive/docker-spark">semantive/spark</a>がシンプルで使いやすい印象です。</p><h3 id="Docker-Compose"><a href="#Docker-Compose" class="headerlink" title="Docker Compose"></a>Docker Compose</h3><p>　<code>semantive/spark</code>イメージの使い方は<a href="http://semantive.com/docker-images-for-apache-spark/">Docker Images For Apache Spark</a>に書いてあります。Docker Hubは<a href="https://hub.docker.com/r/semantive/spark/">こちら</a>、GitHubは<a href="https://github.com/Semantive/docker-spark">こちら</a>になります。</p><p>　リポジトリにある<a href="https://github.com/Semantive/docker-spark/blob/master/docker-compose.yml">docker-compose.yml</a>からいくつか変更しました。主な変更点はSparkのバージョンを合わせるためイメージタグを明示的に指定する、<code>SPARK_PUBLIC_DNS</code>と<code>SPARK_MASTER_HOST</code>環境変数にクラウド上の仮想マシンのパブリックIPアドレスを指定することです。</p><figure class="highlight yaml"><figcaption><span>docker-compose.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;2&#x27;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">master:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">semantive/spark:spark-2.1.1-hadoop-2.7.3</span></span><br><span class="line">    <span class="attr">command:</span> <span class="string">bin/spark-class</span> <span class="string">org.apache.spark.deploy.master.Master</span> <span class="string">-h</span> <span class="string">master</span></span><br><span class="line">    <span class="attr">hostname:</span> <span class="string">master</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">MASTER:</span> <span class="string">spark://master:7077</span></span><br><span class="line">      <span class="attr">SPARK_CONF_DIR:</span> <span class="string">/conf</span></span><br><span class="line">      <span class="attr">SPARK_PUBLIC_DNS:</span> <span class="string">&lt;仮想マシンのパブリックIPアドレス&gt;</span></span><br><span class="line">      <span class="attr">SPARK_MASTER_HOST:</span> <span class="string">&lt;仮想マシンのパブリックIPアドレス&gt;</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">4040</span><span class="string">:4040</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">6066</span><span class="string">:6066</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">7077</span><span class="string">:7077</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">8080</span><span class="string">:8080</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">spark_data:/tmp/data</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">worker1:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">semantive/spark:spark-2.1.1-hadoop-2.7.3</span></span><br><span class="line">    <span class="attr">command:</span> <span class="string">bin/spark-class</span> <span class="string">org.apache.spark.deploy.worker.Worker</span> <span class="string">spark://master:7077</span></span><br><span class="line">    <span class="attr">hostname:</span> <span class="string">worker1</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">SPARK_CONF_DIR:</span> <span class="string">/conf</span></span><br><span class="line">      <span class="attr">SPARK_WORKER_CORES:</span> <span class="number">4</span></span><br><span class="line">      <span class="attr">SPARK_WORKER_MEMORY:</span> <span class="string">2g</span></span><br><span class="line">      <span class="attr">SPARK_WORKER_PORT:</span> <span class="number">8881</span></span><br><span class="line">      <span class="attr">SPARK_WORKER_WEBUI_PORT:</span> <span class="number">8081</span></span><br><span class="line">      <span class="attr">SPARK_PUBLIC_DNS:</span> <span class="string">&lt;仮想マシンのパブリックIPアドレス&gt;</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">master</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">8081</span><span class="string">:8081</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">spark_data:/tmp/data</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">worker2:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">semantive/spark:spark-2.1.1-hadoop-2.7.3</span></span><br><span class="line">    <span class="attr">command:</span> <span class="string">bin/spark-class</span> <span class="string">org.apache.spark.deploy.worker.Worker</span> <span class="string">spark://master:7077</span></span><br><span class="line">    <span class="attr">hostname:</span> <span class="string">worker2</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">SPARK_CONF_DIR:</span> <span class="string">/conf</span></span><br><span class="line">      <span class="attr">SPARK_WORKER_CORES:</span> <span class="number">4</span></span><br><span class="line">      <span class="attr">SPARK_WORKER_MEMORY:</span> <span class="string">2g</span></span><br><span class="line">      <span class="attr">SPARK_WORKER_PORT:</span> <span class="number">8882</span></span><br><span class="line">      <span class="attr">SPARK_WORKER_WEBUI_PORT:</span> <span class="number">8082</span></span><br><span class="line">      <span class="attr">SPARK_PUBLIC_DNS:</span> <span class="string">&lt;仮想マシンのパブリックIPアドレス&gt;</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">master</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">8082</span><span class="string">:8082</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">spark_data:/tmp/data</span></span><br><span class="line"></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line">  <span class="attr">spark_data:</span></span><br><span class="line">    <span class="attr">driver:</span> <span class="string">local</span></span><br></pre></td></tr></table></figure><p>　Spark Standalone Clusterを起動します。</p><figure class="highlight elixir"><table><tr><td class="code"><pre><span class="line"><span class="variable">$ </span>docker-compose up -d</span><br></pre></td></tr></table></figure><p>　Spark Master UIを開いてクラスタの状態を確認します。</p><ul><li>http://&lt;仮想マシンのパブリックIPアドレス&gt;:8080</li></ul><p>　Masterコンテナのspark-shellを実行してScalaとSparkのバージョンを確認します。Sparkは開発のスピードがとても速く、Scalaのバージョンも含めてよく確認しないと思わぬエラーに遭遇してしまいます。</p><ul><li>Scala: 2.11.8</li><li>Spark: 2.1.1</li></ul><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">$ docker-compose exec master spark-shell</span><br><span class="line">...</span><br><span class="line">Welcome to</span><br><span class="line">      ____              __</span><br><span class="line">     <span class="regexp">/ __/</span>__  ___ _____<span class="regexp">/ /</span>__</span><br><span class="line">    _\ \<span class="regexp">/ _ \/ _ `/</span> __<span class="regexp">/  &#x27;_/</span></span><br><span class="line">   <span class="regexp">/___/</span> .__<span class="regexp">/\_,_/</span>_<span class="regexp">/ /</span>_/\_\   version <span class="number">2.1</span>.<span class="number">1</span></span><br><span class="line">      <span class="regexp">/_/</span></span><br><span class="line"></span><br><span class="line">Using Scala version <span class="number">2.11</span>.<span class="number">8</span> (OpenJDK <span class="number">64</span>-Bit Server VM, Java <span class="number">1.8</span>.<span class="number">0</span>_131)</span><br><span class="line">Type <span class="keyword">in</span> expressions to have them evaluated.</span><br><span class="line">Type :help <span class="keyword">for</span> more information.</span><br><span class="line"></span><br><span class="line">scala&gt;</span><br></pre></td></tr></table></figure><h2 id="Jupyter"><a href="#Jupyter" class="headerlink" title="Jupyter"></a>Jupyter</h2><p>　JupyterのDockerイメージは公式の<a href="https://hub.docker.com/r/jupyter/all-spark-notebook/">jupyter/all-spark-notebook</a>を使います。ScalaやSparkまで使える全部入りのイメージです。</p><h3 id="Apache-Toree"><a href="#Apache-Toree" class="headerlink" title="Apache Toree"></a>Apache Toree</h3><p>　<a href="https://toree.apache.org/">Apache Toree</a>はSparkクラスタにJupyterから接続するためのツールです。PySparkに加え、Scala、SparkR、SQLのKernelが提供されます。</p><p>　<a href="https://github.com/jupyter/docker-stacks/blob/master/all-spark-notebook/Dockerfile">Dockerfile</a>を見るとApache Toreeもインストールされています。</p><figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Apache Toree kernel</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> pip --no-cache-dir install https://dist.apache.org/repos/dist/dev/incubator/toree/0.2.0/snapshots/dev1/toree-pip/toree-0.2.0.dev1.tar.gz</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> jupyter toree install --sys-prefix</span></span><br></pre></td></tr></table></figure><h3 id="docker-compose-yml"><a href="#docker-compose-yml" class="headerlink" title="docker-compose.yml"></a>docker-compose.yml</h3><p>　Spark Standalone Clusterのdocker-compose.ymlにJupyterサービスを追加します。</p><figure class="highlight yaml"><figcaption><span>docker-compose.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">jupyter:</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">jupyter/all-spark-notebook:c1b0cf6bf4d6</span></span><br><span class="line">  <span class="attr">depends_on:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">master</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="number">8888</span><span class="string">:8888</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">./notebooks:/home/jovyan/work</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">./ivy2:/home/jovyan/.ivy2</span></span><br><span class="line">  <span class="attr">env_file:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">./.env</span></span><br><span class="line">  <span class="attr">environment:</span></span><br><span class="line">    <span class="attr">TINI_SUBREAPER:</span> <span class="string">&#x27;true&#x27;</span></span><br><span class="line">    <span class="attr">SPARK_OPTS:</span> <span class="string">--master</span> <span class="string">spark://master:7077</span> <span class="string">--deploy-mode</span> <span class="string">client</span> <span class="string">--packages</span> <span class="string">com.amazonaws:aws-java-sdk:1.7.4,org.apache.hadoop:hadoop-aws:2.7.3</span></span><br><span class="line">  <span class="attr">command:</span> <span class="string">start-notebook.sh</span> <span class="string">--NotebookApp.password=sha1:xxx</span> <span class="string">--NotebookApp.iopub_data_rate_limit=10000000</span></span><br></pre></td></tr></table></figure><h2 id="Jupyterサービスのオプションについて"><a href="#Jupyterサービスのオプションについて" class="headerlink" title="Jupyterサービスのオプションについて"></a>Jupyterサービスのオプションについて</h2><p>　Spark Standalone ClusterではHadoopを利用していないため分散ファイルシステムにAmazon S3を利用する設定を追加しています。サンプルデータやParquetファイルの保存先にあると便利です。</p><h3 id="image"><a href="#image" class="headerlink" title="image"></a>image</h3><p>　<code>jupyter/all-spark-notebook</code>イメージは更新が頻繁に入ります。Apache Toreeで使うSparkとSparkクラスタのバージョンがエラーになり起動しなくなります。今回はSparkクラスタのバージョンは<code>2.1.1</code>なので同じバージョンのイメージのtagを指定します。<code>jupyter/all-spark-notebook</code>イメージのタグはIDしかわからないのが不便です。</p><p>　Sparkのバージョンはすでに<a href="https://github.com/jupyter/docker-stacks/commit/c740fbb1ca63db5856e004d29dd08d11fb4f91f8">2.2.0</a>へ上がっているため<code>2.1.1</code>のタグを指定します。</p><p>　タグのDockerイメージをpullして<code>spark-shell</code>で確認します。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker pull jupyter/all-spark-notebook:c1b0cf6bf4d6</span><br><span class="line">$ docker run -it --rm \</span><br><span class="line">  jupyter/all-spark-notebook:c1b0cf6bf4d6 \</span><br><span class="line">  /usr/<span class="built_in">local</span>/spark-2.1.1-bin-hadoop2.7/bin/spark-shell</span><br></pre></td></tr></table></figure><p>　SparkクラスタとSparkとScalaのバージョンが同じであることが確認できました。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Welcome to</span><br><span class="line">      ____              __</span><br><span class="line">     / __/__  ___ _____/ /__</span><br><span class="line">    _\ \/ _ \/ _ `/ __/  <span class="string">&#x27;_/</span></span><br><span class="line"><span class="string">   /___/ .__/\_,_/_/ /_/\_\   version 2.1.1</span></span><br><span class="line"><span class="string">      /_/</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Using Scala version 2.11.8 (OpenJDK 64-Bit Server VM, Java 1.8.0_131)</span></span><br><span class="line"><span class="string">Type in expressions to have them evaluated.</span></span><br><span class="line"><span class="string">Type :help for more information.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">scala&gt;</span></span><br></pre></td></tr></table></figure><p>　Jupyterのバージョンも確認しておきます。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker run -it --rm jupyter/all-spark-notebook:c1b0cf6bf4d6 jupyter --version</span><br><span class="line">4.3.0</span><br></pre></td></tr></table></figure><h3 id="TINI-SUBREAPERとSPARK-OPTS"><a href="#TINI-SUBREAPERとSPARK-OPTS" class="headerlink" title="TINI_SUBREAPERとSPARK_OPTS"></a>TINI_SUBREAPERとSPARK_OPTS</h3><p>　Apache Toreeを利用してJupyterからリモートのSparkに接続するために必須な設定はこの2つです。<code>TINI_SUBREAPER</code>環境変数はinitに<a href="https://github.com/krallin/tini">Tini</a>を使います。Sparkで追加のJarファイルを使わない場合は<code>SPARK_OPTS</code>環境変数に以下の指定だけでリモートのSpark Standalone Clusterに接続できます。通常のspark-submitのオプションと同じです。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">--master spark://master:7077 --deploy-mode client</span><br></pre></td></tr></table></figure><p>　追加のJarファイルがある場合はさらに<code>--packages</code>フラグを追加します。この場合はAmazon S3に接続するために必要なパッケージです。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">--packages com.amazonaws:aws-java-sdk:1.7.4,org.apache.hadoop:hadoop-aws:2.7.3</span><br></pre></td></tr></table></figure><h3 id="–NotebookApp-iopub-data-rate-limit"><a href="#–NotebookApp-iopub-data-rate-limit" class="headerlink" title="–NotebookApp.iopub_data_rate_limit"></a>–NotebookApp.iopub_data_rate_limit</h3><p>　<a href="http://bokeh.pydata.org/en/latest/">Bokeh</a>など可視化ツールで大きな画像イメージを扱う場合はJupyterの起動スクリプトのオプションを指定します。</p><ul><li><a href="https://stackoverflow.com/questions/43288550/iopub-data-rate-exceeded-when-viewing-image-in-jupyter-notebook">IOPub data rate exceeded when viewing image in Jupyter notebook</a></li></ul><h3 id="–NotebookApp-password"><a href="#–NotebookApp-password" class="headerlink" title="–NotebookApp.password"></a>–NotebookApp.password</h3><p>　Jupyterの認証方法はデフォルトはtokenです。Dockerコンテナのように頻繁に起動と破棄を繰り返す場合に毎回異なるtokenを入れるのは面倒なのでパスワード認証に変更しました。ipythonを使いパスワードのハッシュ値を取得します。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ docker run -it --rm jupyter/<span class="built_in">all</span>-spark-notebook:c1b0cf6bf4d6 ipython</span><br><span class="line">Python <span class="number">3.6</span><span class="number">.1</span> | packaged by conda-forge | (default, May <span class="number">23</span> <span class="number">2017</span>, <span class="number">14</span>:<span class="number">16</span>:<span class="number">20</span>)</span><br><span class="line">Type <span class="string">&#x27;copyright&#x27;</span>, <span class="string">&#x27;credits&#x27;</span> <span class="keyword">or</span> <span class="string">&#x27;license&#x27;</span> <span class="keyword">for</span> more information</span><br><span class="line">IPython <span class="number">6.1</span><span class="number">.0</span> -- An enhanced Interactive Python. Type <span class="string">&#x27;?&#x27;</span> <span class="keyword">for</span> <span class="built_in">help</span>.</span><br></pre></td></tr></table></figure><p>　パスワードは以下のように生成します。出力されたハッシュ値をJupyterの起動オプションに指定します。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">1</span>]: <span class="keyword">from</span> notebook.auth <span class="keyword">import</span> passwd</span><br><span class="line">In [<span class="number">2</span>]: passwd()</span><br><span class="line"></span><br><span class="line">Enter password:</span><br><span class="line">Verify password:</span><br><span class="line">Out[<span class="number">2</span>]: <span class="string">&#x27;sha1:xxx&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="volumes"><a href="#volumes" class="headerlink" title="volumes"></a>volumes</h3><p>　<code>/home/jovyan</code>はJupyterコンテナを実行しているユーザーのホームディレクトリです。作成したnotebookやダンロードしたJarファイルをDockerホストにマウントします。</p><h3 id="env-file"><a href="#env-file" class="headerlink" title="env_file"></a>env_file</h3><p>　<code>.env</code>ファイルに環境変数を記述してコンテナに渡します。Amazon S3への接続に使うaccess key と secret keyを指定します。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">AWS_ACCESS_KEY_ID=xxx</span><br><span class="line">AWS_SECRET_ACCESS_KEY=xxx</span><br></pre></td></tr></table></figure><p>　Gitにcommitしないように忘れずに.gitignoreにも追加します。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">.env</span><br></pre></td></tr></table></figure><h2 id="JupyterからSparkとAmazon-S3を使う"><a href="#JupyterからSparkとAmazon-S3を使う" class="headerlink" title="JupyterからSparkとAmazon S3を使う"></a>JupyterからSparkとAmazon S3を使う</h2><p>　JupyterでSparkとAmazon S3を使うサンプルをScalaとPythonで書いてみようと思います。<a href="https://dzone.com/articles/monitoring-real-time-uber-data-using-apache-apis-p">Monitoring Real-Time Uber Data Using Apache APIs, Part 1: Spark Machine Learning</a>の記事で利用しているUberのピックアップデータをサンプルに使います。ここでは単純にCSVファイルをS3から読み込んで表示するだけです。docker-compose.ymlに定義した全てのサービスを起動します。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker-compose up -d</span><br></pre></td></tr></table></figure><p>　Jupyterをブラウザで開きさきほど作成したパスワードでログインします。</p><ul><li>http://&lt;仮想マシンのパブリックIPアドレス&gt;:8888</li></ul><h3 id="データ準備"><a href="#データ準備" class="headerlink" title="データ準備"></a>データ準備</h3><p>　リポジトリをcloneしたあと<code>uber.csv</code>ファイルを<code>s3cmd</code>から適当なバケットにputします。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ git <span class="built_in">clone</span> https://github.com/caroljmcdonald/spark-ml-kmeans-uber</span><br><span class="line">$ <span class="built_in">cd</span> spark-ml-kmeans-uber/data</span><br><span class="line">$ s3cmd put uber.csv s3://&lt;バケット名&gt;/uber-csv/</span><br></pre></td></tr></table></figure><h3 id="Scala"><a href="#Scala" class="headerlink" title="Scala"></a>Scala</h3><p>　以下のようなコードを確認したいところでセルに分割してインタラクティブに実行することができます。ScalaのNotebookを書く場合は右上の<code>New</code>ボタンから<code>Apache Toree - Scala</code>を選択します。</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SparkSession</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> spark = <span class="type">SparkSession</span>.</span><br><span class="line">    builder.</span><br><span class="line">    getOrCreate()</span><br><span class="line"></span><br><span class="line">sc.hadoopConfiguration.set(<span class="string">&quot;fs.s3a.impl&quot;</span>, <span class="string">&quot;org.apache.hadoop.fs.s3a.S3AFileSystem&quot;</span>)</span><br><span class="line">sc.hadoopConfiguration.set(<span class="string">&quot;fs.s3a.fast.upload&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> schema = <span class="type">StructType</span>(</span><br><span class="line">    <span class="type">StructField</span>(<span class="string">&quot;dt&quot;</span>, <span class="type">TimestampType</span>, <span class="literal">true</span>) ::</span><br><span class="line">    <span class="type">StructField</span>(<span class="string">&quot;lat&quot;</span>, <span class="type">DoubleType</span>, <span class="literal">true</span>) ::</span><br><span class="line">    <span class="type">StructField</span>(<span class="string">&quot;lon&quot;</span>, <span class="type">DoubleType</span>, <span class="literal">true</span>) ::</span><br><span class="line">    <span class="type">StructField</span>(<span class="string">&quot;base&quot;</span>, <span class="type">StringType</span>, <span class="literal">true</span>) :: <span class="type">Nil</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> df = </span><br><span class="line">    spark.read.</span><br><span class="line">    option(<span class="string">&quot;header&quot;</span>, <span class="literal">false</span>).</span><br><span class="line">    schema(schema).</span><br><span class="line">    csv(<span class="string">&quot;s3a://&lt;バケット名&gt;/uber-csv/uber.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line">df.printSchema</span><br><span class="line"></span><br><span class="line">df.cache</span><br><span class="line">df.show(<span class="literal">false</span>)</span><br></pre></td></tr></table></figure><p>　Scalaの場合スキーマのStructTypeは次のようにも書くことができます。</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> schema = (<span class="keyword">new</span> <span class="type">StructType</span>).</span><br><span class="line">    add(<span class="string">&quot;dt&quot;</span>, <span class="string">&quot;timestamp&quot;</span>, <span class="literal">true</span>).</span><br><span class="line">    add(<span class="string">&quot;lat&quot;</span>, <span class="string">&quot;double&quot;</span>, <span class="literal">true</span>).</span><br><span class="line">    add(<span class="string">&quot;lon&quot;</span>, <span class="string">&quot;double&quot;</span>, <span class="literal">true</span>).</span><br><span class="line">    add(<span class="string">&quot;base&quot;</span>, <span class="string">&quot;string&quot;</span>, <span class="literal">true</span>)</span><br></pre></td></tr></table></figure><p>　最後の<code>df.show(false)</code>の出力結果です。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">+---------------------+-------+--------+------+</span><br><span class="line">|dt                   |lat    |lon     |base  |</span><br><span class="line">+---------------------+-------+--------+------+</span><br><span class="line">|2014-08-01 00:00:00.0|40.729 |-73.9422|B02598|</span><br><span class="line">|2014-08-01 00:00:00.0|40.7476|-73.9871|B02598|</span><br><span class="line">|2014-08-01 00:00:00.0|40.7424|-74.0044|B02598|</span><br><span class="line">|2014-08-01 00:00:00.0|40.751 |-73.9869|B02598|</span><br><span class="line">|2014-08-01 00:00:00.0|40.7406|-73.9902|B02598|</span><br><span class="line">|2014-08-01 00:00:00.0|40.6994|-73.9591|B02617|</span><br><span class="line">|2014-08-01 00:00:00.0|40.6917|-73.9398|B02617|</span><br><span class="line">|2014-08-01 00:00:00.0|40.7063|-73.9223|B02617|</span><br><span class="line">|2014-08-01 00:00:00.0|40.6759|-74.0168|B02617|</span><br><span class="line">|2014-08-01 00:00:00.0|40.7617|-73.9847|B02617|</span><br><span class="line">|2014-08-01 00:00:00.0|40.6969|-73.9064|B02617|</span><br><span class="line">|2014-08-01 00:00:00.0|40.7623|-73.9751|B02617|</span><br><span class="line">|2014-08-01 00:00:00.0|40.6982|-73.9669|B02617|</span><br><span class="line">|2014-08-01 00:00:00.0|40.7553|-73.9253|B02617|</span><br><span class="line">|2014-08-01 00:00:00.0|40.7325|-73.9876|B02682|</span><br><span class="line">|2014-08-01 00:00:00.0|40.6754|-74.017 |B02682|</span><br><span class="line">|2014-08-01 00:00:00.0|40.7303|-74.0029|B02682|</span><br><span class="line">|2014-08-01 00:00:00.0|40.7218|-73.9973|B02682|</span><br><span class="line">|2014-08-01 00:00:00.0|40.7134|-74.0091|B02682|</span><br><span class="line">|2014-08-01 00:00:00.0|40.7194|-73.9964|B02682|</span><br><span class="line">+---------------------+-------+--------+------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><h3 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h3><p>　Python 3のNotebookを書く場合は右上の<code>New</code>ボタンから<code>Python 3</code>を選択します。以下のコードを適当なところでセルに分割して実行していきます。Scalaと異なるのは追加Jarは<code>PYSPARK_SUBMIT_ARGS</code>環境変数に指定する点です。</p><p>　以下のようにPythonでもほぼScalaと同じようにでSparkアプリを書くことができます。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&#x27;PYSPARK_SUBMIT_ARGS&#x27;</span>] = <span class="string">&#x27;--packages com.amazonaws:aws-java-sdk:1.7.4,org.apache.hadoop:hadoop-aws:2.7.3 pyspark-shell&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = (</span><br><span class="line">    SparkSession.builder</span><br><span class="line">        .getOrCreate()</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">sc = spark.sparkContext</span><br><span class="line"></span><br><span class="line">sc._jsc.hadoopConfiguration().<span class="built_in">set</span>(<span class="string">&quot;fs.s3a.impl&quot;</span>, <span class="string">&quot;org.apache.hadoop.fs.s3a.S3AFileSystem&quot;</span>)</span><br><span class="line">sc._jsc.hadoopConfiguration().<span class="built_in">set</span>(<span class="string">&quot;fs.s3a.fast.upload&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">schema = StructType([</span><br><span class="line">    StructField(<span class="string">&quot;dt&quot;</span>, TimestampType(), <span class="literal">True</span>),</span><br><span class="line">    StructField(<span class="string">&quot;lat&quot;</span>, DoubleType(), <span class="literal">True</span>),</span><br><span class="line">    StructField(<span class="string">&quot;lon&quot;</span>, DoubleType(), <span class="literal">True</span>),</span><br><span class="line">    StructField(<span class="string">&quot;base&quot;</span>, StringType(), <span class="literal">True</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">df = (</span><br><span class="line">    spark.read</span><br><span class="line">    .option(<span class="string">&quot;header&quot;</span>, <span class="literal">False</span>)</span><br><span class="line">    .schema(schema)</span><br><span class="line">    .csv(<span class="string">&quot;s3a://&lt;バケット名&gt;/uber-csv/uber.csv&quot;</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">df.printSchema()</span><br><span class="line"></span><br><span class="line">df.cache()</span><br><span class="line">df.show(truncate=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>　最後の<code>df.show(truncate=False)</code>の出力結果は先ほどのScalaのコードと同じです。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">+---------------------+-------+--------+------+</span><br><span class="line">|dt                   |lat    |lon     |base  |</span><br><span class="line">+---------------------+-------+--------+------+</span><br><span class="line">|2014-08-01 00:00:00.0|40.729 |-73.9422|B02598|</span><br><span class="line">|2014-08-01 00:00:00.0|40.7476|-73.9871|B02598|</span><br><span class="line">|2014-08-01 00:00:00.0|40.7424|-74.0044|B02598|</span><br><span class="line">|2014-08-01 00:00:00.0|40.751 |-73.9869|B02598|</span><br><span class="line">|2014-08-01 00:00:00.0|40.7406|-73.9902|B02598|</span><br><span class="line">|2014-08-01 00:00:00.0|40.6994|-73.9591|B02617|</span><br><span class="line">|2014-08-01 00:00:00.0|40.6917|-73.9398|B02617|</span><br><span class="line">|2014-08-01 00:00:00.0|40.7063|-73.9223|B02617|</span><br><span class="line">|2014-08-01 00:00:00.0|40.6759|-74.0168|B02617|</span><br><span class="line">|2014-08-01 00:00:00.0|40.7617|-73.9847|B02617|</span><br><span class="line">|2014-08-01 00:00:00.0|40.6969|-73.9064|B02617|</span><br><span class="line">|2014-08-01 00:00:00.0|40.7623|-73.9751|B02617|</span><br><span class="line">|2014-08-01 00:00:00.0|40.6982|-73.9669|B02617|</span><br><span class="line">|2014-08-01 00:00:00.0|40.7553|-73.9253|B02617|</span><br><span class="line">|2014-08-01 00:00:00.0|40.7325|-73.9876|B02682|</span><br><span class="line">|2014-08-01 00:00:00.0|40.6754|-74.017 |B02682|</span><br><span class="line">|2014-08-01 00:00:00.0|40.7303|-74.0029|B02682|</span><br><span class="line">|2014-08-01 00:00:00.0|40.7218|-73.9973|B02682|</span><br><span class="line">|2014-08-01 00:00:00.0|40.7134|-74.0091|B02682|</span><br><span class="line">|2014-08-01 00:00:00.0|40.7194|-73.9964|B02682|</span><br><span class="line">+---------------------+-------+--------+------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      <comments>https://masato.github.io/2017/08/01/sensortag-kafka-python-spark-streaming-5/#disqus_thread</comments>
    </item>
    
    <item>
      <title>PythonとSensorTag, Kafka, Spark Streamingのストリーム処理 - Part 4: Kafka ConnectでMongoDBに出力する</title>
      <link>https://masato.github.io/2017/07/31/sensortag-kafka-python-spark-streaming-4/</link>
      <guid>https://masato.github.io/2017/07/31/sensortag-kafka-python-spark-streaming-4/</guid>
      <pubDate>Sun, 30 Jul 2017 21:02:15 GMT</pubDate>
      <description>
      
        Kafka ConnectはデータベースやKVSなど外部システムをKafkaに接続して連携させる仕組みです。スケールするストリーム処理のためのDataPipelineツールです。
      
      </description>
      
      
      <content:encoded><![CDATA[<p>　Kafka ConnectはデータベースやKVSなど外部システムをKafkaに接続して連携させる仕組みです。スケールするストリーム処理のためのDataPipelineツールです。ちょうどSensorTagのデータフォーマットを<a href="https://masato.github.io/2017/07/30/sensortag-kafka-python-spark-streaming-3/">Apache Avroに変更</a>しました。<a href="https://github.com/Landoop/kafka-connect-ui">Kafka Connect UI</a>ではデフォルトでAvroフォーマットを利用します。SensorTagのデータをKafkaのトピックを経由してMongoDBにSink(出力)してみます。</p><span id="more"></span><h2 id="Kafka-Connect-UI"><a href="#Kafka-Connect-UI" class="headerlink" title="Kafka Connect UI"></a>Kafka Connect UI</h2><p>　通常Kafka ConnectはCLIやREST APIを使い<a href="http://docs.confluent.io/current/connect/managing.html">Connector</a>の設定を行います。<a href="https://github.com/Landoop/kafka-connect-ui">Kafka Connect UI</a>の場合はエディタでConnectorの設定と<a href="https://github.com/datamountaineer/kafka-connect-query-language">KCQL</a>を記述しConnectorを実行することができます。</p><h3 id="Connectors"><a href="#Connectors" class="headerlink" title="Connectors"></a>Connectors</h3><p>　データベースなど外部システムをKafkaと接続するために、Source (入力)とSink (出力)の２種類のConnectorがあります。<a href="http://docs.confluent.io/current/connect/connectors.html">デフォルト</a>でいくつかのConnectorは用意されています。Kafka Connect UIでは<a href="https://fast-data-dev.demo.landoop.com/kafka-connect-ui/#/cluster/fast-data-dev/select-connector">demoページ</a>にあるように<a href="https://datamountaineer.com/">Data Mountaineer</a>が開発しているConnectorが追加されています。<br>　<br><img src="/2017/07/31/sensortag-kafka-python-spark-streaming-4/kafka-connect-1.png" alt="kafka-connect-1.png">　</p><h3 id="KCQL"><a href="#KCQL" class="headerlink" title="KCQL"></a>KCQL</h3><p>　<a href="https://github.com/datamountaineer/kafka-connect-query-language">KCQL(Kafka Connect Query Language)</a>はSQL風にKafka ConnectのSourceとSinkの設定を記述することができます。例えばKafkaのtopicをMongoDBにSinkする場合<a href="http://docs.datamountaineer.com/en/latest/mongo-sink.html#starting-the-connector">ドキュメント</a>にあるサンプルでは以下のように記述します。</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="attribute">name</span>=mongo-sink-orders</span><br><span class="line">connector.<span class="attribute">class</span>=com.datamountaineer.streamreactor.connect.mongodb.sink.MongoSinkConnector</span><br><span class="line">tasks.<span class="attribute">max</span>=1</span><br><span class="line"><span class="attribute">topics</span>=orders-topic</span><br><span class="line">connect.mongo.sink.<span class="attribute">kcql</span>=INSERT INTO orders SELECT * <span class="keyword">FROM</span> orders-topic</span><br><span class="line">connect.mongo.<span class="attribute">database</span>=connect</span><br><span class="line">connect.mongo.<span class="attribute">connection</span>=mongodb://localhost:27017</span><br><span class="line">connect.mongo.sink.batch.<span class="attribute">size</span>=10</span><br></pre></td></tr></table></figure><h2 id="使い方"><a href="#使い方" class="headerlink" title="使い方"></a>使い方</h2><p>　<a href="https://github.com/Landoop/fast-data-dev">fast-data-dev</a>のdocker-compose.ymlを利用して構築したKafkaクラスタにMongoDBを追加してデータ連携のテストを行います。</p><ul><li>SensorTag -&gt; Kafka -&gt; Kafka Connect -&gt; MongoDB</li></ul><h3 id="MongoDB"><a href="#MongoDB" class="headerlink" title="MongoDB"></a>MongoDB</h3><p>　<a href="https://github.com/Landoop/fast-data-dev">fast-data-dev</a>で構築したKafkaクラスタを起動しているdocker-compose.ymlにMongoDBサービスを追加します。</p><figure class="highlight yaml"><figcaption><span>docker-compose.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;2&#x27;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">kafka-stack:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">landoop/fast-data-dev:latest</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">FORWARDLOGS=0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">RUNTESTS=0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ADV_HOST=&lt;fast-data-devのIPアドレス&gt;</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">3030</span><span class="string">:3030</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">9092</span><span class="string">:9092</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">2181</span><span class="string">:2181</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">8081</span><span class="string">:8081</span></span><br><span class="line">  <span class="attr">connect-node-1:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">landoop/fast-data-dev-connect-cluster:latest</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">kafka-stack</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ID=01</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">BS=kafka-stack:9092</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ZK=kafka-stack:2181</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SR=http://kafka-stack:8081</span></span><br><span class="line">  <span class="attr">connect-node-2:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">landoop/fast-data-dev-connect-cluster:latest</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">kafka-stack</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ID=01</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">BS=kafka-stack:9092</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ZK=kafka-stack:2181</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SR=http://kafka-stack:8081</span></span><br><span class="line">  <span class="attr">connect-node-3:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">landoop/fast-data-dev-connect-cluster:latest</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">kafka-stack</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ID=01</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">BS=kafka-stack:9092</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ZK=kafka-stack:2181</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SR=http://kafka-stack:8081</span></span><br><span class="line">  <span class="attr">connect-ui:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">landoop/kafka-connect-ui:latest</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">connect-node-1</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">CONNECT_URL=http://connect-node-1:8083</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">8000</span><span class="string">:8000</span></span><br><span class="line">  <span class="attr">mongo:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">mongo</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">27017</span><span class="string">:27017</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">mongo_data:/data/db</span></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line">  <span class="attr">mongo_data:</span></span><br><span class="line">    <span class="attr">driver:</span> <span class="string">local</span></span><br></pre></td></tr></table></figure><p>　MongoDBサービスを起動します。</p><figure class="highlight elixir"><table><tr><td class="code"><pre><span class="line"><span class="variable">$ </span>docker-compose up -d mongo</span><br></pre></td></tr></table></figure><h3 id="Kafka-Connect-UI-1"><a href="#Kafka-Connect-UI-1" class="headerlink" title="Kafka Connect UI"></a>Kafka Connect UI</h3><p>　Kafka Connect UIのページを開きNEWボタン -&gt; SinkからMongoDBを選択します。Create New Connector画面のエディタに以下のように記述してCreateボタンを押します。</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="attribute">name</span>=MongoSinkConnector</span><br><span class="line">connector.<span class="attribute">class</span>=com.datamountaineer.streamreactor.connect.mongodb.sink.MongoSinkConnector</span><br><span class="line"><span class="attribute">topics</span>=sensortag-avro</span><br><span class="line">tasks.<span class="attribute">max</span>=1</span><br><span class="line">connect.mongo.<span class="attribute">database</span>=connect-db</span><br><span class="line">connect.mongo.<span class="attribute">connection</span>=mongodb://mongo:27017</span><br><span class="line">connect.mongo.sink.<span class="attribute">kcql</span>=INSERT INTO sensortag SELECT * <span class="keyword">FROM</span> sensortag-avro</span><br></pre></td></tr></table></figure><p>　サンプルから変更したところは以下です。</p><ul><li>connect.mongo.database</li></ul><figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="section">&lt;MongoDBのデータベース名&gt;</span></span><br></pre></td></tr></table></figure><ul><li>connect.mongo.connection</li></ul><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">mongodb:<span class="regexp">//</span>&lt;MongoDBのサービス名&gt;:<span class="number">27017</span></span><br></pre></td></tr></table></figure><ul><li>connect.mongo.sink.kcql</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="operator">&lt;</span>MongoDBのコレクション名<span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="operator">&lt;</span>Kafkaのトピック名<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure><p><img src="/2017/07/31/sensortag-kafka-python-spark-streaming-4/kafka-connect-2.png" alt="kafka-connect-2.png"></p><h3 id="Raspberry-Pi-3"><a href="#Raspberry-Pi-3" class="headerlink" title="Raspberry Pi 3"></a>Raspberry Pi 3</h3><p>　Raspberry Pi 3にSSH接続します。<a href="https://masato.github.io/2017/07/30/sensortag-kafka-python-spark-streaming-3/">前回</a>作成したAvroフォーマットでKafkaにデータ送信するPythonスクリプトを使います。　</p><figure class="highlight python"><figcaption><span>avro_producer_sensortag.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> bluepy.sensortag <span class="keyword">import</span> SensorTag</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> calendar</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> confluent_kafka <span class="keyword">import</span> avro</span><br><span class="line"><span class="keyword">from</span> confluent_kafka.avro <span class="keyword">import</span> AvroProducer</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    argvs = sys.argv</span><br><span class="line">    argc = <span class="built_in">len</span>(argvs)</span><br><span class="line">    <span class="keyword">if</span> (argc != <span class="number">2</span>):</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;Usage: # python &#123;0&#125; bd_address&#x27;</span>.<span class="built_in">format</span>(argvs[<span class="number">0</span>])</span><br><span class="line">        quit()</span><br><span class="line">    bid = argvs[<span class="number">1</span>]</span><br><span class="line">    print(<span class="string">&#x27;Connecting to &#x27;</span> + bid)</span><br><span class="line"></span><br><span class="line">    timeout = <span class="number">10.0</span></span><br><span class="line"></span><br><span class="line">    tag = SensorTag(bid)</span><br><span class="line">    tag.IRtemperature.enable()</span><br><span class="line">    tag.humidity.enable()</span><br><span class="line"></span><br><span class="line">    time.sleep(<span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">    get_schema_req_data = requests.get(</span><br><span class="line">        <span class="string">&quot;http://&lt;fast-data-devのIPアドレス&gt;:8081/subjects/sensortag-avro-value/versions/latest&quot;</span>)</span><br><span class="line">    get_schema_req_data.raise_for_status()</span><br><span class="line"></span><br><span class="line">    schema_string = get_schema_req_data.json()[<span class="string">&#x27;schema&#x27;</span>]</span><br><span class="line">    value_schema = avro.loads(schema_string)</span><br><span class="line"></span><br><span class="line">    avroProducer = AvroProducer(&#123;</span><br><span class="line">        <span class="string">&#x27;api.version.request&#x27;</span>:<span class="literal">True</span>,</span><br><span class="line">        <span class="string">&#x27;bootstrap.servers&#x27;</span>: <span class="string">&#x27;&lt;fast-data-devのIPアドレス&gt;:9092&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;schema.registry.url&#x27;</span>: <span class="string">&#x27;&lt;fast-data-devのIPアドレス&gt;:8081&#x27;</span></span><br><span class="line">    &#125;, default_value_schema=value_schema)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        tAmb, tObj = tag.IRtemperature.read()</span><br><span class="line">        humidity, rh = tag.humidity.read()</span><br><span class="line"></span><br><span class="line">        value = &#123;</span><br><span class="line">            <span class="string">&quot;bid&quot;</span> : bid,</span><br><span class="line">            <span class="string">&quot;time&quot;</span> : calendar.timegm(time.gmtime()),</span><br><span class="line">            <span class="string">&quot;ambient&quot;</span>: tAmb,</span><br><span class="line">            <span class="string">&quot;objecttemp&quot;</span>: tObj,</span><br><span class="line">            <span class="string">&quot;humidity&quot;</span>: humidity,</span><br><span class="line">            <span class="string">&quot;rh&quot;</span>: rh</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        avroProducer.produce(topic=<span class="string">&#x27;sensortag-avro&#x27;</span>, value=value)</span><br><span class="line">        avroProducer.flush()</span><br><span class="line">        print(value)</span><br><span class="line">        time.sleep(timeout)</span><br><span class="line"></span><br><span class="line">    tag.disconnect()</span><br><span class="line">    <span class="keyword">del</span> tag</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p>　<br>　SensorTagのBDアドレスPythonスクリプトに渡して実行します。10秒間隔でKafkaの<code>sensortag-avro</code>トピックにAvroフォーマットのデータを送信します。</p><figure class="highlight vim"><table><tr><td class="code"><pre><span class="line">$ <span class="keyword">python</span> avro_producer_sensortag.<span class="keyword">py</span> &lt;SensorTagのBDアドレス&gt;</span><br><span class="line">Connecting <span class="keyword">to</span> B0:B4:<span class="number">48</span>:BE:<span class="number">5</span>E:<span class="number">00</span></span><br><span class="line">&#123;<span class="string">&#x27;bid&#x27;</span>: <span class="string">&#x27;B0:B4:48:BE:5E:00&#x27;</span>, <span class="string">&#x27;time&#x27;</span>: <span class="number">1501541405</span>, <span class="string">&#x27;humidity&#x27;</span>: <span class="number">26.9708251953125</span>, <span class="string">&#x27;objecttemp&#x27;</span>: <span class="number">21.8125</span>, <span class="string">&#x27;ambient&#x27;</span>: <span class="number">26.78125</span>, <span class="string">&#x27;rh&#x27;</span>: <span class="number">73.62060546875</span>&#125;</span><br><span class="line">&#123;<span class="string">&#x27;bid&#x27;</span>: <span class="string">&#x27;B0:B4:48:BE:5E:00&#x27;</span>, <span class="string">&#x27;time&#x27;</span>: <span class="number">1501541416</span>, <span class="string">&#x27;humidity&#x27;</span>: <span class="number">26.990966796875</span>, <span class="string">&#x27;objecttemp&#x27;</span>: <span class="number">22.625</span>, <span class="string">&#x27;ambient&#x27;</span>: <span class="number">26.8125</span>, <span class="string">&#x27;rh&#x27;</span>: <span class="number">73.52294921875</span>&#125;</span><br></pre></td></tr></table></figure><h3 id="MongoDB-1"><a href="#MongoDB-1" class="headerlink" title="MongoDB"></a>MongoDB</h3><p>　MongoDBのコンテナに入りKafka Connect UIで設定したデータベースに接続します。KCQLの<code>INSERT INTO</code>に指定したコレクション(sensortag)にKafkaを経由してSensorTagのデータが出力されました。</p><figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">$ docker-compose exec mongo mongo connect-db</span><br><span class="line">&gt; show collections;</span><br><span class="line">sensortag</span><br><span class="line">&gt; db.sensortag.find<span class="literal">()</span></span><br><span class="line">&#123; <span class="string">&quot;_id&quot;</span> : <span class="constructor">ObjectId(<span class="string">&quot;597fb4f4a7b11b00636cfc13&quot;</span>)</span>, <span class="string">&quot;bid&quot;</span> : <span class="string">&quot;B0:B4:48:BE:5E:00&quot;</span>, <span class="string">&quot;time&quot;</span> : <span class="constructor">NumberLong(1501541619)</span>, <span class="string">&quot;ambient&quot;</span> : <span class="number">26.96875</span>, <span class="string">&quot;objecttemp&quot;</span> : <span class="number">22.9375</span>, <span class="string">&quot;humidity&quot;</span> : <span class="number">27.152099609375</span>, <span class="string">&quot;rh&quot;</span> : <span class="number">73.52294921875</span> &#125;</span><br><span class="line">&#123; <span class="string">&quot;_id&quot;</span> : <span class="constructor">ObjectId(<span class="string">&quot;597fb4ffa7b11b00636cfc14&quot;</span>)</span>, <span class="string">&quot;bid&quot;</span> : <span class="string">&quot;B0:B4:48:BE:5E:00&quot;</span>, <span class="string">&quot;time&quot;</span> : <span class="constructor">NumberLong(1501541630)</span>, <span class="string">&quot;ambient&quot;</span> : <span class="number">26.96875</span>, <span class="string">&quot;objecttemp&quot;</span> : <span class="number">22.9375</span>, <span class="string">&quot;humidity&quot;</span> : <span class="number">27.1722412109375</span>, <span class="string">&quot;rh&quot;</span> : <span class="number">73.431396484375</span> &#125;</span><br><span class="line">&#123; <span class="string">&quot;_id&quot;</span> : <span class="constructor">ObjectId(<span class="string">&quot;597fb50ba7b11b00636cfc15&quot;</span>)</span>, <span class="string">&quot;bid&quot;</span> : <span class="string">&quot;B0:B4:48:BE:5E:00&quot;</span>, <span class="string">&quot;time&quot;</span> : <span class="constructor">NumberLong(1501541642)</span>, <span class="string">&quot;ambient&quot;</span> : <span class="number">27</span>, <span class="string">&quot;objecttemp&quot;</span> : <span class="number">23.15625</span>, <span class="string">&quot;humidity&quot;</span> : <span class="number">27.18231201171875</span>, <span class="string">&quot;rh&quot;</span> : <span class="number">73.431396484375</span> &#125;</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      <comments>https://masato.github.io/2017/07/31/sensortag-kafka-python-spark-streaming-4/#disqus_thread</comments>
    </item>
    
    <item>
      <title>PythonとSensorTag, Kafka, Spark Streamingのストリーム処理 - Part 3: Apache AvroとSchema Registry</title>
      <link>https://masato.github.io/2017/07/30/sensortag-kafka-python-spark-streaming-3/</link>
      <guid>https://masato.github.io/2017/07/30/sensortag-kafka-python-spark-streaming-3/</guid>
      <pubDate>Sun, 30 Jul 2017 03:46:11 GMT</pubDate>
      <description>
      
        　Landoopが提供するfast-data-devのDockerイメージにはSchema Registryも含まれています。前回はSensorTagのデータはJSONフォーマットで送信しましたがApache Avroフォーマットも試してみます。
      
      </description>
      
      
      <content:encoded><![CDATA[<span id="more"></span><p>　<a href="http://www.landoop.com/">Landoop</a>が提供する<a href="https://hub.docker.com/r/landoop/fast-data-dev/">fast-data-dev</a>のDockerイメージには<a href="https://www.confluent.io/product/confluent-open-source/">Confluent Open Source</a>の<a href="http://docs.confluent.io/current/schema-registry/docs/index.html">Schema Registry</a>とWebツールの<a href="https://github.com/Landoop/schema-registry-ui">Schema Registry UI</a>が含まれています。<a href="https://masato.github.io/2017/07/28/sensortag-kafka-python-spark-streaming-2/">前回</a>SensorTagのデータはJSONフォーマットでKafkaへ送信していましたが<a href="https://avro.apache.org/">Apache Avro</a>フォーマットも試してみます。Apache Avroはデータのシリアル化と言語に依存しないスキーマによるデータ交換の仕組みを提供します。Schema RegistryはREST APIから操作できるAvroスキーマを一元管理するためのストレージです。</p><h2 id="Schema-Registry"><a href="#Schema-Registry" class="headerlink" title="Schema Registry"></a>Schema Registry</h2><p>　ローカルにあるAvroスキーマファイルを利用してデータをシリアライズすることもできますが、Schema Registryで一元管理することでAvroメッセージをデシリアライズする側も共通のデータフォーマットを参照することができます。</p><h3 id="Schema-Registry-UI"><a href="#Schema-Registry-UI" class="headerlink" title="Schema Registry UI"></a>Schema Registry UI</h3><p>　fast-data-devのトップページからSCHEMASをクリックするとSchema Registry UIのページが開きます。左上にあるNEWボタンをクリックするとAvroスキーマを記述するエディタが起動します。</p><p><img src="/2017/07/30/sensortag-kafka-python-spark-streaming-3/schema-registry.png" alt="schema-registry.png"></p><p>　<a href="https://github.com/Landoop/schema-registry-ui">Schema Registry UI</a>のエディタでAvroスキーマを記述します。保存する前にバリデーションを実行するため記述したJSONが正しいフォーマットか確認できます。</p><p>　フォームの<code>Subject Name</code>はvalueスキーマの場合<code>topic名-value</code>と書くようです。SensorTagからAvroフォーマットで送信するtopic名は<code>sensortag-avro</code>なので、この場合は<code>sensortag-avro-value</code>になります。<code>Schema</code>のフィールドにSensorTag用のAvroスキーマをJSONフォーマットで記述します。</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;record&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;SensorAvroValue&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;fields&quot;</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;bid&quot;</span>,</span><br><span class="line">      <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;string&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;time&quot;</span>,</span><br><span class="line">      <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;long&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;ambient&quot;</span>,</span><br><span class="line">      <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;double&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;objecttemp&quot;</span>,</span><br><span class="line">      <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;double&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;humidity&quot;</span>,</span><br><span class="line">      <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;double&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;rh&quot;</span>,</span><br><span class="line">      <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;double&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Raspberry-Pi-3"><a href="#Raspberry-Pi-3" class="headerlink" title="Raspberry Pi 3"></a>Raspberry Pi 3</h2><p>　<a href="https://masato.github.io/2017/07/28/sensortag-kafka-python-spark-streaming-2/">前回</a>Raspberry Pi 3ではKafkaのPythonクライアントとして<a href="http://kafka-python.readthedocs.io/en/master/">kafka-python</a>を利用しました。今回はAvroフォーマットに対応している<a href="https://github.com/confluentinc/confluent-kafka-python">confluent-kafka-python</a>を使います。</p><h3 id="librdkafkaのインストール"><a href="#librdkafkaのインストール" class="headerlink" title="librdkafkaのインストール"></a>librdkafkaのインストール</h3><p>　confluent-kafka-pythonのインストールには<a href="https://github.com/edenhill/librdkafka">librdkafka</a>のヘッダが必要です。先にlibrdkafkaをビルドして共有ライブラリ情報を更新します。</p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="variable">$</span> sudo apt<span class="literal">-get</span> update &amp;&amp; sudo apt<span class="literal">-get</span> install git <span class="built_in">build-essential</span> <span class="literal">-y</span></span><br><span class="line"><span class="variable">$</span> git clone https://github.com/edenhill/librdkafka.git</span><br><span class="line"><span class="variable">$</span> <span class="built_in">cd</span> librdkafka</span><br><span class="line"><span class="variable">$</span> ./configure </span><br><span class="line"><span class="variable">$</span> make &amp;&amp; sudo make install</span><br><span class="line"><span class="variable">$</span> sudo ldconfig</span><br></pre></td></tr></table></figure><h3 id="confluent-kafkaのインストール"><a href="#confluent-kafkaのインストール" class="headerlink" title="confluent-kafkaのインストール"></a>confluent-kafkaのインストール</h3><p>　Pythonのヘッダファイルも必要です。Avroフォーマットを利用する場合pipパッケージ名は<code>confluent-kafka[avro]</code>になります。Avroが不要な場合は<code>confluent-kafka</code>です。</p><figure class="highlight q"><table><tr><td class="code"><pre><span class="line">$ sudo apt-<span class="built_in">get</span> <span class="keyword">update</span> &amp;&amp; sudo apt-<span class="built_in">get</span> install python-<span class="built_in">dev</span> -y</span><br><span class="line">$ sudo pip install confluent-kafka[avro]</span><br></pre></td></tr></table></figure><h3 id="Avro-Producer"><a href="#Avro-Producer" class="headerlink" title="Avro Producer"></a>Avro Producer</h3><p>　オフィシャルの<a href="https://github.com/confluentinc/confluent-kafka-python">confluent-kafka-python</a>のページにあるコードを参考にAvro Producerを書きます。公式サンプルではローカルにあるスキーマファイルを利用しています。スキーマをSchema Registryから取得する機能は実装されていないようなので、ちょっと手間ですがSchema Registryから直接REST APIでスキーマを文字列として取得します。</p><figure class="highlight python"><figcaption><span>avro_producer_sensortag.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> bluepy.sensortag <span class="keyword">import</span> SensorTag</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> calendar</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> confluent_kafka <span class="keyword">import</span> avro</span><br><span class="line"><span class="keyword">from</span> confluent_kafka.avro <span class="keyword">import</span> AvroProducer</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    argvs = sys.argv</span><br><span class="line">    argc = <span class="built_in">len</span>(argvs)</span><br><span class="line">    <span class="keyword">if</span> (argc != <span class="number">2</span>):</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;Usage: # python &#123;0&#125; bd_address&#x27;</span>.<span class="built_in">format</span>(argvs[<span class="number">0</span>])</span><br><span class="line">        quit()</span><br><span class="line">    bid = argvs[<span class="number">1</span>]</span><br><span class="line">    print(<span class="string">&#x27;Connecting to &#x27;</span> + bid)</span><br><span class="line"></span><br><span class="line">    timeout = <span class="number">10.0</span></span><br><span class="line"></span><br><span class="line">    tag = SensorTag(bid)</span><br><span class="line">    tag.IRtemperature.enable()</span><br><span class="line">    tag.humidity.enable()</span><br><span class="line"></span><br><span class="line">    time.sleep(<span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">    get_schema_req_data = requests.get(</span><br><span class="line">        <span class="string">&quot;http://&lt;fast-data-devのIPアドレス&gt;:8081/subjects/sensortag-avro-value/versions/latest&quot;</span>)</span><br><span class="line">    get_schema_req_data.raise_for_status()</span><br><span class="line"></span><br><span class="line">    schema_string = get_schema_req_data.json()[<span class="string">&#x27;schema&#x27;</span>]</span><br><span class="line">    value_schema = avro.loads(schema_string)</span><br><span class="line"></span><br><span class="line">    avroProducer = AvroProducer(&#123;</span><br><span class="line">        <span class="string">&#x27;api.version.request&#x27;</span>:<span class="literal">True</span>,</span><br><span class="line">        <span class="string">&#x27;bootstrap.servers&#x27;</span>: <span class="string">&#x27;&lt;fast-data-devのIPアドレス&gt;:9092&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;schema.registry.url&#x27;</span>: <span class="string">&#x27;&lt;fast-data-devのIPアドレス&gt;:8081&#x27;</span></span><br><span class="line">    &#125;, default_value_schema=value_schema)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        tAmb, tObj = tag.IRtemperature.read()</span><br><span class="line">        humidity, rh = tag.humidity.read()</span><br><span class="line"></span><br><span class="line">        value = &#123;</span><br><span class="line">            <span class="string">&quot;bid&quot;</span> : bid,</span><br><span class="line">            <span class="string">&quot;time&quot;</span> : calendar.timegm(time.gmtime()),</span><br><span class="line">            <span class="string">&quot;ambient&quot;</span>: tAmb,</span><br><span class="line">            <span class="string">&quot;objecttemp&quot;</span>: tObj,</span><br><span class="line">            <span class="string">&quot;humidity&quot;</span>: humidity,</span><br><span class="line">            <span class="string">&quot;rh&quot;</span>: rh</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        avroProducer.produce(topic=<span class="string">&#x27;sensortag-avro&#x27;</span>, value=value)</span><br><span class="line">        avroProducer.flush()</span><br><span class="line">        print(value)</span><br><span class="line">        time.sleep(timeout)</span><br><span class="line"></span><br><span class="line">    tag.disconnect()</span><br><span class="line">    <span class="keyword">del</span> tag</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p>　SensorTagのBDアドレスをhcitoolを使い確認します。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ sudo hcitool lescan</span><br><span class="line">LE Scan ...</span><br><span class="line">...</span><br><span class="line">B0:B4:48:BE:5E:00 CC2650 SensorTag</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>　BDアドレスを引数にして作成したPythonスクリプトを実行します。</p><figure class="highlight vim"><table><tr><td class="code"><pre><span class="line">$ <span class="keyword">python</span> avro_producer_sensortag.<span class="keyword">py</span> &lt;SensorTagのBDアドレス&gt;</span><br></pre></td></tr></table></figure><p>　以下のようなログを出力してKafkaブローカーへメッセージ送信を開始します。</p><figure class="highlight 1c"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;bid&#x27;: &#x27;B0:B4:48:BE:5E:00&#x27;, &#x27;time&#x27;: <span class="number">1501495463</span>, &#x27;humidity&#x27;: <span class="number">27.04132080078125</span>, &#x27;objecttemp&#x27;: <span class="number">22.5</span>, &#x27;ambient&#x27;: <span class="number">26.84375</span>, &#x27;rh&#x27;: <span class="number">69.05517578125</span>&#125;</span><br><span class="line">&#123;&#x27;bid&#x27;: &#x27;B0:B4:48:BE:5E:00&#x27;, &#x27;time&#x27;: <span class="number">1501495475</span>, &#x27;humidity&#x27;: <span class="number">27.02117919921875</span>, &#x27;objecttemp&#x27;: <span class="number">22.75</span>, &#x27;ambient&#x27;: <span class="number">26.84375</span>, &#x27;rh&#x27;: <span class="number">69.05517578125</span>&#125;</span><br><span class="line">&#123;&#x27;bid&#x27;: &#x27;B0:B4:48:BE:5E:00&#x27;, &#x27;time&#x27;: <span class="number">1501495486</span>, &#x27;humidity&#x27;: <span class="number">27.04132080078125</span>, &#x27;objecttemp&#x27;: <span class="number">22.96875</span>, &#x27;ambient&#x27;: <span class="number">26.84375</span>, &#x27;rh&#x27;: <span class="number">69.05517578125</span>&#125;</span><br></pre></td></tr></table></figure><p>　</p><h3 id="Avro-Consumer"><a href="#Avro-Consumer" class="headerlink" title="Avro Consumer"></a>Avro Consumer</h3><p>　Avro Consumerのコードは<a href="https://github.com/confluentinc/confluent-kafka-python">confluent-kafka-python</a>にあるサンプルをそのまま使います。</p><figure class="highlight python"><figcaption><span>avro_consumer_sensortag.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> confluent_kafka <span class="keyword">import</span> KafkaError</span><br><span class="line"><span class="keyword">from</span> confluent_kafka.avro <span class="keyword">import</span> AvroConsumer</span><br><span class="line"><span class="keyword">from</span> confluent_kafka.avro.serializer <span class="keyword">import</span> SerializerError</span><br><span class="line"></span><br><span class="line">c = AvroConsumer(&#123;</span><br><span class="line">    <span class="string">&#x27;api.version.request&#x27;</span>:<span class="literal">True</span>,</span><br><span class="line">    <span class="string">&#x27;bootstrap.servers&#x27;</span>: <span class="string">&#x27;&lt;fast-data-devのIPアドレス&gt;:9092&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;group.id&#x27;</span>: <span class="string">&#x27;raspiavro&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;schema.registry.url&#x27;</span>: <span class="string">&#x27;http://&lt;fast-data-devのIPアドレス&gt;:8081&#x27;</span>&#125;)</span><br><span class="line">c.subscribe([<span class="string">&#x27;sensortag-avro&#x27;</span>])</span><br><span class="line"></span><br><span class="line">running = <span class="literal">True</span></span><br><span class="line"><span class="keyword">while</span> running:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        msg = c.poll(<span class="number">10</span>)</span><br><span class="line">        print(msg)</span><br><span class="line">        <span class="keyword">if</span> msg:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> msg.error():</span><br><span class="line">                print(msg.value())</span><br><span class="line">            <span class="keyword">elif</span> msg.error().code() != KafkaError._PARTITION_EOF:</span><br><span class="line">                print(msg.error())</span><br><span class="line">                running = <span class="literal">False</span></span><br><span class="line">    <span class="keyword">except</span> SerializerError <span class="keyword">as</span> e:</span><br><span class="line">        print(<span class="string">&quot;Message deserialization failed for %s: %s&quot;</span> % (msg, e))</span><br><span class="line">        running = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">c.close()</span><br></pre></td></tr></table></figure><p>　作成したPythoのスクリプトを実行します。</p><figure class="highlight vim"><table><tr><td class="code"><pre><span class="line">$ <span class="keyword">python</span> avro_consumer_sensortag.<span class="keyword">py</span></span><br></pre></td></tr></table></figure><p>　サンプルでは10秒間隔でpollingしています。タイミングがあわないとデータを取得できないためNoneが返ります。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&lt;cimpl.Message <span class="built_in">object</span> at <span class="number">0x7655de88</span>&gt;</span><br><span class="line">&lt;cimpl.Message <span class="built_in">object</span> at <span class="number">0x764ee6f0</span>&gt;</span><br><span class="line">&#123;<span class="string">u&#x27;bid&#x27;</span>: <span class="string">u&#x27;B0:B4:48:BE:5E:00&#x27;</span>, <span class="string">u&#x27;time&#x27;</span>: <span class="number">1501495204L</span>, <span class="string">u&#x27;humidity&#x27;</span>: <span class="number">27.27294921875</span>, <span class="string">u&#x27;objecttemp&#x27;</span>: <span class="number">22.78125</span>, <span class="string">u&#x27;ambient&#x27;</span>: <span class="number">27.09375</span>, <span class="string">u&#x27;rh&#x27;</span>: <span class="number">69.671630859375</span>&#125;</span><br><span class="line">&lt;cimpl.Message <span class="built_in">object</span> at <span class="number">0x7655de88</span>&gt;</span><br><span class="line"><span class="literal">None</span></span><br><span class="line">&lt;cimpl.Message <span class="built_in">object</span> at <span class="number">0x7655de88</span>&gt;</span><br><span class="line">&#123;<span class="string">u&#x27;bid&#x27;</span>: <span class="string">u&#x27;B0:B4:48:BE:5E:00&#x27;</span>, <span class="string">u&#x27;time&#x27;</span>: <span class="number">1501495215L</span>, <span class="string">u&#x27;humidity&#x27;</span>: <span class="number">27.26287841796875</span>, <span class="string">u&#x27;objecttemp&#x27;</span>: <span class="number">22.9375</span>, <span class="string">u&#x27;ambient&#x27;</span>: <span class="number">27.09375</span>, <span class="string">u&#x27;rh&#x27;</span>: <span class="number">69.671630859375</span>&#125;</span><br><span class="line">&lt;cimpl.Message <span class="built_in">object</span> at <span class="number">0x747caa98</span>&gt;</span><br></pre></td></tr></table></figure><h3 id="kafka-avro-console-consumer"><a href="#kafka-avro-console-consumer" class="headerlink" title="kafka-avro-console-consumer"></a>kafka-avro-console-consumer</h3><p>　最後にサーバー側でも<code>kafka-avro-console-consumer</code>コマンドからメッセージを取得してみます。</p><figure class="highlight livescript"><table><tr><td class="code"><pre><span class="line">$ docker-compose exec kafka-stack <span class="string">\</span></span><br><span class="line">  kafka-avro-<span class="built_in">console</span>-consumer <span class="string">\</span></span><br><span class="line">  --bootstrap-server localhost:<span class="number">9092</span> <span class="string">\</span></span><br><span class="line">  --topic sensortag-avro</span><br></pre></td></tr></table></figure><p>　こちらも同様にSensorTagのデータを取得することができます。</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;<span class="attr">&quot;bid&quot;</span>:<span class="string">&quot;B0:B4:48:BE:5E:00&quot;</span>,<span class="attr">&quot;time&quot;</span>:<span class="number">1501495384</span>,<span class="attr">&quot;ambient&quot;</span>:<span class="number">26.9375</span>,<span class="attr">&quot;objecttemp&quot;</span>:<span class="number">22.96875</span>,<span class="attr">&quot;humidity&quot;</span>:<span class="number">27.11181640625</span>,<span class="attr">&quot;rh&quot;</span>:<span class="number">69.05517578125</span>&#125;</span><br><span class="line">&#123;<span class="attr">&quot;bid&quot;</span>:<span class="string">&quot;B0:B4:48:BE:5E:00&quot;</span>,<span class="attr">&quot;time&quot;</span>:<span class="number">1501495396</span>,<span class="attr">&quot;ambient&quot;</span>:<span class="number">26.90625</span>,<span class="attr">&quot;objecttemp&quot;</span>:<span class="number">22.6875</span>,<span class="attr">&quot;humidity&quot;</span>:<span class="number">27.0916748046875</span>,<span class="attr">&quot;rh&quot;</span>:<span class="number">69.05517578125</span>&#125;</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      <comments>https://masato.github.io/2017/07/30/sensortag-kafka-python-spark-streaming-3/#disqus_thread</comments>
    </item>
    
    <item>
      <title>PythonとSensorTag, Kafka, Spark Streamingのストリーム処理 - Part 2: KafkaとLandoop</title>
      <link>https://masato.github.io/2017/07/28/sensortag-kafka-python-spark-streaming-2/</link>
      <guid>https://masato.github.io/2017/07/28/sensortag-kafka-python-spark-streaming-2/</guid>
      <pubDate>Fri, 28 Jul 2017 03:24:03 GMT</pubDate>
      <description>
      
        Landoopを使いKafkaクラスタをDocker Composeで構築します。
      
      </description>
      
      
      <content:encoded><![CDATA[<p>　<a href="https://masato.github.io/2017/07/27/sensortag-kafka-python-spark-streaming-1/">前回</a>はRaspberry Pi 3上でSensorTagから環境データを取得するPythonスクリプトを書きました。この環境データはKafkaを経由してストリーム処理する予定です。次にRaspberry Pi 3からメッセージを受け取るKafkaクラスタをクラウド上に構築していきます。</p><p>　Kafkaクラスタは<a href="http://www.landoop.com/">Landoop</a>が開発している<a href="https://hub.docker.com/r/landoop/fast-data-dev/">fast-data-dev</a>のDockerイメージを使います。　</p><span id="more"></span><h2 id="LandoopでKafkaクラスタを構築する"><a href="#LandoopでKafkaクラスタを構築する" class="headerlink" title="LandoopでKafkaクラスタを構築する"></a>LandoopでKafkaクラスタを構築する</h2><p>　<a href="http://www.landoop.com/">Landoop</a>はKafkaのソリューションを提供する会社です。特に<a href="http://docs.confluent.io/current/connect/index.html">Kafka Connect</a>を中心にしたストリームのデータパイプラインの開発に強い印象です。</p><h3 id="Landoop"><a href="#Landoop" class="headerlink" title="Landoop"></a>Landoop</h3><p>　<br>　Landoopでは<a href="http://kafka-topics-ui.landoop.com/#/">Kafka Topics UI</a>や<a href="http://kafka-connect-ui.landoop.com/#/">Kafka Connect UI</a>、<a href="https://hub.docker.com/r/landoop/kafka-topics-ui/">Kafka Topics UI</a>などのWebツールを開発しています。<a href="https://fast-data-dev.demo.landoop.com/">demo</a>サイトからどのようなツールなのかを確認できます。このdemoサイトと同じ環境は<a href="https://github.com/Landoop/fast-data-connect-cluster">fast-data-connect-cluster</a>を使うと簡単に構築することができます。　</p><p><img src="/2017/07/28/sensortag-kafka-python-spark-streaming-2/landoop-top.png" alt="landoop-top.png"></p><h3 id="fast-data-connect-cluster"><a href="#fast-data-connect-cluster" class="headerlink" title="fast-data-connect-cluster"></a>fast-data-connect-cluster</h3><p>　fast-data-connect-clusterのリポジトリをcloneします。</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">$ git clone https:<span class="regexp">//gi</span>thub.com<span class="regexp">/Landoop/</span>fast-data-connect-cluster</span><br></pre></td></tr></table></figure><p>　<br>　リポジトリに含まれる<a href="https://github.com/Landoop/fast-data-connect-cluster/blob/master/docker-compose.yml">docker-compose.yml</a>を少し変更してクラウド上で利用します。Debianの仮想マシンを用意してDockerとDocker Composeをインストールしました。利用するバージョンは以下です。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker --version</span><br><span class="line">Docker version 17.06.0-ce, build 02c1d87</span><br><span class="line"></span><br><span class="line">$ docker-compose --version</span><br><span class="line">docker-compose version 1.14.0, build c7bdf9e</span><br></pre></td></tr></table></figure><p>　このdocker-compose.ymlにはLandoopのWebツールに加えて<a href="https://www.confluent.io/product/confluent-open-source/">Confluent Open Source</a>に含まれる<a href="https://kafka.apache.org/">Kafka</a>、<a href="http://docs.confluent.io/current/schema-registry/docs/intro.html">Schema Registry</a>、<a href="http://docs.confluent.io/current/kafka-rest/docs/index.html">Kafka REST Proxy</a>、<a href="http://docs.confluent.io/current/connect/index.html">Kafka Connect</a>、<a href="https://zookeeper.apache.org/">Apache ZooKeeper</a>が含まれます。一通りKafkaを使った開発に必要なコンテナが揃うのでとても便利です。</p><p>　現在Confluent Open SourceとKafkaのバージョンは以下になっています。　</p><ul><li>Confluent Open Source: v3.2.2</li><li>Kafka v0.10.2.1</li></ul><p>　docker-compose.ymlの主な変更点です。</p><ul><li>ADV_HOST: Dockerが起動している仮想マシンのパブリックIPアドレスを指定します。</li><li>ports: リモートから接続するためにZooKeeperやKafkaクラスタのポートを公開します。</li></ul><figure class="highlight yaml"><figcaption><span>docker-compose.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;2&#x27;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">kafka-stack:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">landoop/fast-data-dev</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">FORWARDLOGS=0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">RUNTESTS=0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ADV_HOST=210.xxx.xxx.xxx</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">3030</span><span class="string">:3030</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">9092</span><span class="string">:9092</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">2181</span><span class="string">:2181</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">8081</span><span class="string">:8081</span></span><br><span class="line">  <span class="attr">connect-node-1:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">landoop/fast-data-dev-connect-cluster</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">kafka-stack</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ID=01</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">BS=kafka-stack:9092</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ZK=kafka-stack:2181</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SR=http://kafka-stack:8081</span></span><br><span class="line">  <span class="attr">connect-node-2:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">landoop/fast-data-dev-connect-cluster</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">kafka-stack</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ID=01</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">BS=kafka-stack:9092</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ZK=kafka-stack:2181</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SR=http://kafka-stack:8081</span></span><br><span class="line">  <span class="attr">connect-node-3:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">landoop/fast-data-dev-connect-cluster</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">kafka-stack</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ID=01</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">BS=kafka-stack:9092</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ZK=kafka-stack:2181</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SR=http://kafka-stack:8081</span></span><br><span class="line">  <span class="attr">connect-ui:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">landoop/kafka-connect-ui:latest</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">connect-node-1</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">CONNECT_URL=http://connect-node-1:8083</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">8000</span><span class="string">:8000</span></span><br></pre></td></tr></table></figure><p>　docker-compose.ymlのディレクトリに移動してコンテナを起動します。</p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="variable">$</span> <span class="built_in">cd</span> fast<span class="literal">-data</span><span class="literal">-connect</span><span class="literal">-cluster</span></span><br><span class="line"><span class="variable">$</span> docker<span class="literal">-compose</span> up <span class="literal">-d</span></span><br></pre></td></tr></table></figure><h3 id="動作確認"><a href="#動作確認" class="headerlink" title="動作確認"></a>動作確認</h3><p>　Kafkaクライアントから簡単に動作確認をします。kafka-topicsコマンドでトピックを作成します。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker-compose <span class="built_in">exec</span> kafka-stack kafka-topics \</span><br><span class="line">    --create --topic <span class="built_in">test</span> \</span><br><span class="line">    --zookeeper localhost:2181 \</span><br><span class="line">    --partitions 1 --replication-factor 1</span><br></pre></td></tr></table></figure><p>　kafka-console-consumerコマンドを実行します。メッセージがトピックに届くとこのシェルに表示されます。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker-compose <span class="built_in">exec</span> kafka-stack \</span><br><span class="line">  kafka-console-consumer \</span><br><span class="line">  --bootstrap-server localhost:9092 \</span><br><span class="line">  --from-beginning \</span><br><span class="line">  --topic <span class="built_in">test</span></span><br></pre></td></tr></table></figure><p>　別のシェルからkafka-console-producerコマンドを実行します。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker-compose <span class="built_in">exec</span> kafka-stack \</span><br><span class="line">  kafka-console-producer \</span><br><span class="line">  --broker-list localhost:9092 \</span><br><span class="line">  --topic <span class="built_in">test</span></span><br></pre></td></tr></table></figure><p>　コマンドは待機状態になるので適当なメッセージをシェルに入力します。同じメッセージがkafka-console-consumerのシェルにも表示されます。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hello world</span><br></pre></td></tr></table></figure><p>　Kafka Topics UIのページではトピックの一覧とメッセージの中身を確認することができます。<br>　<br><img src="/2017/07/28/sensortag-kafka-python-spark-streaming-2/landoop-topic.png" alt="landoop-topic.png"></p><h2 id="SensorTagの環境データをKafkaに送信する"><a href="#SensorTagの環境データをKafkaに送信する" class="headerlink" title="SensorTagの環境データをKafkaに送信する"></a>SensorTagの環境データをKafkaに送信する</h2><h3 id="kafka-python"><a href="#kafka-python" class="headerlink" title="kafka-python"></a>kafka-python</h3><p>　PythonのKafkaクライアントには<a href="http://kafka-python.readthedocs.io/en/master/">kafka-python</a>と<a href="http://docs.confluent.io/current/clients/confluent-kafka-python/">confluent-kafka-python</a>があります。APIが微妙に違うので間違えないようにします。今回はkafka-pythonをインストールして使います。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ sudo pip install kafka-python</span><br></pre></td></tr></table></figure><p>　<a href="https://masato.github.io/2017/07/27/sensortag-kafka-python-spark-streaming-1/">前回</a>書いたSensorTagのデータを取得するPythonのコードにKafkaへメッセージを送信するproducerを追加します。</p><figure class="highlight python"><figcaption><span>json_producer_sensortag_kafka.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> bluepy.sensortag <span class="keyword">import</span> SensorTag</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> calendar</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> kafka <span class="keyword">import</span> KafkaProducer</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    argvs = sys.argv</span><br><span class="line">    argc = <span class="built_in">len</span>(argvs)</span><br><span class="line">    <span class="keyword">if</span> (argc != <span class="number">2</span>):</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;Usage: # python &#123;0&#125; bd_address&#x27;</span>.<span class="built_in">format</span>(argvs[<span class="number">0</span>])</span><br><span class="line">        quit()</span><br><span class="line">    bid = argvs[<span class="number">1</span>]</span><br><span class="line">    print(<span class="string">&#x27;Connecting to &#x27;</span> + bid)</span><br><span class="line"></span><br><span class="line">    timeout = <span class="number">10.0</span></span><br><span class="line"></span><br><span class="line">    tag = SensorTag(bid)</span><br><span class="line">    tag.IRtemperature.enable()</span><br><span class="line">    tag.humidity.enable()</span><br><span class="line">    </span><br><span class="line">    time.sleep(<span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">    producer = KafkaProducer(bootstrap_servers=<span class="string">&#x27;210.xxx.xxx.xxx:9092&#x27;</span>)</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        tAmb, tObj = tag.IRtemperature.read()</span><br><span class="line">        humidity, rh = tag.humidity.read()</span><br><span class="line"></span><br><span class="line">        value = &#123;</span><br><span class="line">            <span class="string">&quot;bid&quot;</span> : bid,</span><br><span class="line">            <span class="string">&quot;time&quot;</span> : calendar.timegm(time.gmtime()),</span><br><span class="line">            <span class="string">&quot;ambient&quot;</span>: tAmb,</span><br><span class="line">            <span class="string">&quot;objecttemp&quot;</span>: tObj,</span><br><span class="line">            <span class="string">&quot;humidity&quot;</span>: humidity,</span><br><span class="line">            <span class="string">&quot;rh&quot;</span>: rh</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        msg = json.dumps(value).encode(<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">        producer.send(<span class="string">&#x27;sensortag&#x27;</span>, msg)</span><br><span class="line">        producer.flush()</span><br><span class="line">        print(msg)</span><br><span class="line"></span><br><span class="line">        time.sleep(timeout)</span><br><span class="line"></span><br><span class="line">    tag.disconnect()</span><br><span class="line">    <span class="keyword">del</span> tag</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p>　SensorTagのBDアドレスを引数にしてPythonスクリプトを実行します。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ python json_producer_sensortag_kafka.py B0:B4:48:BE:5E:00</span><br></pre></td></tr></table></figure><p>　10秒間隔で取得した環境データをJSON文字列に整形してKafkaクラスタに送信します。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Connecting to B0:B4:48:BE:5E:00</span><br><span class="line">&#123;<span class="string">&quot;bid&quot;</span>: <span class="string">&quot;B0:B4:48:BE:5E:00&quot;</span>, <span class="string">&quot;time&quot;</span>: 1501464133, <span class="string">&quot;humidity&quot;</span>: 26.8096923828125, <span class="string">&quot;objecttemp&quot;</span>: 22.0625, <span class="string">&quot;ambient&quot;</span>: 26.59375, <span class="string">&quot;rh&quot;</span>: 68.829345703125&#125;</span><br><span class="line">&#123;<span class="string">&quot;bid&quot;</span>: <span class="string">&quot;B0:B4:48:BE:5E:00&quot;</span>, <span class="string">&quot;time&quot;</span>: 1501464143, <span class="string">&quot;humidity&quot;</span>: 26.86004638671875, <span class="string">&quot;objecttemp&quot;</span>: 22.40625, <span class="string">&quot;ambient&quot;</span>: 26.65625, <span class="string">&quot;rh&quot;</span>: 68.927001953125&#125;</span><br><span class="line">&#123;<span class="string">&quot;bid&quot;</span>: <span class="string">&quot;B0:B4:48:BE:5E:00&quot;</span>, <span class="string">&quot;time&quot;</span>: 1501464153, <span class="string">&quot;humidity&quot;</span>: 26.92047119140625, <span class="string">&quot;objecttemp&quot;</span>: 22.71875, <span class="string">&quot;ambient&quot;</span>: 26.71875, <span class="string">&quot;rh&quot;</span>: 68.95751953125&#125;</span><br></pre></td></tr></table></figure><p>　Kafka Topics UIの画面にもSensorTagの環境データが表示されました。</p><p><img src="/2017/07/28/sensortag-kafka-python-spark-streaming-2/landoop-sensortag.png" alt="landoop-sensortag.png"></p>]]></content:encoded>
      
      <comments>https://masato.github.io/2017/07/28/sensortag-kafka-python-spark-streaming-2/#disqus_thread</comments>
    </item>
    
    <item>
      <title>PythonとSensorTag, Kafka, Spark Streamingのストリーム処理 - Part 1: Raspberry Pi 3</title>
      <link>https://masato.github.io/2017/07/27/sensortag-kafka-python-spark-streaming-1/</link>
      <guid>https://masato.github.io/2017/07/27/sensortag-kafka-python-spark-streaming-1/</guid>
      <pubDate>Thu, 27 Jul 2017 04:15:19 GMT</pubDate>
      <description>
      
        Raspberry Pi 3からSensorTagの環境データを取得します。
      
      </description>
      
      
      <content:encoded><![CDATA[<p>　このシリーズではRaspberry Pi 3からSensorTagの環境データを取得します。その後にKafkaを経由したSpark Streamingでウィンド分析するPythonのコードを書いてみます。<br>　<br>　Raspberry Pi 3のセットアップ方法は多くの<a href="https://masato.github.io/2017/01/29/eclipse-iot-kura-install/">サンプル</a>があります。ここでは簡単にSensorTagの環境データを取得するための準備をします。</p><span id="more"></span><h2 id="用意するもの"><a href="#用意するもの" class="headerlink" title="用意するもの"></a>用意するもの</h2><p>　Raspberry Pi 3はWi-FiとBluetoothを内蔵しています。ドングルが不要になり用意するものが減りました。この例ではUSB-A端子がある古いMacBook Pro (macOS Sierra 10.12.6)を開発用端末に使っています。Raspberry Pi 3とEthernet接続する周辺機器を用意します。　</p><ul><li><a href="https://www.amazon.co.jp/dp/B00LVH885U">USB2.0 有線LANアダプタ</a></li><li><a href="https://www.amazon.co.jp/dp/B008RVY7K8/">Ethernetケーブル</a></li></ul><p>　テキサスインスツルメンツのSensorTagはRaspberry Pi 3とBluetooth接続して温度や湿度といった環境データを簡単に取得することができます。　</p><ul><li><a href="http://www.tij.co.jp/tool/jp/TIDC-CC2650STK-SENSORTAG">CC2650</a></li></ul><h2 id="macOSでRaspbian-Liteイメージを焼く"><a href="#macOSでRaspbian-Liteイメージを焼く" class="headerlink" title="macOSでRaspbian Liteイメージを焼く"></a>macOSでRaspbian Liteイメージを焼く</h2><p>　オフィシャルの<a href="https://www.raspberrypi.org/documentation/installation/installing-images/mac.md">Installing operating system images on Mac OS</a>の手順に従います。SDカードのデバイス名を確認してunmountします。この例では/dev/disk2です。</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">$ diskutil list</span><br><span class="line">...</span><br><span class="line"><span class="regexp">/dev/</span>disk2 (internal, physical):</span><br><span class="line">   <span class="comment">#:                       TYPE NAME                    SIZE       IDENTIFIER</span></span><br><span class="line">   <span class="number">0</span>:     FDisk_partition_scheme                        *<span class="number">15.6</span> GB    disk2</span><br><span class="line">   <span class="number">1</span>:             Windows_FAT_32 NO NAME                 <span class="number">15.6</span> GB    disk2s1</span><br><span class="line"></span><br><span class="line">$ diskutil unmountDisk <span class="regexp">/dev/</span>disk2</span><br></pre></td></tr></table></figure><p>　Raspbian Jessie Liteを<a href="https://www.raspberrypi.org/downloads/raspbian/">ダウンロード</a>してSDカードに焼きます。SSHの有効化も忘れずに行います。</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">$ cd ~/Downloads</span><br><span class="line">$ wget http:<span class="regexp">//</span>director.downloads.raspberrypi.org<span class="regexp">/raspbian_lite/im</span>ages<span class="regexp">/raspbian_lite-2017-07-05/</span><span class="number">2017</span>-<span class="number">07</span>-<span class="number">05</span>-raspbian-jessie-lite.zip</span><br><span class="line">$ unzip <span class="number">2017</span>-<span class="number">07</span>-<span class="number">05</span>-raspbian-jessie-lite.zip</span><br><span class="line">$ sudo dd bs=<span class="number">1</span>m <span class="keyword">if</span>=<span class="number">2017</span>-<span class="number">07</span>-<span class="number">05</span>-raspbian-jessie-lite.img of=<span class="regexp">/dev/</span>rdisk2</span><br><span class="line">$ touch <span class="regexp">/Volumes/</span>boot/ssh</span><br><span class="line">$ diskutil unmountDisk <span class="regexp">/dev/</span>disk2</span><br></pre></td></tr></table></figure><h3 id="mDNSでSSH接続する"><a href="#mDNSでSSH接続する" class="headerlink" title="mDNSでSSH接続する"></a>mDNSでSSH接続する</h3><p>　macOSはRaspberry Pi 3とEthernetケーブル接続をして簡単にSSHできます。デフォルトでは以下のユーザーが設定されています。</p><ul><li>username: pi</li><li>password: raspberry</li></ul><figure class="highlight julia"><table><tr><td class="code"><pre><span class="line">$ ssh <span class="literal">pi</span><span class="meta">@raspberrypi</span>.<span class="keyword">local</span></span><br></pre></td></tr></table></figure><p>　macOSの公開鍵をRaspberry Pi 3の`~/.ssh/authorized_keys’にコピーします。</p><figure class="highlight gams"><table><tr><td class="code"><pre><span class="line"><span class="symbol">$</span> mkdir -p -m <span class="number">700</span> ~/.ssh</span><br><span class="line"><span class="symbol">$</span> cat &lt;&lt; EOF &gt; ~/.ssh/authorized_keys</span><br><span class="line"><span class="function"><span class="title">ssh</span></span>-rsa AAAA...</span><br><span class="line">EOF</span><br><span class="line"><span class="symbol">$</span> chmod <span class="number">600</span> ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure><p>　ログインし直します。</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">$ <span class="keyword">exit</span></span><br></pre></td></tr></table></figure><h3 id="無線LAN"><a href="#無線LAN" class="headerlink" title="無線LAN"></a>無線LAN</h3><p>　無線LANのアクセスポイント(ESSID)を設定してネットワークを再起動します。<code>ping</code>からインターネット接続を確認します。</p><figure class="highlight elixir"><table><tr><td class="code"><pre><span class="line"><span class="variable">$ </span>sudo sh -c <span class="string">&#x27;wpa_passphrase [ESSID] [パスワード] &gt;&gt; /etc/wpa_supplicant/wpa_supplicant.conf&#x27;</span></span><br><span class="line"><span class="variable">$ </span>sudo ifdown wlan0</span><br><span class="line"><span class="variable">$ </span>sudo ifup wlan0</span><br><span class="line"><span class="variable">$ </span>ping -c <span class="number">1</span> www.yahoo.co.jp</span><br></pre></td></tr></table></figure><h3 id="raspi-config"><a href="#raspi-config" class="headerlink" title="raspi-config"></a>raspi-config</h3><p>　<code>raspi-config</code>でパスワードとタイムゾーンを変更します。</p><figure class="highlight arduino"><table><tr><td class="code"><pre><span class="line">$ sudo raspi-<span class="built_in">config</span></span><br></pre></td></tr></table></figure><ul><li>1 Change User Password</li><li>4 Localisation Options</li><li>I2 Change Timezone</li><li>Asia &gt; Tokyo</li></ul><h3 id="apt-get"><a href="#apt-get" class="headerlink" title="apt-get"></a>apt-get</h3><p>　日本のミラーサイトに変更してパッケージを最新にします。ファイルを編集するためにvimをインストールします。</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">$ sudo sed -i<span class="string">&quot;.bak&quot;</span> -e <span class="string">&quot;s/mirrordirector.raspbian.org/ftp.jaist.ac.jp/g&quot;</span> /etc/apt/sources.list</span><br><span class="line">$ sudo apt-<span class="builtin-name">get</span> update &amp;&amp; sudo apt-<span class="builtin-name">get</span> dist-upgrade -y</span><br><span class="line">$ sudo apt-<span class="builtin-name">get</span> install vim -y</span><br></pre></td></tr></table></figure><h2 id="BluetoothとSensorTag"><a href="#BluetoothとSensorTag" class="headerlink" title="BluetoothとSensorTag"></a>BluetoothとSensorTag</h2><p>　SensorTagの電源を入れてRaspberry Pi 3からスキャンします。BDアドレスを確認します。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ sudo hcitool lescan</span><br><span class="line">...</span><br><span class="line">B0:B4:48:BE:5E:00 CC2650 SensorTag</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h3 id="gatttool"><a href="#gatttool" class="headerlink" title="gatttool"></a>gatttool</h3><p>　<code>gatttool</code>コマンドのインタラクティブモードで確認したBDアドレスのSensorTagに接続します。</p><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">$ gatttool -b B0:B4:<span class="number">48</span>:BE:<span class="number">5</span>E:<span class="number">00</span> <span class="comment">--interactive</span></span><br><span class="line">[B0:B4:<span class="number">48</span>:BE:<span class="number">5</span>E:<span class="number">00</span>][LE]&gt; <span class="keyword">connect</span></span><br><span class="line">Attempting <span class="keyword">to</span> <span class="keyword">connect</span> <span class="keyword">to</span> B0:B4:<span class="number">48</span>:BE:<span class="number">5</span>E:<span class="number">00</span></span><br><span class="line"><span class="keyword">Connection</span> successful</span><br><span class="line">[B0:B4:<span class="number">48</span>:BE:<span class="number">5</span>E:<span class="number">00</span>][LE]&gt;</span><br></pre></td></tr></table></figure><p>　<a href="http://blog.livedoor.jp/sce_info3-craft/archives/8932936.html">Raspberry PiでTI製センサータグ(CC2650)の値を取得してみる</a>を参考にしてセンサーの値を取得します。</p><ul><li>0x24(config)に01を書いて有効にする</li><li>0x21からバイトを取得する</li></ul><figure class="highlight arduino"><table><tr><td class="code"><pre><span class="line">[B0:B4:<span class="number">48</span>:BE:<span class="number">5</span>E:<span class="number">00</span>][LE]&gt; <span class="keyword">char</span>-<span class="built_in">write</span>-cmd <span class="number">0x24</span> <span class="number">01</span></span><br><span class="line">[B0:B4:<span class="number">48</span>:BE:<span class="number">5</span>E:<span class="number">00</span>][LE]&gt; <span class="keyword">char</span>-<span class="built_in">read</span>-hnd <span class="number">0x21</span></span><br><span class="line">Characteristic value/descriptor: <span class="number">94</span> <span class="number">0b</span> f0 <span class="number">0</span>d</span><br></pre></td></tr></table></figure><p>　4バイトの値が得られます。<a href="http://processors.wiki.ti.com/index.php/SensorTag_User_Guide#IR_Temperature_Sensor">SensorTag User Guide</a>によると順番に以下のデータになります。</p><figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">ObjLSB ObjMSB AmbLSB AmbMSB</span></span><br></pre></td></tr></table></figure><p>　Python REPLから取得した4バイトを摂氏に変換して周辺温度と物体温度を出力します。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>raw_data = <span class="string">&#x27;94 0b f0 0d&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rval = raw_data.split()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>obj_temp = <span class="built_in">int</span>(rval[<span class="number">1</span>] + rval[<span class="number">0</span>], <span class="number">16</span>) / <span class="number">4</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>amb_temp = <span class="built_in">int</span>(rval[<span class="number">3</span>] + rval[<span class="number">2</span>], <span class="number">16</span>) / <span class="number">4</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>obj_temp_celcius = obj_temp * <span class="number">0.03125</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>amb_temp_celcius = amb_temp * <span class="number">0.03125</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(<span class="string">&quot;周囲温度 : &#123;:.2f&#125; ℃&quot;</span>.<span class="built_in">format</span>(amb_temp_celcius))</span><br><span class="line">周囲温度 : <span class="number">27.88</span> ℃</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(<span class="string">&quot;物体温度 : &#123;:.2f&#125; ℃&quot;</span>.<span class="built_in">format</span>(obj_temp_celcius))</span><br><span class="line">物体温度 : <span class="number">23.16</span> ℃</span><br></pre></td></tr></table></figure><h3 id="bluepyのsensortagコマンド"><a href="#bluepyのsensortagコマンド" class="headerlink" title="bluepyのsensortagコマンド"></a>bluepyのsensortagコマンド</h3><p>　PythonからBluetooth LEのデバイスを操作するために<a href="https://github.com/IanHarvey/bluepy.git">bluepy</a>をインストールします。</p><figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get <span class="keyword">install</span> python-pip libglib2.<span class="number">0</span>-dev -y</span><br><span class="line">$ sudo pip <span class="keyword">install</span> bluepy</span><br></pre></td></tr></table></figure><p>　<code>sensortag</code>コマンドが使えるようになります。<code>-T</code>フラグを付けBDアドレスを引数に実行します。</p><figure class="highlight elixir"><table><tr><td class="code"><pre><span class="line"><span class="variable">$ </span>sensortag -T <span class="symbol">B0:</span><span class="symbol">B4:</span><span class="number">48</span><span class="symbol">:BE</span><span class="symbol">:</span><span class="number">5</span><span class="symbol">E:</span>00</span><br></pre></td></tr></table></figure><p>　<code>-T</code>フラグを指定すると周囲温度、物体温度の順番に取得できます。</p><figure class="highlight lasso"><table><tr><td class="code"><pre><span class="line">Connecting <span class="keyword">to</span> B0:B4:<span class="number">48</span>:BE:<span class="number">5</span>E:<span class="number">00</span></span><br><span class="line">(<span class="string">&#x27;Temp: &#x27;</span>, (<span class="number">28.34375</span>, <span class="number">24.25</span>))</span><br><span class="line">(<span class="string">&#x27;Temp: &#x27;</span>, (<span class="number">28.375</span>, <span class="number">23.28125</span>))</span><br><span class="line"><span class="params">...</span></span><br></pre></td></tr></table></figure><h3 id="SensorTag"><a href="#SensorTag" class="headerlink" title="SensorTag"></a>SensorTag</h3><p>　周囲温度(ambient)と物体温度(object)、湿度(humidy)を取得するPythonのスクリプトを書きます。</p><figure class="highlight python"><figcaption><span>~/python_apps/temp.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">from</span> bluepy.sensortag <span class="keyword">import</span> SensorTag</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    argvs = sys.argv</span><br><span class="line">    argc = <span class="built_in">len</span>(argvs)</span><br><span class="line">    <span class="keyword">if</span> (argc != <span class="number">2</span>):</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;Usage: # python &#123;0&#125; bd_address&#x27;</span>.<span class="built_in">format</span>(argvs[<span class="number">0</span>])</span><br><span class="line">        quit()</span><br><span class="line">    host = argvs[<span class="number">1</span>]</span><br><span class="line">    print(<span class="string">&#x27;Connecting to &#x27;</span> + host)</span><br><span class="line"></span><br><span class="line">    timeout = <span class="number">5.0</span></span><br><span class="line">    count = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">    tag = SensorTag(host)</span><br><span class="line"></span><br><span class="line">    tag.IRtemperature.enable()</span><br><span class="line">    tag.humidity.enable()</span><br><span class="line"></span><br><span class="line">    time.sleep(<span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">    counter = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        counter += <span class="number">1</span></span><br><span class="line">        tAmb, tObj = tag.IRtemperature.read()</span><br><span class="line"></span><br><span class="line">        print(<span class="string">&quot;温度: 周囲: &#123;0:.2f&#125;, 物体: &#123;1:.2f&#125;&quot;</span>.<span class="built_in">format</span>(tAmb, tObj) )</span><br><span class="line">        humidy, RH = tag.humidity.read()</span><br><span class="line">        print(<span class="string">&quot;湿度: humidy: &#123;0:.2f&#125;, RH: &#123;1:.2f&#125;&quot;</span>.<span class="built_in">format</span>(humidy, RH))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> counter &gt;= count:</span><br><span class="line">           <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        tag.waitForNotifications(timeout)</span><br><span class="line"></span><br><span class="line">    tag.disconnect()</span><br><span class="line">    <span class="keyword">del</span> tag</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p>　SensorTagのBDアドレスを引数にスクリプトを実行します。</p><figure class="highlight elixir"><table><tr><td class="code"><pre><span class="line"><span class="variable">$ </span>python temp.py <span class="symbol">B0:</span><span class="symbol">B4:</span><span class="number">48</span><span class="symbol">:BE</span><span class="symbol">:</span><span class="number">5</span><span class="symbol">E:</span>00</span><br></pre></td></tr></table></figure><p>　5秒間隔で3回計測した結果を出力します。エアコンが効いてきたので快適になりました。</p><figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">Connecting to B0:B4:48:BE:5E:00</span><br><span class="line"><span class="section">温度: 周囲: 25.03, 物体: 19.94</span></span><br><span class="line"><span class="section">湿度: humidy: 25.25, RH: 69.47</span></span><br><span class="line"><span class="section">温度: 周囲: 25.06, 物体: 20.69</span></span><br><span class="line"><span class="section">湿度: humidy: 25.25, RH: 69.37</span></span><br><span class="line"><span class="section">温度: 周囲: 25.06, 物体: 20.69</span></span><br><span class="line"><span class="section">湿度: humidy: 25.25, RH: 69.37</span></span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      <comments>https://masato.github.io/2017/07/27/sensortag-kafka-python-spark-streaming-1/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Eclipse IoT の紹介 - Part3: Eclipse KuraでOSGiのHello World</title>
      <link>https://masato.github.io/2017/02/06/eclipse-iot-hello-world/</link>
      <guid>https://masato.github.io/2017/02/06/eclipse-iot-hello-world/</guid>
      <pubDate>Mon, 06 Feb 2017 06:46:59 GMT</pubDate>
      <description>
      
        EclipseでOSGiバンドルのHello Worldを開発してEclipse Kuraにリモートからデプロイします。
      
      </description>
      
      
      <content:encoded><![CDATA[<p>　はじめに<a href="http://www.eclipse.org/kura/">Eclipse Kura</a>で採用されているOSGiについて少し復習してから、<a href="http://eclipse.github.io/kura/doc/hello-example.html">ドキュメントサイト</a>にある簡単なHello Woldアプリを開発してEclipse Kuraへデプロイしてみます。</p><span id="more"></span><h2 id="OSGiの復習"><a href="#OSGiの復習" class="headerlink" title="OSGiの復習"></a>OSGiの復習</h2><p>　OSGiはEclipseのプラグインの仕組みに採用されているので名前を聞いたことがある方も多いと思います。1999年に設立された<a href="https://www.osgi.org/">OSGi Alliance</a>が仕様を策定しています。</p><p>　もともと「Open Service Gateway Initiative」と呼ばれるように、家庭やオフィスに設置したゲートウェイ端末上で家電やセンサーなどを制御するプログラムを動かすためのプラットフォームの仕様でした。その後ゲートウェイ以外に車載や組込機器、工場などエンタープライズの分野に採用が広が���ます。</p><h3 id="OSGiバンドルとOSGiフレームワーク"><a href="#OSGiバンドルとOSGiフレームワーク" class="headerlink" title="OSGiバンドルとOSGiフレームワーク"></a>OSGiバンドルとOSGiフレームワーク</h3><p>　リモートから動的にJavaモジュールを追加、更新できるのが特徴です。このモジュールをOSGiバンドルと呼びます。クラスファイルやリソースファイル、マニフェストなどを含んだ通常のjarファイルです。</p><p>　OSGiバンドルはJVMで動作するOSGiフレームワークにインストールします。Eclipse KuraではOSGiフレームワークの実装として<a href="https://projects.eclipse.org/projects/rt.equinox">Eclipse Equinox</a>が採用されています。アプリケーションのコンポーネント化技術として他のモジュールを停止せずに機能の追加や更新ができます。現在主流になりつつあるコンテナ技術をベースにしたマイクロサービスのアーキテクチャと似ています。<a href="http://qiita.com/masato/items/912a447698f172dbb45b">前回</a>調査した、<a href="https://resin.io/">Resin.io</a>や<a href="https://www.ubuntu.com/core">Ubuntu Core</a>もIoT Gatewayのアプリケーション管理に同様のコンテナ化のアプローチを取っています。</p><h2 id="Working-Setの作成"><a href="#Working-Setの作成" class="headerlink" title="Working Setの作成"></a>Working Setの作成</h2><p>　ここからEclipse使いHello Wolrdアプリを開発していきます。まずEclipseで複数のプロジェクトを管理する仕組みとしてワーキングセットを使います。パッケージエクスプローラの三角マークをクリックし���、表示する単位をワーキングセットにします。適当な名前をつけて新しいワーキングセットを作成します。今回は「Kura Projects」にしました。</p><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line">P<span class="function"><span class="title">ackage</span> Exploler -&gt;</span> T<span class="function"><span class="title">op</span> Level Elements -&gt;</span> Working Sets</span><br></pre></td></tr></table></figure><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world1.png" alt="hello-world1.png"></p><h3 id="サンプルプロジェクトをインポート"><a href="#サンプルプロジェクトをインポート" class="headerlink" title="サンプルプロジェクトをインポート"></a>サンプルプロジェクトをインポート</h3><p>　<a href="https://eclipse.github.io/kura/doc/kura-setup.html">Getting Started</a>にあるKuraのサンプルワークスペースから以下の6つのプロジェクトをEclipseにインポートします。</p><ul><li>org.eclipse.kura.demo.heater</li><li>org.eclipse.kura.emulator</li><li>org.eclipse.kura.example.beacon</li><li>org.eclipse.kura.example.ble.tisensortag</li><li>org.eclipse.kura.example.publisher</li><li>target-definition</li></ul><p>　<a href="http://www.eclipse.org/downloads/download.php?file=/kura/releases/2.0.2/user_workspace_archive_2.0.2.zip">Kura User Workspace archive</a>をダウンロードします。Eclipse Kuraは2.0.2をインストールしているので同じバージョンを使います。</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">$ wget http:<span class="regexp">//</span>www.eclipse.org<span class="regexp">/downloads/</span>download.php?file=<span class="regexp">/kura/</span>releases<span class="regexp">/2.0.2/u</span>ser_workspace_archive_2.<span class="number">0.2</span>.zip</span><br></pre></td></tr></table></figure><p>　ダウンロードしたzipファイルをEclipseにインポートします。プロジェクトは先ほど作成した<code>Kura Projets</code>に追加します。</p><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line">F<span class="function"><span class="title">ile</span> -&gt;</span> I<span class="function"><span class="title">mport</span> -&gt;</span> G<span class="function"><span class="title">eneral</span> -&gt;</span> Existing Projects into Workspace</span><br><span class="line">S<span class="function"><span class="title">elect</span> archive file -&gt;</span> <span class="function"><span class="title">user_workspace_archive_2</span>.0.2.zip　-&gt;</span> A<span class="function"><span class="title">dd</span> projects to working sets -&gt;</span> <span class="function"><span class="title">select</span> -&gt;</span> Kura Projects</span><br></pre></td></tr></table></figure><h3 id="プロジェクトの再ビルド"><a href="#プロジェクトの再ビルド" class="headerlink" title="プロジェクトの再ビルド"></a>プロジェクトの再ビルド</h3><p>　target-definitionプロジェクトにあるkura-equinox_3.8.1.targetをTarget Editorで開きます。</p><figure class="highlight clean"><table><tr><td class="code"><pre><span class="line">target-<span class="keyword">definition</span>/kura-equinox_3<span class="number">.8</span><span class="number">.1</span>.target -&gt; 右クリック -&gt; Open With -&gt; Target Editor</span><br></pre></td></tr></table></figure><p>　Target Platformをリセットしてプロジェクトを再ビルドします。</p><figure class="highlight coq"><table><tr><td class="code"><pre><span class="line">Difinitionタブ -&gt; <span class="keyword">Set</span> <span class="built_in">as</span> Target Platformをクリック</span><br></pre></td></tr></table></figure><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world2.png" alt="hello-world2.png"></p><h2 id="Plug-in-プロジェクト"><a href="#Plug-in-プロジェクト" class="headerlink" title="Plug-in プロジェクト"></a>Plug-in プロジェクト</h2><p>　OSGiバンドルの開発はPlug-inプロジェクトで行います。　ウィザードを使いプロジェクトを作成します。</p><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line">F<span class="function"><span class="title">ile</span> -&gt;</span> N<span class="function"><span class="title">ew</span> -&gt;</span> P<span class="function"><span class="title">roject</span> -&gt;</span> P<span class="function"><span class="title">lug</span>-<span class="built_in">in</span> Development  -&gt;</span> Plug-<span class="built_in">in</span> Project</span><br></pre></td></tr></table></figure><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world3.png" alt="hello-world3.png"></p><p>　<a href="http://eclipse.github.io/kura/doc/hello-example.html">Hello World Example</a>の例に沿って新しいプロジェクトを作成します。</p><ul><li>Project name: org.eclipse.kura.example.hello_osgi</li><li>Target Platform: an OSGi framework: チェック</li><li>選択: standard</li></ul><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world4.png" alt="hello-world4.png"></p><p>　ダイアログを次に進みプラグインのプロパティを設定します。</p><ul><li><p>Name: Hello World Example with Logger</p></li><li><p>Execution Environment : JavaSE-1.8</p></li><li><p>Generate an activator… : チェックしない</p></li></ul><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world5.png" alt="hello-world5.png"></p><p>　<code>Kura Projects</code>ワーキングセットに<code>eclipse.kura.example.hello_osgi</code>が作成されました。</p><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world6.png" alt="hello-world6.png"></p><h3 id="MANIFEST-MFの編集"><a href="#MANIFEST-MFの編集" class="headerlink" title="MANIFEST.MFの編集"></a>MANIFEST.MFの編集</h3><p>　OSGiバンドルはバンドルのマニフェストファイルを含むjarファイルです。ここにバンドルのメタデータを定義します。プロジェクトに作成された<code>META-INF/MANIFEST.MF</code>をPlug-in Manifest Editorで開きDependenciesタブをクリックします。</p><figure class="highlight coq"><table><tr><td class="code"><pre><span class="line">META-INF/MANIFEST.MFを右クリック -&gt; <span class="keyword">Open</span> With -&gt; Plug-<span class="built_in">in</span> Manifest Editor -&gt; <span class="keyword">Dependencies</span>タブ</span><br></pre></td></tr></table></figure><p>　dependenciesにjarファイルを追加してファイルの変更を保存します。</p><ul><li>Automated Management of Dependencies を開く</li><li>Add -&gt; org.eclipse.osgi.services -&gt; OK</li><li>Add -&gt; slf4j.api -&gt; OK</li></ul><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world7.png" alt="hello-world7.png"></p><p>　作成されたMANIFEST.MFはEclipseでOpenJDK 8を利用しているため<code>JavaSE-1.8</code>となっています。Java 1.8のままOSGiバンドルをエクスポートすると<code>Export Plug-ins&#39; has encountered a problem.</code>のエラーが出るためJavaSE-1.7に変更します。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Manifest-Version: 1.0</span><br><span class="line">Bundle-ManifestVersion: 2</span><br><span class="line">Bundle-Name: Hello World Example with Logger</span><br><span class="line">Bundle-SymbolicName: org.eclipse.kura.example.hello_osgi</span><br><span class="line">Bundle-Version: 1.0.0.qualifier</span><br><span class="line">Bundle-RequiredExecutionEnvironment: JavaSE-1.7</span><br><span class="line">Import-Package: org.osgi.service.component;version&#x3D;&quot;1.2.0&quot;,</span><br><span class="line"> org.slf4j;version&#x3D;&quot;1.6.4&quot;</span><br><span class="line">Service-Component: component.xml</span><br></pre></td></tr></table></figure><ul><li>Bundle-RequiredExecutionEnvironment: JavaSE-1.7</li></ul><h3 id="Javaクラスの作成"><a href="#Javaクラスの作成" class="headerlink" title="Javaクラスの作成"></a>Javaクラスの作成</h3><p>　プロジェクトにサンプルにあるJavaクラスを作成してactivate()、deactivate()メソッドを定義します。この2つのメソッドはKuraのOSGiフレームワークによってインスタンスがActivate (活性化) 、Deactivate (非活性化)したときに実行され、OSGiバンドルをstart/stopした時に標準出力します。あとでに<code>component.xml</code>に指定します。</p><figure class="highlight coq"><table><tr><td class="code"><pre><span class="line">プロジェクトを右クリック -&gt;  New -&gt; <span class="keyword">Class</span></span><br></pre></td></tr></table></figure><ul><li>Source folder: org.eclipse.kura.example.hello_osgi/src</li><li>Package field: org.eclipse.kura.example.hello_osgi</li><li>Name field: HelloOsgi</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package org.eclipse.kura.example.hello_osgi;</span><br><span class="line"></span><br><span class="line">import org.osgi.service.component.ComponentContext;</span><br><span class="line">import org.slf4j.Logger;</span><br><span class="line">import org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line">public class HelloOsgi &#123;</span><br><span class="line"></span><br><span class="line">    private static final Logger s_logger &#x3D; LoggerFactory.getLogger(HelloOsgi.class);</span><br><span class="line">    private static final String APP_ID &#x3D; &quot;org.eclipse.kura.example.hello_osgi&quot;;</span><br><span class="line"></span><br><span class="line">    protected void activate(ComponentContext componentContext) &#123;</span><br><span class="line">        s_logger.info(&quot;Bundle &quot; + APP_ID + &quot; has started!&quot;);</span><br><span class="line">        s_logger.info(APP_ID + &quot;: This is a debug message.&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    protected void deactivate(ComponentContext componentContext) &#123;</span><br><span class="line">        s_logger.info(&quot;Bundle &quot; + APP_ID + &quot; has stopped!&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="MANIFEST-MFにパッケージを追加"><a href="#MANIFEST-MFにパッケージを追加" class="headerlink" title="MANIFEST.MFにパッケージを追加"></a>MANIFEST.MFにパッケージを追加</h3><p>　MANIFEST.MFファイルをPlug-in Manifest Editorで開きDependencisesタブをクリックします。<code>Automated Management of Dependencies</code>メニューの<code>add dependencies</code> リンクをクリックすると、Javaファイルのimport宣言をベースにして<code>Imported Packages</code>に自動的にjarファイルが追加されます。</p><ul><li>org.osgi.service.component (1.2.0)</li><li>org.slf4j (1.6.4)</li></ul><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world8.png" alt="hello-world8.png"></p><p>　忘れずにMANIFEST.MFファイルの変更を保存して反映しておきます。</p><h3 id="component-xmlの作成"><a href="#component-xmlの作成" class="headerlink" title="component.xmlの作成"></a>component.xmlの作成</h3><p>　次にOSGiコンポーネント定義ファイルの<code>component.xml</code>を作成します。このファイルでHelloOsgi.javaのインスタンスをコンポーネントに定義します。</p><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line">プロジェクトを右クリック -&gt; N<span class="function"><span class="title">ew</span> -&gt;</span> O<span class="function"><span class="title">ther</span> -&gt;</span> P<span class="function"><span class="title">lug</span>-<span class="built_in">in</span> Development -&gt;</span> Component Definition</span><br></pre></td></tr></table></figure><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world9.png" alt="hello-world9.png"></p><p>　現在のプロジェクトのフォルダが選択されていることを確認して、<code>Class</code>の右にあるBrowseボタンをクリッ���します。</p><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world10.png" alt="hello-world10.png"></p><p>　Select entriesのフィールドに<code>hello</code>と入力して先ほど作成したJavaクラスを選択してOKボタンをクリックします。</p><ul><li>Select entries: hello</li><li>Matching items: HelloOsgi</li></ul><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world11.png" alt="hello-world11.png"></p><p>　ウィザードに戻ると選択したクラスが入力された状態になります。最後に<code>component.xml</code>ファイルを保存する<code>OSGI-INF</code>フォルダを入力します。Finishボタンをクリックしてウィザードは終了です。</p><ul><li>Enter or select the parent folder: org.eclipse.kura.example.hello_osgi/OSGI-INF</li></ul><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world12.png" alt="hello-world12.png"></p><p>　component.xmlをComponent Definition Editorで開きます。コンポーネントのライフサイクルは、OSGiフレームワークが管理します。Activate　(活性化)、Deactivate (非活性化)のサイクルで実行するコンポーネントのメソッドを指定します。</p><ul><li>Activate: activate</li><li>Deactivate: deactivate</li></ul><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world13.png" alt="hello-world13.png"></p><p>　XMLファイルのコンポーネント定義が作成されました。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;scr:component xmlns:scr&#x3D;&quot;http:&#x2F;&#x2F;www.osgi.org&#x2F;xmlns&#x2F;scr&#x2F;v1.1.0&quot; activate&#x3D;&quot;activate&quot; deactivate&#x3D;&quot;deactivate&quot; name&#x3D;&quot;org.eclipse.kura.example.hello_osgi&quot;&gt;</span><br><span class="line">   &lt;implementation class&#x3D;&quot;org.eclipse.kura.example.hello_osgi.HelloOsgi&quot;&#x2F;&gt;</span><br><span class="line">&lt;&#x2F;scr:component&gt;</span><br></pre></td></tr></table></figure><h2 id="OSGiバンドルのエクスポート"><a href="#OSGiバンドルのエクスポート" class="headerlink" title="OSGiバンドルのエクスポート"></a>OSGiバンドルのエクスポート</h2><p>　ここまで開発したOSGiバンドルをエクスポートしてEclipse KuraのOSGiフレームワークにデプロイする準備をします。OSGiバンドルのデプロイ方法は、スタンドアロンのOSGiプラグイン形式と、デプロイ管理サービスを使うDeploymentパッケージの2つあります。</p><h3 id="OSGiプラグイン"><a href="#OSGiプラグイン" class="headerlink" title="OSGiプラグイン"></a>OSGiプラグイン</h3><p>　最初にスタンドアロンのOSGiプラグインとしてOSGiバンドルを作成します。</p><figure class="highlight coq"><table><tr><td class="code"><pre><span class="line">プロジェクトを右クリック -&gt; <span class="keyword">Export</span> -&gt; Plug-<span class="built_in">in</span> Development -&gt; Deployable plug-ins and fragments</span><br></pre></td></tr></table></figure><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world14.png" alt="hello-world14.png"></p><p><code>Available Plug-ins and Fragments</code>で作成したOSGiプラグインを選択します。</p><ul><li>org.eclipse.kura.example.hello_osgi</li></ul><p>　Directoryをチェックして右のBrowseボタンをクリックします。jarファイルを保存するローカルのファイルシステムの場所を選択します。</p><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world15.png" alt="hello-world15.png"></p><p>　<code>MANIFEST.MF</code>をJavaSE-1.8をJavaSE-1.7に変更していない場合はこのエクスポートの時にエラーになるため確���しておきます。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Bundle-RequiredExecutionEnvironment: JavaSE-1.7</span><br></pre></td></tr></table></figure><p>　Finishボタンでウィザードを終了すると以下のように指定したフォルダにjarファイルがエクスポートされます。</p><figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">~/myPlugins/plugins/org<span class="selector-class">.eclipse</span><span class="selector-class">.kura</span><span class="selector-class">.example</span><span class="selector-class">.hello_osgi_1</span>.<span class="number">0.0</span>.<span class="number">201702060832</span>.jar</span><br></pre></td></tr></table></figure><h3 id="Deploymentパッケージ"><a href="#Deploymentパッケージ" class="headerlink" title="Deploymentパッケージ"></a>Deploymentパッケージ</h3><p>　次はもう一つのDeploymentパッケージを作成します。拡張子は<code>*.dp</code>のファイルです。<code>*.dpp</code>のパッケージ定義ファイルからビルドして複数のOSGiバンドルをパッケージ化できます。dpファイルはデプロイ管理サービスを使いリモートのEclipse Kuraにデプロイすることができます。</p><p>　最初にdppとdpファイルをエクスポートするフォルダ<code>resources/dp</code>を作成します。</p><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line">プロジェクトを右クリック -&gt; N<span class="function"><span class="title">ew</span> -&gt;</span> F<span class="function"><span class="title">older</span> -&gt;</span> org.eclipse.kura.example.hello_osgi</span><br></pre></td></tr></table></figure><ul><li>folder name: resources/dpを作成</li></ul><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world16.png" alt="hello-world16.png"></p><p>　<code>Deployment Package Definition</code>ウィザードを起動してDeploymentパッケージ定義のdppファイルを作成します。</p><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line">F<span class="function"><span class="title">ile</span> -&gt;</span> N<span class="function"><span class="title">ew</span> -&gt;</span> O<span class="function"><span class="title">ther</span> -&gt;</span> OSG<span class="function"><span class="title">i</span> -&gt;</span> Deployment Package Definition</span><br></pre></td></tr></table></figure><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world17.png" alt="hello-world17.png"></p><p>　ファイルを出力するフォルダとファイル名を指定します。</p><ul><li>Target folder: /org.eclipse.kura.example.hello_osgi/resources/dp</li><li>File name: hello_osgi</li></ul><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world18.png" alt="hello-world18.png"></p><p>　Finishボタンでウィザードを終了すると<code>resources/dp/hello_osgi.dpp</code>に定義ファイルが作成されます。</p><p>　次にhello_osgi.dppファイルをDeployment Editorで開きます。BundlesタブにあるNewボタンをクリックして新しい行を作成したあと、Bundle Pathセルにある<code>...</code>ボタンをクリックします。ここで先ほどmyPluginsフォルダにエクスポートしたOSGiプラグインのjarファイルを選択します。</p><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line">N<span class="function"><span class="title">ew</span> -&gt;</span> B<span class="function"><span class="title">undle</span> Path column -&gt;</span> Browse</span><br></pre></td></tr></table></figure><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world19.png" alt="hello-world19.png"></p><p>　Headersタブは以下のようにキーが入力されます。</p><ul><li>DeploymentPackage-SymbolicName: hello_osgi</li><li>DeploymentPackage-Version: 1.0.0</li></ul><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world20.png" alt="hello-world20.png"></p><p>　dppファイルから<code>Quick Build</code>するとhello_osgi.dpが作成されます。</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">resources<span class="regexp">/dp/</span>hello_osgi.dppを右クリック -&gt; Quick Build</span><br></pre></td></tr></table></figure><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world21.png" alt="hello-world21.png"></p><h2 id="OSGiバンドルのデプロイ-Local-Emulation-Mode"><a href="#OSGiバンドルのデプロイ-Local-Emulation-Mode" class="headerlink" title="OSGiバンドルのデプロイ - Local Emulation Mode"></a>OSGiバンドルのデプロイ - Local Emulation Mode</h2><p>　<a href="http://eclipse.github.io/kura/doc/deploying-bundles.html">Deploying Bundles</a>のページを読みながらOSGiバンドルをデプロイします。</p><h3 id="エミュレータの起動"><a href="#エミュレータの起動" class="headerlink" title="エミュレータの起動"></a>エミュレータの起動</h3><p>　最初に試す<a href="http://eclipse.github.io/kura/doc/deploying-bundles.html#local-emulation-mode">Local Emulation Mode</a>はLinuxとmacOSだけで動作するモードです。KuraのエミュレータをEclipse上で起動してここにOSGiバンドルをデプロイします。</p><p>　 他のプロジェクトが開いているとエミュレータを起動した時に一緒に動いてしまうので、Working SetはインポートしたKuraのサンプルプロジェクトの<code>org.eclipse.kura.emulator</code>と<code>hello_osgi</code>を残し他はcloseしておきます。</p><p>　macOSの場合src/main/resourcesフォルダにあるKura_Emulator_OSXを起動します。</p><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line">/<span class="function"><span class="title">org</span>.eclipse.kura.emulator/src/main/resources/Kura_Emulator_OSX.launch ファイル -&gt;</span> 右クリック -&gt; R<span class="function"><span class="title">un</span> <span class="keyword">as</span> -&gt;</span> Kura_Emulator_OSX</span><br></pre></td></tr></table></figure><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world22.png" alt="hello-world22.png"></p><p>　エミュレータが起動するとhello_osgiのOSGiバンドルにある<code>activate()</code>メソッドが自動的に開始します。EclipseのConsoleにHelloOsgiのログが出力されました。</p><figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line"><span class="number">13</span>:<span class="number">47</span>:<span class="number">07</span>,<span class="number">009</span> <span class="selector-attr">[Component Resolve Thread]</span> INFO  HelloOsgi:<span class="number">13</span>  - Bundle org<span class="selector-class">.eclipse</span><span class="selector-class">.kura</span><span class="selector-class">.example</span><span class="selector-class">.hello_osgi</span> has started!</span><br><span class="line"><span class="number">13</span>:<span class="number">47</span>:<span class="number">07</span>,<span class="number">009</span> <span class="selector-attr">[Component Resolve Thread]</span> INFO  HelloOsgi:<span class="number">14</span>  - org<span class="selector-class">.eclipse</span><span class="selector-class">.kura</span><span class="selector-class">.example</span><span class="selector-class">.hello_osgi</span>: This is <span class="selector-tag">a</span> debug message.</span><br><span class="line">Framework is running <span class="keyword">in</span> emulation mode</span><br></pre></td></tr></table></figure><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world23.png" alt="hello-world23.png"></p><h3 id="OSGiコンソール"><a href="#OSGiコンソール" class="headerlink" title="OSGiコンソール"></a>OSGiコンソール</h3><p>　ConsoleウィンドウをクリックしてEnterキーを押すとOSGiコンソールの<code>osgi&gt;</code>プロンプトが表示されます。ssコマンドでインストールされたOSGiバンドルのリストを表示することができます。バンドルID: 40が今回作成したhello_osgiのOSGiバンドルです。</p><figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">osgi&gt; ss</span><br><span class="line">idState       Bundle</span><br><span class="line"><span class="number">0</span>ACTIVE      org<span class="selector-class">.eclipse</span><span class="selector-class">.osgi_3</span>.<span class="number">8.1</span>.v20120830-<span class="number">144521</span></span><br><span class="line">            Fragments=<span class="number">2</span></span><br><span class="line"><span class="number">1</span>ACTIVE      org<span class="selector-class">.eclipse</span><span class="selector-class">.equinox</span><span class="selector-class">.cm_1</span>.<span class="number">0.400</span>.v20120522-<span class="number">1841</span></span><br><span class="line"><span class="number">2</span>RESOLVED    org<span class="selector-class">.eclipse</span><span class="selector-class">.kura</span><span class="selector-class">.sun</span><span class="selector-class">.misc_1</span>.<span class="number">0.0</span></span><br><span class="line">            Master=<span class="number">0</span></span><br><span class="line"><span class="number">3</span>ACTIVE      org<span class="selector-class">.eclipse</span><span class="selector-class">.equinox</span><span class="selector-class">.common_3</span>.<span class="number">6.100</span>.v20120522-<span class="number">1841</span></span><br><span class="line">...</span><br><span class="line"><span class="number">38</span>ACTIVE      org<span class="selector-class">.apache</span><span class="selector-class">.felix</span><span class="selector-class">.gogo</span><span class="selector-class">.runtime_0</span>.<span class="number">8.0</span>.v201108120515</span><br><span class="line"><span class="number">39</span>ACTIVE      org<span class="selector-class">.apache</span><span class="selector-class">.commons</span><span class="selector-class">.fileupload_1</span>.<span class="number">2.2</span>.v20111214-<span class="number">1400</span></span><br><span class="line"><span class="number">40</span>ACTIVE      org<span class="selector-class">.eclipse</span><span class="selector-class">.kura</span><span class="selector-class">.example</span><span class="selector-class">.hello_osgi_1</span>.<span class="number">0.0</span>.qualifier</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world23.png" alt="hello-world24.png"></p><p>　stopコマンドにバンドルIDを指定して　OSGiバンドルを停止させます。<code>deactivate()</code>メソッドが実行され定義してあるメッセージが出力されました。</p><figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">osgi&gt; stop <span class="number">40</span></span><br><span class="line"><span class="number">09</span>:<span class="number">39</span>:<span class="number">38</span>,<span class="number">217</span> <span class="selector-attr">[Gogo shell]</span> INFO  HelloOsgi:<span class="number">18</span>  - Bundle org<span class="selector-class">.eclipse</span><span class="selector-class">.kura</span><span class="selector-class">.example</span><span class="selector-class">.hello_osgi</span> has stopped!</span><br></pre></td></tr></table></figure><p>　同様にuninstallコマンドにバンドルIDを指定するとOSGiバンドルを削除することができます。</p><figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">osgi&gt; uninstall <span class="number">40</span></span><br><span class="line">osgi&gt; </span><br><span class="line">osgi&gt; ss</span><br><span class="line">...</span><br><span class="line"><span class="number">38</span>ACTIVE      org<span class="selector-class">.apache</span><span class="selector-class">.felix</span><span class="selector-class">.gogo</span><span class="selector-class">.runtime_0</span>.<span class="number">8.0</span>.v201108120515</span><br><span class="line"><span class="number">39</span>ACTIVE      org<span class="selector-class">.apache</span><span class="selector-class">.commons</span><span class="selector-class">.fileupload_1</span>.<span class="number">2.2</span>.v20111214-<span class="number">1400</span></span><br><span class="line"><span class="number">41</span>ACTIVE      org<span class="selector-class">.hsqldb</span><span class="selector-class">.hsqldb_2</span>.<span class="number">3.0</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>　OSGiコンソールから直接OSGiバンドルをインストールしてみます。引数にはOSGiプラグインのjarを指定します。今度はバンドルID: 66でデプロイされました。</p><figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line">osgi&gt; install <span class="keyword">file</span>:<span class="regexp">/Users/m</span>shimizu<span class="regexp">/myPlugins/</span>plugins/org.eclipse.kura.example.hello_osgi_1.<span class="number">0.0</span>.<span class="number">201702060832</span>.jar</span><br><span class="line">Bundle id is <span class="number">66</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world24.png" alt="hello-world24.png"></p><p>　startコマンドにバンドルIDを指定してOSGiバンドルを起動します。<code>activate()</code>メソッドに定義したメッセージが標準出力されました。</p><figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">osgi&gt; start <span class="number">66</span></span><br><span class="line"><span class="number">14</span>:<span class="number">11</span>:<span class="number">37</span>,<span class="number">276</span> <span class="selector-attr">[Component Resolve Thread (Bundle 29)]</span> INFO  HelloOsgi:<span class="number">13</span>  - Bundle org<span class="selector-class">.eclipse</span><span class="selector-class">.kura</span><span class="selector-class">.example</span><span class="selector-class">.hello_osgi</span> has started!</span><br><span class="line"><span class="number">14</span>:<span class="number">11</span>:<span class="number">37</span>,<span class="number">276</span> <span class="selector-attr">[Component Resolve Thread (Bundle 29)]</span> INFO  HelloOsgi:<span class="number">14</span>  - org<span class="selector-class">.eclipse</span><span class="selector-class">.kura</span><span class="selector-class">.example</span><span class="selector-class">.hello_osgi</span>: This is <span class="selector-tag">a</span> debug message.</span><br></pre></td></tr></table></figure><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world25.png" alt="hello-world25.png"></p><h2 id="OSGiバンドルのデプロイ-Remote-Target-Device"><a href="#OSGiバンドルのデプロイ-Remote-Target-Device" class="headerlink" title="OSGiバンドルのデプロイ - Remote Target Device"></a>OSGiバンドルのデプロイ - Remote Target Device</h2><p>　最後に<a href="https://masato.github.io/2017/01/29/eclipse-iot-kura-install/">前回</a>Raspberry Pi 2にインストールしたEclipse KuraのOSGiフレームワークに<a href="http://eclipse.github.io/kura/doc/deploying-bundles.html#remote-target-device">リモートから</a>OSGiバンドルをデプロイしてみます。Raspberry Pi 2はmacOSと有線LANで接続してmDNSで名前解決できるように���ておきます。</p><h3 id="mToolkitのFrameworksビュー"><a href="#mToolkitのFrameworksビュー" class="headerlink" title="mToolkitのFrameworksビュー"></a>mToolkitのFrameworksビュー</h3><p>　Eclipseにインストールした<a href="http://dz.prosyst.com/pdoc/mBS_SDK_8.1/eclipse_plugins/mtoolkit/introduction.html">mToolkit</a>プラグインからリモートのOSGiフレームワークに接続してみます。最初にmToolkitのFrameworksビューを開きます。</p><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line">W<span class="function"><span class="title">indow</span> -&gt;</span> S<span class="function"><span class="title">how</span> View -&gt;</span> O<span class="function"><span class="title">ther</span> -&gt;</span>  <span class="function"><span class="title">mToolkit</span> -&gt;</span> Frameworks </span><br></pre></td></tr></table></figure><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world26.png" alt="hello-world26.png"></p><p>　Frameworksビューを右クリックしてOSGiフレームワークを追加します。</p><figure class="highlight coq"><table><tr><td class="code"><pre><span class="line">右クリック -&gt; <span class="keyword">Add</span> Framework</span><br></pre></td></tr></table></figure><p>　macOSと有線LANで接続したRaspberry Pi 2の名前とアドレスを入力します。mDNSで名前解決する場合は<code>raspberrypi.local</code>、または直接IPアドレスを入力します。</p><ul><li>Name: RPi2</li><li>Address: raspberrypi.local</li></ul><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world27.png" alt="hello-world27.png"></p><p>　Framework名は適当に「RPi2」と名前をつけました。右クリックして接続します。</p><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line">F<span class="function"><span class="title">ramework</span>名を右クリック -&gt;</span> Connect Framework</span><br></pre></td></tr></table></figure><p>　OSGiフレームワークのKuraはファイアウォールでポートを許可する必要があります。KuraのWeb UIからファイアウォールの設定を確認します。</p><p><a href="http://raspberrypi.local/kura">http://raspberrypi.local/kura</a></p><p>　OSGiフレームワークへの接続は1450ポートを使います。デフォルトで許可されていました。</p><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line">F<span class="function"><span class="title">irewall</span> -&gt;</span> O<span class="function"><span class="title">pen</span> Portsタブ -&gt;</span> <span class="number">1450</span>の許可</span><br></pre></td></tr></table></figure><ul><li>Port or Port Range: 1450</li><li>Protocol: tcp</li><li>Permitted Network: 0.0.0.0/0</li><li>Permitted Interface Name: eth0</li></ul><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world28.png" alt="hello-world28.png"></p><h3 id="OSGiプラグイン-1"><a href="#OSGiプラグイン-1" class="headerlink" title="OSGiプラグイン"></a>OSGiプラグイン</h3><p>スタンドアロンのOSGiプラグインのjarを選択してデプロイします。</p><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line">* <span class="function"><span class="title">mToolkit</span> Frameworksビュー -&gt;</span> F<span class="function"><span class="title">ramework</span>名を右クリック -&gt;</span>  I<span class="function"><span class="title">nstall</span> Bundle -&gt;</span> org.eclipse.kura.example.hello_osgi_1.<span class="number">0.0</span>.<span class="number">201702060832</span>.jar</span><br></pre></td></tr></table></figure><p>　Framework名のBundlesにデプロイしたorg.eclipse.kura.example.hello_osgiが表示されます。</p><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world29.png" alt="hello-world29.png"></p><p>　バンドル名を右クリックしてStart、StopするとOSGiコンソールの時と同じように<code>activate()</code>と<code>deactivate()</code>メソッドのメッセージが表示されます。</p><h3 id="Deploymentパッケージ-1"><a href="#Deploymentパッケージ-1" class="headerlink" title="Deploymentパッケージ"></a>Deploymentパッケージ</h3><p>　以前にインストールしたOSGiバンドルはuninstallしておきます。Framework名を右クリックして今度は<code>Install Deployment Package</code>を選択します。</p><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">mToolkit</span> Frameworks view -&gt;</span> F<span class="function"><span class="title">ramework</span>名を右クリック -&gt;</span> Install Deployment Package</span><br></pre></td></tr></table></figure><p>　dpファイルは先ほどエクスポートした<code>hello_osgi.dp</code>ファイルを選択します。</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">~<span class="regexp">/Documents/</span>workspace<span class="regexp">/org.eclipse.kura.example.hello_osgi/</span>resources<span class="regexp">/dp/</span>hello_osgi.dp</span><br></pre></td></tr></table></figure><p>　Deployment Packagesのツリーの中にOSGiバンドルが表示されました。 </p><p><img src="/2017/02/06/eclipse-iot-hello-world/hello-world30.png" alt="hello-world30.png"></p><h3 id="Eclipse-Kuraから確認"><a href="#Eclipse-Kuraから確認" class="headerlink" title="Eclipse Kuraから確認"></a>Eclipse Kuraから確認</h3><p>　Eclipse KuraへmacOSからSSH接続してログを確認します。Hello Worldバンドルのstartとstopのログが表示されています。</p><figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">$ ssh pi@raspberrypi.local</span><br><span class="line">$ tail -f /var/log/kura.log</span><br><span class="line">...</span><br><span class="line"><span class="number">2017</span>-<span class="number">02</span>-<span class="number">08</span> <span class="number">12</span>:<span class="number">38</span>:<span class="number">59</span>,<span class="number">923</span> <span class="selector-attr">[Component Resolve Thread (Bundle 7)]</span> INFO  o<span class="selector-class">.e</span><span class="selector-class">.k</span><span class="selector-class">.e</span><span class="selector-class">.h</span><span class="selector-class">.HelloOsgi</span> - Bundle org<span class="selector-class">.eclipse</span><span class="selector-class">.kura</span><span class="selector-class">.example</span><span class="selector-class">.hello_osgi</span> has started!</span><br><span class="line"><span class="number">2017</span>-<span class="number">02</span>-<span class="number">08</span> <span class="number">12</span>:<span class="number">38</span>:<span class="number">59</span>,<span class="number">925</span> <span class="selector-attr">[Component Resolve Thread (Bundle 7)]</span> INFO  o<span class="selector-class">.e</span><span class="selector-class">.k</span><span class="selector-class">.e</span><span class="selector-class">.h</span><span class="selector-class">.HelloOsgi</span> - org<span class="selector-class">.eclipse</span><span class="selector-class">.kura</span><span class="selector-class">.example</span><span class="selector-class">.hello_osgi</span>: This is <span class="selector-tag">a</span> debug message.</span><br></pre></td></tr></table></figure><p>　teleneでOSGiフレームワークに接続してOSGiバンドルを一覧します。</p><figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">$ telnet localhost <span class="number">5002</span></span><br><span class="line">osgi&gt; ss</span><br><span class="line"><span class="string">&quot;Framework is launched.&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">idState       Bundle</span><br><span class="line"><span class="number">0</span>ACTIVE      org<span class="selector-class">.eclipse</span><span class="selector-class">.osgi_3</span>.<span class="number">8.1</span>.v20120830-<span class="number">144521</span></span><br><span class="line">            Fragments=<span class="number">2</span></span><br><span class="line"><span class="number">1</span>ACTIVE      org<span class="selector-class">.eclipse</span><span class="selector-class">.equinox</span><span class="selector-class">.cm_1</span>.<span class="number">0.400</span>.v20120522-<span class="number">1841</span></span><br><span class="line"><span class="number">2</span>RESOLVED    org<span class="selector-class">.eclipse</span><span class="selector-class">.kura</span><span class="selector-class">.sun</span><span class="selector-class">.misc_1</span>.<span class="number">0.0</span></span><br><span class="line">...</span><br><span class="line"><span class="number">78</span>ACTIVE      org<span class="selector-class">.eclipse</span><span class="selector-class">.kura</span><span class="selector-class">.example</span><span class="selector-class">.hello_osgi_1</span>.<span class="number">0.0</span>.<span class="number">201702081230</span></span><br></pre></td></tr></table></figure><h2 id="OSGiバンドルを永続化する"><a href="#OSGiバンドルを永続化する" class="headerlink" title="OSGiバンドルを永続化する"></a>OSGiバンドルを永続化する</h2><p>　mToolkitからリモートのOSGiフレームワークにデプロイする方法は一時的な方法なのでEclipse Kuraを再起動すると消えてしまいます。</p><h3 id="SCPする場合"><a href="#SCPする場合" class="headerlink" title="SCPする場合"></a>SCPする場合</h3><p>　動作確認が終わったらdpファイルをターゲットデバイスの以下のディレクトリにコピーして永続化します。</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line"><span class="regexp">/opt/</span>eclipse<span class="regexp">/kura/</span>kura/packages</span><br></pre></td></tr></table></figure><p>　macOSから一度Raspberry Pi 2にSCPでdpファイルを転送してから目的のディレクトリにコピーします。</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">$ scp ~<span class="regexp">/Documents/</span>workspace<span class="regexp">/org.eclipse.kura.example.hello_osgi/</span>resources<span class="regexp">/dp/</span>hello_osgi.dp pi@raspberrypi.local:</span><br><span class="line">$ ssh pi@raspberrypi.local</span><br><span class="line">$ sudo cp ~<span class="regexp">/hello_osgi.dp /</span>opt<span class="regexp">/eclipse/</span>kura<span class="regexp">/kura/</span>packages/</span><br></pre></td></tr></table></figure><p> <code>/opt/eclipse/kura/kura/dpa.properties</code>ファイルに以下の書式でパッケージ名とファイルのパスを追加します。</p><figure class="highlight elixir"><table><tr><td class="code"><pre><span class="line">package_name=file\<span class="symbol">:/opt/eclipse/kura/kura/packages/package_filename</span>.dp </span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">org.eclipse.kura.example.hello_osgi&#x3D;file\:&#x2F;opt&#x2F;eclipse&#x2F;kura&#x2F;kura&#x2F;packages&#x2F;hello_osgi.dp</span><br></pre></td></tr></table></figure><p> Eclipse Kuraをリスタートします。restartコマンドを使うとプロセスの停止に失敗することがあるので、stop　-&gt; startします。</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">$ sudo <span class="regexp">/etc/i</span>nit.d/kura stop</span><br><span class="line">$ sudo <span class="regexp">/etc/i</span>nit.d/kura start</span><br></pre></td></tr></table></figure><h3 id="KuraのWeb-UIからアップロードする場合"><a href="#KuraのWeb-UIからアップロードする場合" class="headerlink" title="KuraのWeb UIからアップロードする場合"></a>KuraのWeb UIからアップロードする場合</h3><p>　Eclipse KuraのWeb UIにログインしてdpファイルをアップロードしてもOSGiバンドルは永続化されます。Webブラウザからデプロイできるのでこちらの方が簡単です。左のPackageメニューからdpファイルをSubmitします。</p><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line">P<span class="function"><span class="title">ackage</span> -&gt;</span> U<span class="function"><span class="title">pload</span> - dpファイル -&gt;</span> Submit</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      <comments>https://masato.github.io/2017/02/06/eclipse-iot-hello-world/#disqus_thread</comments>
    </item>
    
    <item>
      <title>IDCFクラウドのUbuntu 16.04を16.10にupgradeしてxrdpリモートデスクトップ環境を構築する</title>
      <link>https://masato.github.io/2017/02/04/idcf-ubuntu-1610-xrdp/</link>
      <guid>https://masato.github.io/2017/02/04/idcf-ubuntu-1610-xrdp/</guid>
      <pubDate>Sat, 04 Feb 2017 06:14:04 GMT</pubDate>
      <description>
      
        IDCFクラウドにUbuntu 16.10 MATEのデスクトップ環境を構築します。
      
      </description>
      
      
      <content:encoded><![CDATA[<p>　クラウド上にLinuxのデスクトップ環境を構築します。プログラミング言語によってはSSH接続してEmacsやVimなどのエディタで十分な場合もあります。JavaやScalaのプログラミングになると<a href="http://eclim.org/index.html">Eclim</a>や<a href="http://ensime.org/">ENSIME</a>といったCUIも使えますが、EclipseなどのGUIが使えると便利な場合があります。開発用にIDCFクラウド上にリモートデスクトップ環境を用意しようと思います。</p><span id="more"></span><h2 id="Ubuntu-16-04にボリュームを追加する"><a href="#Ubuntu-16-04にボリュームを追加する" class="headerlink" title="Ubuntu 16.04にボリュームを追加する"></a>Ubuntu 16.04にボリュームを追加する</h2><p>　最近の開発ではDockerを使うケースがほとんどですし、Mavenの<code>~/.m2</code>ディレクトリなどすぐに1GBを超えてしまいます。IDCFクラウドの標準ではルートディスクが15GBしかディスクがないため、面倒ですがデータディスクを増設して<code>/home</code>や<code>/var</code>にマウントして使います。</p><p>　Ubuntu 16.04のテンプレートの仮想マシンに100GBのボリュームを追加して起動します。<code>/dev/sda1</code>のルートディスクはext4でフォーマットされていました。今回はこのディスクを<code>/home</code>ディレクトリにマウントします。</p><figure class="highlight tap"><table><tr><td class="code"><pre><span class="line"><span class="comment"># df -T</span></span><br><span class="line">Filesystem     Type     1K-blocks    Used Available Use% Mounted on</span><br><span class="line">udev           devtmpfs  <span class="number"> 4065756 </span>     <span class="number"> 0 </span> <span class="number"> 4065756 </span>  0% /dev</span><br><span class="line">tmpfs          tmpfs      <span class="number"> 816668 </span>  <span class="number"> 8912 </span>  <span class="number"> 807756 </span>  2% /run</span><br><span class="line">/dev/sda1      ext4     <span class="number"> 15348720 </span>1721424 <span class="number"> 12824584 </span> 12% /</span><br><span class="line">tmpfs          tmpfs     <span class="number"> 4083324 </span>     <span class="number"> 0 </span> <span class="number"> 4083324 </span>  0% /dev/shm</span><br><span class="line">tmpfs          tmpfs        <span class="number"> 5120 </span>     <span class="number"> 0 </span>    <span class="number"> 5120 </span>  0% /run/lock</span><br><span class="line">tmpfs          tmpfs     <span class="number"> 4083324 </span>     <span class="number"> 0 </span> <span class="number"> 4083324 </span>  0% /sys/fs/cgroup</span><br></pre></td></tr></table></figure><p>　増設した100GBのデータディスクは<code>/dev/sdb</code>のデバイスファイルです。</p><figure class="highlight tap"><table><tr><td class="code"><pre><span class="line"><span class="comment"># fdisk -l</span></span><br><span class="line">...</span><br><span class="line">Disk /dev/sdb:<span class="number"> 100 </span>GiB,<span class="number"> 107374182400 </span>bytes,<span class="number"> 209715200 </span>sectors</span><br><span class="line">Units: sectors of<span class="number"> 1 </span>*<span class="number"> 512 </span>=<span class="number"> 512 </span>bytes</span><br><span class="line">Sector size (logical/physical):<span class="number"> 512 </span>bytes /<span class="number"> 512 </span>bytes</span><br><span class="line">I/O size (minimum/optimal):<span class="number"> 512 </span>bytes /<span class="number"> 512 </span>bytes</span><br></pre></td></tr></table></figure><p>　fdiskコマンドでパーティションを作成してext4でフォーマットします。n -&gt; pと入力して残りはデフォルトでエンターキーを押します。</p><figure class="highlight mel"><table><tr><td class="code"><pre><span class="line"># fdisk /dev/sdb</span><br><span class="line">...</span><br><span class="line">Command (m <span class="keyword">for</span> <span class="keyword">help</span>): n</span><br><span class="line">Partition type</span><br><span class="line">   p   primary (<span class="number">0</span> primary, <span class="number">0</span> extended, <span class="number">4</span> free)</span><br><span class="line">   e   extended (<span class="keyword">container</span> <span class="keyword">for</span> logical partitions)</span><br><span class="line">Select (<span class="keyword">default</span> p): p</span><br><span class="line">Partition number (<span class="number">1</span><span class="number">-4</span>, <span class="keyword">default</span> <span class="number">1</span>):</span><br><span class="line">First sector (<span class="number">2048</span><span class="number">-209715199</span>, <span class="keyword">default</span> <span class="number">2048</span>):</span><br><span class="line">Last sector, +sectors or +<span class="keyword">size</span>&#123;K,M,G,T,P&#125; (<span class="number">2048</span><span class="number">-209715199</span>, <span class="keyword">default</span> <span class="number">209715199</span>):</span><br><span class="line"></span><br><span class="line">Created a new <span class="keyword">partition</span> <span class="number">1</span> of type <span class="string">&#x27;Linux&#x27;</span> and of <span class="keyword">size</span> <span class="number">100</span> GiB.</span><br><span class="line"></span><br><span class="line">Command (m <span class="keyword">for</span> <span class="keyword">help</span>): w</span><br><span class="line">The <span class="keyword">partition</span> table has been altered.</span><br><span class="line">Calling ioctl() to re-read <span class="keyword">partition</span> table.</span><br><span class="line">Syncing disks.</span><br></pre></td></tr></table></figure><p>　作成したパーティションにext4のファイルシステムを作成します。</p><figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line"># mkfs -t ext4 <span class="regexp">/dev/</span>sdb1</span><br></pre></td></tr></table></figure><p>　<code>/home</code>ディレクトリに作業ユーザーを作成します。<code>pwgen</code>コマンドを使いパスワードを生成します。<code>-B</code>フラグを指定するとパスワードとして判別が紛らわしい文字を除外して生成してくれます。</p><figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line"><span class="comment"># apt-get update &amp;&amp; apt-get install -y pwgen</span></span><br><span class="line"><span class="comment"># pwgen -B</span></span><br><span class="line">doquevi9 zoh4ieY9 oqu4jooN EeFei7aV <span class="keyword">sha7Hiet </span>aiha7Le4 Weehoo4a <span class="keyword">eixua7Ua</span></span><br><span class="line"><span class="keyword">...</span></span><br></pre></td></tr></table></figure><p> <code>cloud-user</code>名でユーザーを作成します。管理者ユーザーとして仮想マシン作成時にrootユーザーの<code>/root/authorized_keys</code>に設定された鍵はコピーして使い、<code>sudo</code>もパスワードなして利用できるようにします。この辺りはセキュリティポリシーに従って設定してください。</p><figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line"># useradd -m -d <span class="regexp">/home/</span>cloud-user -s <span class="regexp">/bin/</span>bash cloud-user \</span><br><span class="line"> &amp;&amp; echo <span class="string">&quot;cloud-user:doquevi9&quot;</span> | chpasswd \</span><br><span class="line"> &amp;&amp; mkdir -p <span class="regexp">/home/</span>cloud-user/.ssh \</span><br><span class="line"> &amp;&amp; chmod <span class="number">700</span> <span class="regexp">/home/</span>cloud-user/.ssh \</span><br><span class="line"> &amp;&amp; cp <span class="regexp">/root/</span>.ssh<span class="regexp">/authorized_keys /</span>home<span class="regexp">/cloud-user/</span>.ssh \</span><br><span class="line"> &amp;&amp; chmod <span class="number">600</span> <span class="regexp">/home/</span>cloud-user<span class="regexp">/.ssh/</span>authorized_keys \</span><br><span class="line"> &amp;&amp; chown -R cloud-user:cloud-user <span class="regexp">/home/</span>cloud-user/.ssh \</span><br><span class="line"> &amp;&amp; echo <span class="string">&quot;cloud-user ALL=(ALL) NOPASSWD:ALL&quot;</span> &gt;&gt; <span class="regexp">/etc/</span>sudoers</span><br></pre></td></tr></table></figure><p>　<code>/home</code>を移動するためのマウントポイントを作成して追加ディスクをマウントします。</p><figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line"># mkdir <span class="regexp">/mnt/</span>home</span><br><span class="line"># mount <span class="regexp">/dev/</span>sdb1 <span class="regexp">/mnt/</span>home</span><br></pre></td></tr></table></figure><p>　<code>/home</code>を全て<code>/mnt/home</code>にコピーします。</p><figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line"># cp -a <span class="regexp">/home/</span>* <span class="regexp">/mnt/</span>home</span><br></pre></td></tr></table></figure><p>　既存の<code>/home</code>ディレクトリはリネームしてバックアップしておきます。</p><figure class="highlight vala"><table><tr><td class="code"><pre><span class="line"><span class="meta"># mv /home /home.old</span></span><br><span class="line"><span class="meta"># mkdir /home      </span></span><br></pre></td></tr></table></figure><p>　<code>blkid</code>コマンドで<code>/dev/sdb1</code>のUUIDを調べます。</p><figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line"># blkid <span class="regexp">/dev/</span>sdb1</span><br><span class="line"><span class="regexp">/dev/</span>sdb1: UUID=<span class="string">&quot;7b323902-0182-426a-8d76-991901d69c02&quot;</span> TYPE=<span class="string">&quot;ext4&quot;</span> PARTUUID=<span class="string">&quot;3986d957-01&quot;</span></span><br></pre></td></tr></table></figure><p>　<code>/etc/fstab</code>はバックアップを取ります。</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">$ cp -ip <span class="regexp">/etc/</span>fstab <span class="regexp">/etc/</span>fstab_`date <span class="string">&quot;+%Y%m%d&quot;</span>`</span><br></pre></td></tr></table></figure><p>　<code>/dev/sdb1</code>を<code>/home</code>へマウントする設定を追加します。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">UUID&#x3D;7b323902-0182-426a-8d76-991901d69c02 &#x2F;home ext4 defaults 0  1</span><br></pre></td></tr></table></figure><p>　rebootすると自動的に追加したデータディスクが<code>/home</code>ディレクトリにマウントして使えるようになります。</p><figure class="highlight vala"><table><tr><td class="code"><pre><span class="line"><span class="meta"># reboot</span></span><br></pre></td></tr></table></figure><h2 id="16-04-LTSから16-10へupgradeする"><a href="#16-04-LTSから16-10へupgradeする" class="headerlink" title="16.04 LTSから16.10へupgradeする"></a>16.04 LTSから16.10へupgradeする</h2><p>　IDCFクラウドで利用できる最新のテンプレートはUbuntu Server 16.04 LTSです。<a href="http://www.xrdp.org/">xrdp</a>は0.9から日本語キーボードが標準で使えるようになります。0.9はUbuntu 16.10から標準で利用できるので16.04から16.10へupgradeします。</p><p>　Ubuntuのupgradeは<code>do-release-upgrade</code>コマンドを利用します。またファイルの編集用にデフォルトエディタとして<code>vim</code>もインストールしておきます。</p><figure class="highlight vim"><table><tr><td class="code"><pre><span class="line">$ sudo apt-<span class="built_in">get</span> <span class="keyword">update</span> &amp;&amp; sudo apt-<span class="built_in">get</span> install -<span class="keyword">y</span> <span class="keyword">update</span>-manager-core <span class="keyword">vim</span></span><br></pre></td></tr></table></figure><p>　<code>/etc/update-manager/release-upgrades</code>ファイルを<code>normal</code>に編集してLTS版からアップグレードできるようにします。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[DEFAULT]</span><br><span class="line">#Prompt&#x3D;lts</span><br><span class="line">Prompt&#x3D;normal </span><br></pre></td></tr></table></figure><p>　Ubuntu 16.04 LTSから16.10にupgradeします。</p><figure class="highlight arduino"><table><tr><td class="code"><pre><span class="line">$ sudo <span class="keyword">do</span>-<span class="built_in">release</span>-upgrade</span><br></pre></td></tr></table></figure><p>　SSH接続でupgradeをしているため途中で失敗して接続が切れる場合を考慮して、新しく別のポートでSSH接続しておきます。</p><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">This <span class="keyword">session</span> appears <span class="keyword">to</span> be running under ssh. It <span class="keyword">is</span> <span class="keyword">not</span> recommended</span><br><span class="line"><span class="keyword">to</span> <span class="keyword">perform</span> a upgrade <span class="keyword">over</span> ssh currently because <span class="keyword">in</span> <span class="keyword">case</span> <span class="keyword">of</span> failure it</span><br><span class="line"><span class="keyword">is</span> harder <span class="keyword">to</span> recover.</span><br><span class="line"></span><br><span class="line"><span class="keyword">If</span> you <span class="keyword">continue</span>, an additional ssh daemon will be started at port</span><br><span class="line"><span class="string">&#x27;1022&#x27;</span>.</span><br><span class="line"><span class="keyword">Do</span> you want <span class="keyword">to</span> <span class="keyword">continue</span>?</span><br><span class="line"></span><br><span class="line"><span class="keyword">Continue</span> [yN]</span><br></pre></td></tr></table></figure><p>　別のターミナルで1022ポートで接続を確認してからupgrade作業を継続します。</p><figure class="highlight arduino"><table><tr><td class="code"><pre><span class="line">To <span class="keyword">continue</span> please <span class="built_in">press</span> [ENTER]</span><br></pre></td></tr></table></figure><p>　upgradeには時間がかかります。<code>y</code>を押して作業を開始します。</p><figure class="highlight livecodeserver"><table><tr><td class="code"><pre><span class="line">Fetching <span class="keyword">and</span> installing <span class="keyword">the</span> upgrade can take several hours. Once <span class="keyword">the</span></span><br><span class="line">download has finished, <span class="keyword">the</span> <span class="built_in">process</span> cannot be canceled.</span><br><span class="line"></span><br><span class="line"> Continue [yN]  Details [d]</span><br></pre></td></tr></table></figure><p>　upgrade作業中にいくつかダイアログが表示されます。デフォルトで以下のように選択しました。</p><ul><li>Postfix Configuration: No configuration</li><li>Configuring grub-pc: keep the local version currently installed</li><li>/etc/update-manager/release-upgrades: N</li><li>Remove obsolete packages?: y</li><li>System upgrade is complete.: y</li></ul><p>　rebootするとupgrade作業は終了です。SSH接続し直してバージョンを確認します。</p><figure class="highlight avrasm"><table><tr><td class="code"><pre><span class="line">$ lsb_release -rd</span><br><span class="line"><span class="symbol">Description:</span>    Ubuntu <span class="number">16.10</span></span><br><span class="line"><span class="symbol">Release:</span>        <span class="number">16.10</span></span><br></pre></td></tr></table></figure><h2 id="xrdp"><a href="#xrdp" class="headerlink" title="xrdp"></a>xrdp</h2><p>　Ubuntu 16.10にupgradeするとxrdpは0.9が使えるようになります。</p><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">$ sudo apt-<span class="keyword">get</span> <span class="keyword">update</span></span><br><span class="line">$ apt-<span class="keyword">cache</span> show xrdp | grep Version</span><br><span class="line">Version: <span class="number">0.9</span><span class="number">.0</span>~<span class="number">20160601</span>+git703fedd<span class="number">-3</span></span><br></pre></td></tr></table></figure><p>　xrdpをインストールして起動設定をします。</p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="variable">$</span> sudo apt<span class="literal">-get</span> install xrdp <span class="literal">-y</span></span><br><span class="line"><span class="variable">$</span> sudo systemctl enable xrdp.service</span><br><span class="line"><span class="variable">$</span> sudo systemctl <span class="built_in">start</span> xrdp.service</span><br></pre></td></tr></table></figure><h3 id="MATE"><a href="#MATE" class="headerlink" title="MATE"></a>MATE</h3><p>　クラウドでの利用に適した軽量なデスクトップ環境もいろいろありますが、GNOME2から派生した<a href="http://mate-desktop.org/">MATE</a>が好みなので良く使います。</p><figure class="highlight crmsh"><table><tr><td class="code"><pre><span class="line">$ apt-cache show mate-core | grep <span class="keyword">Version</span></span><br><span class="line"><span class="keyword">Version</span>: <span class="number">1.16</span>.<span class="number">0</span>+<span class="number">1</span></span><br></pre></td></tr></table></figure><p>　バージョンは1.16です。</p><figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">$ sudo apt update &amp;&amp; sudo apt <span class="keyword">install </span>mate-core mate-desktop-environment mate-desktop-environment-<span class="keyword">extra </span>-y</span><br></pre></td></tr></table></figure><h3 id="日本語入力"><a href="#日本語入力" class="headerlink" title="日本語入力"></a>日本語入力</h3><p>　日本語のIMEは<a href="https://github.com/google/mozc">Mozc</a>を使います。</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">$ sudo apt-<span class="builtin-name">get</span> install ibus-mozc -y</span><br></pre></td></tr></table></figure><p> <code>~/.xsession</code>にibusとMATEの起動を設定します。</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">$ cat &lt;&lt;EOF &gt; ~/.xsession</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">GTK_IM_MODULE</span>=ibus</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">QT_IM_MODULE</span>=ibus</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">XMODIFIERS</span>=<span class="string">&quot;@im=ibus&quot;</span></span><br><span class="line">ibus-daemon -rdx</span><br><span class="line">mate-session</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p> rebootするとxrdp接続でMATEのリモートデスクトップ環境が使えるようになります。</p><figure class="highlight elixir"><table><tr><td class="code"><pre><span class="line"><span class="variable">$ </span>sudo reboot</span><br></pre></td></tr></table></figure><p>　IDCFクラウドの管理コンソースからIPアドレスを追加して、3389ポートのファイアウォールと作成した仮想マシンへのポートフォワードを設定します。Windows 10の場合標準のリモートデスクトップが使えます。追加したIPアドレスを指定して接続します。macOSの場合は日本語キーボードが使える<a href="http://www.microsoft.com/ja-jp/download/details.aspx?id=18140">Microsoft Remote Desktop Connection Client for Mac 2.1.1</a>をインストールします。</p><p>　管理ユーザーとして作成した<code>cloud-user</code>とパスワードを入力してログインします。</p><p><img src="/2017/02/04/idcf-ubuntu-1610-xrdp/ubuntu-mate.png" alt="ubuntu-mate.png"></p><p>　MATE Terminalを開きます。</p><ul><li>Applications -&gt; Sytem Tools -&gt; MATE Terminal</li></ul><p>　<code>ibus-setup</code>を実行して日本語IMEにMozcを指定します。</p><figure class="highlight arduino"><table><tr><td class="code"><pre><span class="line">$ ibus-<span class="built_in">setup</span></span><br></pre></td></tr></table></figure><ul><li>Input Method -&gt; Add -&gt; Japanese -&gt; Mozc -&gt; Add</li></ul><p> Fireroxを使い日本語入力を確認します。</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">$ sudo apt-<span class="builtin-name">get</span> install -y firefox</span><br></pre></td></tr></table></figure><ul><li>Applications -&gt; Internet -&gt; Firefox Web Browser</li></ul><p>　右上メニューをJapanese-Japanese から Japanese-Mozcに変更するとアイコンが「あ」になり日本語入力ができるようになります。</p><p><img src="/2017/02/04/idcf-ubuntu-1610-xrdp/ubuntu-mate-japanese.png" alt="ubuntu-mate-japanese.png"></p><p>　Windows 10の場合はの半角/全角キー、macOSの場合は半角キーで日本語入力を切り換えることができます。</p>]]></content:encoded>
      
      <comments>https://masato.github.io/2017/02/04/idcf-ubuntu-1610-xrdp/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Eclipse IoT の紹介 - Part2: macOS SierraにEclipse Neon.2をインストールする</title>
      <link>https://masato.github.io/2017/02/01/eclipse-iot-eclipse-neon2-setup/</link>
      <guid>https://masato.github.io/2017/02/01/eclipse-iot-eclipse-neon2-setup/</guid>
      <pubDate>Wed, 01 Feb 2017 03:25:41 GMT</pubDate>
      <description>
      
        Eclipse KuraにインストールするOSGiバンドル開発用にEclipse IDE for Java Developersをインストールします。
      
      </description>
      
      
      <content:encoded><![CDATA[<p>　<a href="http://www.eclipse.org/kura/">Eclipse Kura</a>の<a href="https://www.osgi.org/">OSGi</a>ベースのIoT Gatewayのためのフレームワークです。アプリはjarファイルにマニフェストやリソースファイルを追加してパッケージングしたOSGiバンドルをデプロイして使います。今回はEclipuse Kuraのアプリのプログラミング環境としてmacOS Sierraに<a href="https://www.eclipse.org/downloads/packages/eclipse-ide-java-developers/neon2">Eclipse IDE for Java Developers</a>をインストールして簡単な初期設定を行います。</p><span id="more"></span><h2 id="Java-8"><a href="#Java-8" class="headerlink" title="Java 8"></a>Java 8</h2><p>　macOSのパッケージ管理ツールの<a href="http://brew.sh/">Homebrew</a>と<a href="https://caskroom.github.io/">Homebrew Cask</a>からJava 8をインストールします。Oracleの<a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html">ダウンロードサイト</a>から直接パッケージをダウンロードすることもできます。</p><p>　まだHombrewを使ったことがない場合はインストールします。</p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="variable">$</span> ruby <span class="literal">-e</span> <span class="string">&quot;<span class="variable">$</span>(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;</span></span><br></pre></td></tr></table></figure><p>　インストール済みの場合は、古いHombrewとパッケージを更新して最新の状態にします。</p><figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">$ <span class="keyword">brew </span>update &amp;&amp; <span class="keyword">brew </span>cleanup</span><br></pre></td></tr></table></figure><p>　<a href="https://caskroom.github.io/">Homebrew Cask</a>をインストールします。</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">$ brew install caskroom<span class="regexp">/cask/</span>brew-cask</span><br></pre></td></tr></table></figure><p>　<a href="https://github.com/caskroom/homebrew-versions">versions</a>を追加して<code>java</code>を検索します。</p><figure class="highlight elixir"><table><tr><td class="code"><pre><span class="line"><span class="variable">$ </span>brew tap caskroom/versions</span><br><span class="line"><span class="variable">$ </span>brew search java</span><br></pre></td></tr></table></figure><p>　現在の<code>java</code>パッケージのバージョンは<code>1.8.0_112</code>です。</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">$ brew cask info java</span><br><span class="line">java: <span class="number">1.8</span>.<span class="number">0</span>_112-b16</span><br><span class="line">https:<span class="regexp">//</span>www.oracle.com<span class="regexp">/technetwork/</span>java<span class="regexp">/javase/</span>downloads/jdk8-downloads-<span class="number">2133151</span>.html</span><br><span class="line">Not installed</span><br></pre></td></tr></table></figure><p>　Java8をインストールします。</p><figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">$ <span class="keyword">brew </span>cask <span class="keyword">install </span><span class="keyword">java</span></span><br></pre></td></tr></table></figure><p>　<code>1.8.0_112</code>のバージョンがインストールされました。</p><figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">$ <span class="keyword">java </span>-version</span><br><span class="line"><span class="keyword">java </span>version <span class="string">&quot;1.8.0_112&quot;</span></span><br><span class="line"><span class="keyword">Java(TM) </span>SE Runtime Environment (<span class="keyword">build </span><span class="number">1</span>.<span class="number">8</span>.<span class="number">0</span>_112-<span class="keyword">b16)</span></span><br><span class="line"><span class="keyword">Java </span>HotSpot(TM) <span class="number">64</span>-<span class="keyword">Bit </span>Server VM (<span class="keyword">build </span><span class="number">25</span>.<span class="number">112</span>-<span class="keyword">b16, </span>mixed mode)</span><br></pre></td></tr></table></figure><p>　以下のコマンドを実行すると<code>JAVA_HOME</code>の場所を確認できます。</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">$ <span class="regexp">/usr/</span>libexec/java_home -v <span class="number">1.8</span></span><br><span class="line"><span class="regexp">/Library/</span>Java<span class="regexp">/JavaVirtualMachines/</span>jdk1.<span class="number">8.0</span>_112.jdk<span class="regexp">/Contents/</span>Home</span><br></pre></td></tr></table></figure><p>　<code>~/.bashrc</code>に環境変数の<code>JAVA_HOME</code>を設定します。</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">$ echo <span class="string">&#x27;export JAVA_HOME=`/usr/libexec/java_home -v 1.8`&#x27;</span> &gt;&gt; ~/.bashrc</span><br><span class="line">$ source ~/.bashrc</span><br><span class="line">$ echo <span class="variable">$JAVA_HOME</span></span><br><span class="line"><span class="regexp">/Library/</span>Java<span class="regexp">/JavaVirtualMachines/</span>jdk1.<span class="number">8.0</span>_112.jdk<span class="regexp">/Contents/</span>Home</span><br></pre></td></tr></table></figure><h2 id="Maven"><a href="#Maven" class="headerlink" title="Maven"></a>Maven</h2><p>　Javaアプリのビルドツールの<a href="https://maven.apache.org/">Maven</a>をインストールします。MavenやGradle、stbなどVMの開発ツールをインストールする場合は<a href="http://sdkman.io/">SDKMAN!</a>が便利です。</p><p>　SDKMAN!をインストールします。</p><figure class="highlight arcade"><table><tr><td class="code"><pre><span class="line">$ curl -s get.sdkman.io | <span class="regexp">/bin/</span>bash</span><br></pre></td></tr></table></figure><p>　<code>sdk</code>コマンドからMavenをインストールします。</p><figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">$ sdk <span class="keyword">install</span> maven </span><br></pre></td></tr></table></figure><p>　<code>3.3.9</code>のバージョンがインストールされました。</p><figure class="highlight llvm"><table><tr><td class="code"><pre><span class="line">$ mvn --version</span><br><span class="line">Apache Maven <span class="number">3.3</span>.<span class="number">9</span> (bb<span class="number">52</span>d<span class="number">8502</span>b<span class="number">132</span>ec<span class="number">0</span>a<span class="number">5</span>a<span class="number">3</span>f<span class="number">4</span><span class="keyword">c</span><span class="number">09453</span><span class="keyword">c</span><span class="number">07478323</span>dc<span class="number">5</span><span class="comment">; 2015-11-11T01:41:47+09:00)</span></span><br></pre></td></tr></table></figure><h2 id="Eclipse-Neon-2-4-6-2"><a href="#Eclipse-Neon-2-4-6-2" class="headerlink" title="Eclipse Neon.2 (4.6.2)"></a>Eclipse Neon.2 (4.6.2)</h2><p>　macOS用のインストーラーを<a href="http://www.eclipse.org/downloads/eclipse-packages/">ダウンロードサイト</a>から取得します。<br>　<br><img src="/2017/02/01/eclipse-iot-eclipse-neon2-setup/eclipse-downloads.png" alt="eclipse-downloads.png"></p><p>　<code>eclipse-inst-mac64.tar.gz</code>ファイルから解凍した<code>Eclipse Installer</code>を実行します。以下のディレクトリの<code>Eclipse</code>を起動します。</p><figure class="highlight arcade"><table><tr><td class="code"><pre><span class="line">~<span class="regexp">/eclipse/</span>java-neon/Eclipse</span><br></pre></td></tr></table></figure><h2 id="初期設定"><a href="#初期設定" class="headerlink" title="初期設定"></a>初期設定</h2><p>　複数人で開発する場合はEclipseの設定を統一しておくとバージョン管理でdiffが正確に取れます。以下の私の好みなのでチームの規約に合わせて設定を確認してください。</p><h3 id="ファイルのタブは空白にする"><a href="#ファイルのタブは空白にする" class="headerlink" title="ファイルのタブは空白にする"></a>ファイルのタブは空白にする</h3><p>　Eclipseの環境設定メニューからJavaのFormatterに新しいプロファイルの作成します。適当に<code>Eclise [myproject]</code>としました。</p><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line">E<span class="function"><span class="title">clipse</span> -&gt;</span> 環境設定 -&gt; J<span class="function"><span class="title">ava</span> -&gt;</span> C<span class="function"><span class="title">ode</span> Style -&gt;</span> F<span class="function"><span class="title">ormatter</span> -&gt;</span> N<span class="function"><span class="title">ew</span> -&gt;</span> Eclipse [myproject] </span><br></pre></td></tr></table></figure><p><img src="/2017/02/01/eclipse-iot-eclipse-neon2-setup/java-formatter.png" alt="java-formatter.png"></p><p>　<code>Indentation</code>タブを以下の設定にします。</p><ul><li>Tab policy: Spaces only</li><li>Indentation size: 4</li><li>Tab size: 4</li></ul><p><img src="/2017/02/01/eclipse-iot-eclipse-neon2-setup/java-formatter-indent.png" alt="java-formatter-indent.png"></p><p>　Mavenで使うpom.xmlなどXMファイルも同様に設定します。</p><figure class="highlight clean"><table><tr><td class="code"><pre><span class="line">Eclipse -&gt; 環境設定 -&gt; XML -&gt; XML Files -&gt; Editor</span><br></pre></td></tr></table></figure><ul><li>Indent using spaces: チェック</li><li>Indentation size: 2 </li></ul><p><img src="/2017/02/01/eclipse-iot-eclipse-neon2-setup/xml-formatter.png" alt="xml-formatter.png"></p><h3 id="ファイルの末尾は空白除去する"><a href="#ファイルの末尾は空白除去する" class="headerlink" title="ファイルの末尾は空白除去する"></a>ファイルの末尾は空白除去する</h3><p> Java Code Styleに<code>Clean Up</code>に新しいプロファイルの作成します。</p><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line">E<span class="function"><span class="title">clipse</span> -&gt;</span> 環境設定 -&gt; J<span class="function"><span class="title">ava</span> -&gt;</span> C<span class="function"><span class="title">ode</span> Style -&gt;</span> C<span class="function"><span class="title">lean</span> Up -&gt;</span> N<span class="function"><span class="title">ew</span> -&gt;</span> Eclipse [myproject]</span><br></pre></td></tr></table></figure><p><img src="/2017/02/01/eclipse-iot-eclipse-neon2-setup/java-cleanup.png" alt="java-cleanup.png"></p><ul><li>Remove trailing whitespace: チェック</li></ul><p><img src="/2017/02/01/eclipse-iot-eclipse-neon2-setup/java-cleanup-tailtrail.png" alt="java-cleanup-tailtrail.png"></p><p>　既存のソースファイルから末尾の空白を除去する場合はこの<code>Clean UP</code>を実行します。</p><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">src</span> -&gt;</span> 右クリック -&gt; S<span class="function"><span class="title">ource</span> -&gt;</span> Clean UP</span><br></pre></td></tr></table></figure><p>　ファイル保存時に末尾の空白を削除する場合は<code>Save Actions</code>を使います。</p><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line">E<span class="function"><span class="title">clipse</span> -&gt;</span> 環境設定 -&gt;　J<span class="function"><span class="title">ava</span> -&gt;</span> E<span class="function"><span class="title">ditor</span> -&gt;</span> Save Actions</span><br></pre></td></tr></table></figure><p><img src="/2017/02/01/eclipse-iot-eclipse-neon2-setup/java-save-actions.png" alt="java-save-actions.png"></p><ul><li>Perform the selected actions on save: チェック</li></ul><p>　Additional actionsの設定を変更します。</p><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line">A<span class="function"><span class="title">dditional</span> actions -&gt;</span> Configure</span><br></pre></td></tr></table></figure><ul><li>Remove trailing whitespace：　チェック</li><li>All lines: チェック</li></ul><p><img src="/2017/02/01/eclipse-iot-eclipse-neon2-setup/java-save-actions-configure.png" alt="java-save-actions-configure.png"></p><h3 id="テーマ"><a href="#テーマ" class="headerlink" title="テーマ"></a>テーマ</h3><p>　Eclipseの外観を<code>Dark</code>テーマを変えたい場合は以下の設定をします。</p><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line">E<span class="function"><span class="title">clipse</span> -&gt;</span> 環境設定 -&gt; G<span class="function"><span class="title">eneral</span> -&gt;</span> Apperance</span><br></pre></td></tr></table></figure><ul><li>Theme: Dark</li></ul><p><img src="/2017/02/01/eclipse-iot-eclipse-neon2-setup/appearance-theme.png" alt="appearance-theme.png"></p><h2 id="プラグイン"><a href="#プラグイン" class="headerlink" title="プラグイン"></a>プラグイン</h2><p>　EclipseのプラグインもOSGiバンドルとして配布されています。プラグインも好みですがとりあえず最初に必要なプラグインをいくつかインストールします。</p><h3 id="EGit-プラグイン"><a href="#EGit-プラグイン" class="headerlink" title="EGit プラグイン"></a>EGit プラグイン</h3><p>　<a href="http://www.eclipse.org/egit/">EGit</a>プラグインはEclipseからGitを操作することができます。EGitのダウンロードサイトを追加します。</p><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line">H<span class="function"><span class="title">elp</span> -&gt;</span> I<span class="function"><span class="title">nstall</span> New Software... -&gt;</span> Add</span><br></pre></td></tr></table></figure><ul><li>Name: EGit</li><li>Location: <a href="http://download.eclipse.org/egit/updates">http://download.eclipse.org/egit/updates</a></li></ul><p>　使いたいパッケージをチェックしてインストールします。</p><ul><li>Git integration for Eclipse</li><li>Java implementation of Git</li></ul><p><img src="/2017/02/01/eclipse-iot-eclipse-neon2-setup/egit.png" alt="egit.png"></p><p>　EclipseからSSH経由でGitリポジトリを使う場合は秘密鍵の設定を行います。</p><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line">E<span class="function"><span class="title">clipse</span> -&gt;</span> 環境設定 -&gt; G<span class="function"><span class="title">eneral</span> -&gt;</span> N<span class="function"><span class="title">etwork</span> Connections -&gt;</span> SSH2</span><br></pre></td></tr></table></figure><ul><li>SSH2 home: ホームディレクトリの<code>~/.ssh</code>など</li><li>Private keys: GitHubに登録してある公開鍵とペアの秘密鍵など</li></ul><p><img src="/2017/02/01/eclipse-iot-eclipse-neon2-setup/general-ssh2.png" alt="general-ssh2.png"></p><p>　Gitパースペクティブを開きます。</p><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line">W<span class="function"><span class="title">indow</span> -&gt;</span> P<span class="function"><span class="title">ersepective</span> -&gt;</span> O<span class="function"><span class="title">pen</span> Persepective -&gt;</span> O<span class="function"><span class="title">ther</span> -&gt;</span> Git</span><br></pre></td></tr></table></figure><h3 id="M2Eclipse-m2e-プラグイン"><a href="#M2Eclipse-m2e-プラグイン" class="headerlink" title="M2Eclipse (m2e) プラグイン"></a>M2Eclipse (m2e) プラグイン</h3><p> <a href="http://www.eclipse.org/m2e/">M2Eclipse</a>はEclipseからMavenコマンドを実行することができます。プラグインはインストール済みですが、ダウンロードサイトを追加しておきます。</p><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line">H<span class="function"><span class="title">elp</span> -&gt;</span> I<span class="function"><span class="title">nstall</span> New Software... -&gt;</span> Add</span><br></pre></td></tr></table></figure><ul><li>Name: m2e</li><li>Location: <a href="http://download.eclipse.org/technology/m2e/releases">http://download.eclipse.org/technology/m2e/releases</a></li></ul><h3 id="Maven-SCM-Handler-for-EGit"><a href="#Maven-SCM-Handler-for-EGit" class="headerlink" title="Maven SCM Handler for EGit"></a>Maven SCM Handler for EGit</h3><p>　<a href="https://github.com/tesla/m2eclipse-egit">Maven SCM Handler for EGit</a>はm2eから直接<code>git clone</code>してのpom.xmlの依存関係を解決してくれます。</p><p>　パッケージエクスプローラーにプロジェクトをインポートするときのダイアログの中で、m2e Marketplaceからインストールします。</p><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">Package Explorer &gt; <span class="keyword">Import</span> &gt; Maven &gt; <span class="keyword">Check</span> <span class="keyword">out</span> Maven Projects <span class="keyword">from</span> SCM &gt; m2e Marketplace &gt; m2e-egit</span><br></pre></td></tr></table></figure><p><img src="/2017/02/01/eclipse-iot-eclipse-neon2-setup/m2e-marketplace.png" alt="m2e-marketplace.png"></p><p>　Eclipsをリスタートしてインストール終了です。</p><h3 id="mToolkitプラグイン"><a href="#mToolkitプラグイン" class="headerlink" title="mToolkitプラグイン"></a>mToolkitプラグイン</h3><p>　これから<a href="https://eclipse.github.io/kura/">Eclipse Kura Documentation</a>を読みながらEclipseで簡単なOSGiのアプリをビルドしていこうと思います。準備としてEclipse Kura上で動作するOSGiコンテナにリモートから接続できる<a href="http://dz.prosyst.com/pdoc/mBS_SDK_8.1/eclipse_plugins/mtoolkit/introduction.html">mToolkit</a>のプラグインをインストールします。<a href="http://www.bosch.com/en/com/home/index.php">Bosch</a>グループの<a href="http://www.prosyst.com/">ProSyst</a>が提供しているOSGi管理ツールの<a href="https://dz.prosyst.com/pdoc/mBS_SDK_8.1/getting_started/stepbystep.html">mBS SDK</a>に含まれています。</p><figure class="highlight xl"><table><tr><td class="code"><pre><span class="line">H<span class="function"><span class="title">elp</span> -&gt;</span> I<span class="function"><span class="title">nstall</span> New Software... -&gt;</span> Add</span><br></pre></td></tr></table></figure><ul><li>Name: mtoolkit</li><li>Location: <a href="http://mtoolkit-neon.s3-website-us-east-1.amazonaws.com/">http://mtoolkit-neon.s3-website-us-east-1.amazonaws.com</a></li></ul><ul><li>Group items by category: チェックを外す</li><li>mTooklit: チェック</li></ul><h3 id="Plug-in-Development-Environment-PDE-プラグイン"><a href="#Plug-in-Development-Environment-PDE-プラグイン" class="headerlink" title="Plug-in Development Environment (PDE)　プラグイン"></a>Plug-in Development Environment (PDE)　プラグイン</h3><p>　<a href="http://www.eclipse.org/pde/">Plug-in Development Environment (PDE)</a>はEclipseのプラグインを開発するためのツールです。OSGiプロジェクトの開発ではComponent Definition (component.xml)を作成するウィザードを利用します。</p><figure class="highlight lasso"><table><tr><td class="code"><pre><span class="line">Help -&gt; Install <span class="literal">New</span> Software<span class="params">...</span></span><br></pre></td></tr></table></figure><p> <code>type filter text</code>フィールドに<code>Eclipse plug-in</code>を入力して検索します。</p><ul><li>Work with: Neon - <a href="http://download.eclipse.org/releases/neon">http://download.eclipse.org/releases/neon</a></li><li>type filter text: Eclipse plug-in</li><li>Eclipse Plug-in Development Environment: チェック</li></ul><p><img src="/2017/02/01/eclipse-iot-eclipse-neon2-setup/plugin-install.png" alt="plugin-install.png"></p><p>　これでEclipse KuraのOSGiバンドル開発のためのEclipse Neon.2のセットアップは終了です。次回はサンプルプロジェクトをビルドして動かして見ようと思います。</p>]]></content:encoded>
      
      <comments>https://masato.github.io/2017/02/01/eclipse-iot-eclipse-neon2-setup/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Eclipse IoT の紹介 - Part1: Eclipse KuraをRaspberry Piにインストールする</title>
      <link>https://masato.github.io/2017/01/29/eclipse-iot-kura-install/</link>
      <guid>https://masato.github.io/2017/01/29/eclipse-iot-kura-install/</guid>
      <pubDate>Sun, 29 Jan 2017 06:48:28 GMT</pubDate>
      <description>
      
        IoT Gatewayについて調査をしていくつかのプロダクトを試しました。Eclipse Kuraが今のところ実績もあり使いやすそうです。Eclipse IoTプロジェクトの一つで、Raspberry PiやBeagle Bone Black上でIoT Gatewayとして動作するOSGiのオープンソースフレームワークです。
      
      </description>
      
      
      <content:encoded><![CDATA[<p>　<a href="http://qiita.com/masato/items/912a447698f172dbb45b">IoT Gatewayについて</a>調査をしていくつかのプロダクトを試しました。<a href="http://www.eclipse.org/kura/">Eclipse Kura</a>が今のところ実績もあり使いやすそうです。<a href="http://iot.eclipse.org/">Eclipse IoTプロジェクト</a>の一つで、Raspberry PiやBeagle Bone Black上でIoT Gatewayとして動作する<a href="https://www.osgi.org/">OSGi</a>のオープンソースフレームワークです。Eclipse Kuraを拡張した<a href="http://www.eurotech.com/jp/products/software+services/everyware+software+framework">ESF</a>とハードウェアの<a href="http://www.eurotech.com/jp/products/software+services/m2m+products">ReliaGATE</a>シリーズも<a href="http://www.eurotech.com/">Eurotech</a>から提供されています。プロダクション環境でサポートが必要な場合はライセンスを購入すると安心できそうです。</p><span id="more"></span><p>　<a href="https://iot.eclipse.org/">Eclipse IoT</a>プロジェクトは他にも<a href="https://projects.eclipse.org/proposals/eclipse-kapua">Eclipse Kapua</a>、<a href="https://projects.eclipse.org/projects/iot.hono">Eclipse Hono</a>、<a href="http://www.eclipse.org/vorto/">Eclipse Vorto</a>、<a href="http://www.eclipse.org/leshan/">Eclipse Leshan</a>といったクラウドのバックエンド側プロジェクトもあります。<a href="https://www.redhat.com/en">Red Hat</a>、<a href="http://www.eurotech.com/en/">Eurotech</a>、<a href="http://www.bosch.com/en/com/home/index.php">Bosh</a>、<a href="https://www.ge.com/digital/">GE Digital</a>といった企業が乱立気味のIoTプラットフォームの相互接続性と、デバイスからのデータをエンタープライズのアプリケーションに統合することを目標にオープンソースで開発を進めています。バックエンドサービスは<a href="https://www.cloudfoundry.org/">Cloud Foundry</a>や<a href="https://www.openshift.com/">OpanShift</a>といった最近のDockerベースのクラウドプラットフォーム上で動作することにも注目です。</p><p>　まずは身近なところから、Raspberry Pi 2にEclipse Kuraをインストールすることから始めます。</p><h2 id="Raspbian-Jessie-Lite"><a href="#Raspbian-Jessie-Lite" class="headerlink" title="Raspbian Jessie Lite"></a>Raspbian Jessie Lite</h2><p>　Raspbianのセットアップ方法は<a href="https://www.raspberrypi.org/documentation/installation/installing-images/">オフィシャル</a>をはじめにたくさん記事がありますが、2016-11-25の<a href="http://downloads.raspberrypi.org/raspbian/release_notes.txt">リリース</a>からSSHがデフォルトで無効になり注意が必要です。SDカードにイメージを焼いた状態のままではSSHで接続することができません。</p><blockquote><p>2016-11-25:</p></blockquote><ul><li>SSH disabled by default; can be enabled by creating a file with name “ssh” in boot partition</li></ul><p>　ローカルの作業用PCとRaspberry Pi 2を有線LANで接続してヘッドレスインストールする例を簡単にまとめておきます。そのほかには無線LAN USBアダプターなどが必要です。</p><ul><li><p><a href="https://www.amazon.co.jp/dp/B00ESA34GA/">無線LAN USBアダプター</a></p></li><li><p><a href="https://www.amazon.co.jp/dp/B00LVH885U/">有線LAN USBアダプター</a></p></li><li><p><a href="https://www.amazon.co.jp/dp/B008RVY4GK/">LANケーブル</a></p></li></ul><h3 id="SDカードにイメージを焼く"><a href="#SDカードにイメージを焼く" class="headerlink" title="SDカードにイメージを焼く"></a>SDカードにイメージを焼く</h3><p>　SDカードをUSBアダプタに挿して作業用PCに接続します。Fat32でフォーマットされたSDカードのデバイス名を確認してアンマウントします。この例では/dev/disk2です。</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">$ diskutil list</span><br><span class="line">$ diskutil unmountDisk <span class="regexp">/dev/</span>disk2</span><br></pre></td></tr></table></figure><p>　Raspbian Jessie Liteを<a href="https://www.raspberrypi.org/downloads/raspbian/">ダウンロードページ</a>から取得してイメージを解凍します。</p><figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line">$ cd ~/Downloads</span><br><span class="line">$ wget https://downloads.raspberrypi.org/raspbian/images/raspbian<span class="string">-2017</span><span class="string">-01</span><span class="string">-10</span>/2017<span class="string">-01</span><span class="string">-11</span>-raspbian-jessie.zip</span><br><span class="line">$ unzip 2017<span class="string">-01</span><span class="string">-11</span>-raspbian-jessie.zip</span><br></pre></td></tr></table></figure><p>　イメージをSDカードに焼きます。確認したデバイス名に<code>r</code>をつけて<code>/dev/rdisk2</code>を指定します。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ sudo dd bs&#x3D;1m if&#x3D;2017-01-11-raspbian-jessie-lite.img of&#x3D;&#x2F;dev&#x2F;rdisk2</span><br></pre></td></tr></table></figure><p>　Windows 10でRasbianイメージのSDカードを作る場合は<a href="https://ja.osdn.net/projects/sfnet_win32diskimager/">Win32 Disk Imager</a>が便利です。</p><h3 id="SSHを有効にする"><a href="#SSHを有効にする" class="headerlink" title="SSHを有効にする"></a>SSHを有効にする</h3><p>　SSHはデフォルトで無効になっています。macOSのボリュームにマウントした状態でsshファイルを作り有効にします。</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">$ touch <span class="regexp">/Volumes/</span>boot/ssh</span><br></pre></td></tr></table></figure><p>　Windows 10には<code>touch</code>に相当するコマンドがないため、SDカードのDドライブに移動して<code>COPY</code>コマンドで代用します。エクスプローラーからDドライブに直接ファイルを作成する場合は<code>.txt</code>など拡張子をつけないように注意します。</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">&gt; d:</span><br><span class="line">&gt; copy /y nul ssh</span><br><span class="line">&gt; <span class="keyword">exit</span></span><br></pre></td></tr></table></figure><p>　SDカードをアンマウントして取り出します。</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">$ diskutil unmountDisk <span class="regexp">/dev/</span>disk2</span><br></pre></td></tr></table></figure><p>　SDカードをRaspberry Pi 2にさして電源を入れます。macOSとLANケーブルで直接つなぎます。最新のRaspbianはデフォルトでmDNSが有効になりmacOSやWindows10から<code>raspberrypi.local</code>のホスト名で簡単に接続できます。</p><figure class="highlight julia"><table><tr><td class="code"><pre><span class="line">$ ssh <span class="literal">pi</span><span class="meta">@raspberrypi</span>.<span class="keyword">local</span></span><br></pre></td></tr></table></figure><p>　ユーザー名は<code>pi</code>、パスワードは<code>raspbian</code>が設定されています。SSHのデフォルトが無効なのは変更せずにこのまま使う人が多いためらしく、忘れずにパスワードを変更します。</p><figure class="highlight elixir"><table><tr><td class="code"><pre><span class="line"><span class="variable">$ </span>passwd</span><br></pre></td></tr></table></figure><p>　公開鍵を<code>~/.ssh/authorized_keys</code>に追加しSSH接続で利用します。</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">$ mkdir ~/.ssh</span><br><span class="line">$ chmod <span class="number">700</span> ~/.ssh</span><br><span class="line">$ cat &lt;&lt;EOF &gt; ~<span class="regexp">/.ssh/</span>authorized_keys</span><br><span class="line">ssh-rsa AAAAB...</span><br><span class="line">EOF</span><br><span class="line">$ chmod <span class="number">600</span> ~<span class="regexp">/.ssh/</span>authorized_keys</span><br><span class="line">$ <span class="keyword">exit</span></span><br></pre></td></tr></table></figure><h3 id="初期設定"><a href="#初期設定" class="headerlink" title="初期設定"></a>初期設定</h3><p>　raspi-configから初期設定を行います。</p><figure class="highlight arduino"><table><tr><td class="code"><pre><span class="line">$ sudo raspi-<span class="built_in">config</span></span><br></pre></td></tr></table></figure><p>　ファイルシステムの拡張は必ず行います。localeとtimezoneはユーザー環境にあわせて設定します。</p><ul><li>1 Expand Filesystem</li><li>4 Internationalisation Options<ul><li>I1 Change Locale -&gt; en_GB.UTF-8のまま</li><li>I2 Change Timezone -&gt; Asia -&gt; Tokyo</li></ul></li></ul><p>　localeを<code>jp_JP.UTF-8</code>にすると文字化けする場合があるので<code>en_GB.UTF-8</code>のまま使います。一度rebootします。</p><p>　Raspberry Piに日本語キーボードを使う場合はレイアウトを変更します。SSH接続では不要ですが、Windows 10とRaspberry Piを有線LANで接続するとmDNSの<code>raspberrypi.local</code>でうまくSSH接続できないことがあります。キーボードとディスプレイが必要になる場合があるため設定します。</p><ul><li>4 Localisation Options</li><li>I3 Change Keyboard Layout  -&gt; Generic 105-key (Intl) PC -&gt; Japanese -&gt;  The default for the keyboard layout -&gt;  No compose key</li></ul><figure class="highlight elixir"><table><tr><td class="code"><pre><span class="line"><span class="variable">$ </span>sudo reboot</span><br></pre></td></tr></table></figure><h3 id="無線LAN"><a href="#無線LAN" class="headerlink" title="無線LAN"></a>無線LAN</h3><p>　Raspberry Pi 2には無線LANが内蔵されていません。USBの無線LANアダプタを用意しておきます。wlan0で利用する無線LANのアクセスポイントをスキャンしてESSIDを確認します。</p><figure class="highlight 1c"><table><tr><td class="code"><pre><span class="line">$ sudo iwlist wlan0 scan <span class="string">| grep ESSID</span></span><br></pre></td></tr></table></figure><p>　wpa_passphraseコマンドにESSIDとパスワードを渡し、出力を<code>wpa_supplicant.conf</code>に追記します。(例の<code>[</code>と<code>]</code>は不要です。)</p><figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line">$ sudo sh -c &#x27;wp<span class="built_in">a_passphrase</span> [ESSID] [パスワード] &gt;&gt; /etc/wp<span class="built_in">a_supplicant</span>/wp<span class="built_in">a_supplicant</span>.conf&#x27;</span><br></pre></td></tr></table></figure><p>　アクセスポイントを複数指定する場合は<code>priority</code>で接続する優先度を指定します。数字が大きいほど有線されます。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">country&#x3D;GB</span><br><span class="line">ctrl_interface&#x3D;DIR&#x3D;&#x2F;var&#x2F;run&#x2F;wpa_supplicant GROUP&#x3D;netdev</span><br><span class="line">update_config&#x3D;1</span><br><span class="line">network&#x3D;&#123;</span><br><span class="line">        ssid&#x3D;&quot;xxx&quot;</span><br><span class="line">        #psk&#x3D;&quot;xxx&quot;</span><br><span class="line">        psk&#x3D;xxx</span><br><span class="line">        priority&#x3D;0</span><br><span class="line">&#125;</span><br><span class="line">network&#x3D;&#123;</span><br><span class="line">        ssid&#x3D;&quot;xxx&quot;</span><br><span class="line">        #psk&#x3D;&quot;xxx&quot;</span><br><span class="line">        psk&#x3D;xxx</span><br><span class="line">        priority&#x3D;1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>　wlan0のインタフェースにDHCPと先ほどのwpa_supplicant.confを設定します。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">auto lo</span><br><span class="line">iface lo inet loopback</span><br><span class="line"></span><br><span class="line">iface eth0 inet manual</span><br><span class="line"></span><br><span class="line">allow-hotplug wlan0</span><br><span class="line">iface wlan0 inet dhcp</span><br><span class="line">    wpa-conf &#x2F;etc&#x2F;wpa_supplicant&#x2F;wpa_supplicant.conf</span><br></pre></td></tr></table></figure><p>　wlan0を再起動してDHCPでIPアドレスを取得します。</p><figure class="highlight elixir"><table><tr><td class="code"><pre><span class="line"><span class="variable">$ </span>sudo ifdown wlan0</span><br><span class="line"><span class="variable">$ </span>sudo ifup wlan0</span><br></pre></td></tr></table></figure><p> <code>ip</code>コマンドなどを使いwlan0が正常に起動しているか確認します。</p><figure class="highlight elixir"><table><tr><td class="code"><pre><span class="line"><span class="variable">$ </span>sudo iwconfig wlan0</span><br><span class="line"><span class="variable">$ </span>ip addr show wlan0</span><br><span class="line"><span class="variable">$ </span>ping -c <span class="number">1</span> www.yahoo.co.jp</span><br></pre></td></tr></table></figure><h2 id="パッケージの更新"><a href="#パッケージの更新" class="headerlink" title="パッケージの更新"></a>パッケージの更新</h2><p>　ネットワークがつながるようになったので以降の作業を進める前にインストールされているパッケージを更新します。</p><h3 id="apt-get-ミラーサイト"><a href="#apt-get-ミラーサイト" class="headerlink" title="apt-get ミラーサイト"></a>apt-get ミラーサイト</h3><p>　apt-getのデフォルトは<code>mirrordirector.raspbian.org</code>のリポジトリに接続します。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">deb http:&#x2F;&#x2F;mirrordirector.raspbian.org&#x2F;raspbian&#x2F; jessie main contrib non-free rpi</span><br><span class="line"># Uncomment line below then &#39;apt-get update&#39; to enable &#39;apt-get source&#39;</span><br><span class="line">#deb-src http:&#x2F;&#x2F;archive.raspbian.org&#x2F;raspbian&#x2F; jessie main contrib non-free rpi</span><br></pre></td></tr></table></figure><p>　なるべく近くのミラーサイトを<a href="http://www.raspbian.org/RaspbianMirrors">RaspbianMirrors</a>から選びます。今回は<a href="http://ftp.jaist.ac.jp/raspbian">JAIST</a>にしました。</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">$ sudo sed -i<span class="string">&quot;.bak&quot;</span> -e <span class="string">&quot;s/mirrordirector.raspbian.org/ftp.jaist.ac.jp/g&quot;</span> <span class="regexp">/etc/</span>apt/sources.list</span><br></pre></td></tr></table></figure><h3 id="パッケージ更新"><a href="#パッケージ更新" class="headerlink" title="パッケージ更新"></a>パッケージ更新</h3><p> パッケージリストを更新してパッケージを最新の状態にします。</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">$ sudo apt-<span class="builtin-name">get</span> update &amp;&amp; sudo apt-<span class="builtin-name">get</span> dist-upgrade -y</span><br></pre></td></tr></table></figure><p>　nanoエディタが使いづらい場合はvimをインストールしてファイルを編集します。</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">$ sudo apt-<span class="builtin-name">get</span> update &amp;&amp; sudo apt-<span class="builtin-name">get</span> install vim -y</span><br></pre></td></tr></table></figure><h2 id="Eclipse-Kuraのインストール"><a href="#Eclipse-Kuraのインストール" class="headerlink" title="Eclipse Kuraのインストール"></a>Eclipse Kuraのインストール</h2><p>　Raspbianの初期設定が終わったところでようやくEclipse Kuraのインストールを始めていきます。</p><h3 id="OpenJDK-8"><a href="#OpenJDK-8" class="headerlink" title="OpenJDK 8"></a>OpenJDK 8</h3><p>　Eclipse Kuraの動作には<a href="https://wiki.eclipse.org/Kura/Getting_Started#Java">JDK 7以上</a>が必要です。最新の<a href="http://openjdk.java.net/">Open JDK 8</a>を使います。</p><figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get update &amp;&amp; sudo apt-get <span class="keyword">install </span>-y openjdk<span class="number">-8</span>-<span class="keyword">jre-headless</span></span><br><span class="line"><span class="keyword">$ </span><span class="keyword">java </span>-version</span><br><span class="line">openjdk version <span class="string">&quot;1.8.0_40-internal&quot;</span></span><br><span class="line">OpenJDK Runtime Environment (<span class="keyword">build </span><span class="number">1</span>.<span class="number">8</span>.<span class="number">0</span>_40-internal-<span class="keyword">b04)</span></span><br><span class="line"><span class="keyword">OpenJDK </span><span class="built_in">Zero</span> VM (<span class="keyword">build </span><span class="number">25</span>.<span class="number">40</span>-<span class="keyword">b08, </span>interpreted mode)</span><br></pre></td></tr></table></figure><h3 id="Eclipse-Kura-2-0-2"><a href="#Eclipse-Kura-2-0-2" class="headerlink" title="Eclipse Kura 2.0.2"></a>Eclipse Kura 2.0.2</h3><p>　<a href="https://eclipse.github.io/kura/doc/raspberry-pi-quick-start.html">Raspberry Pi Quick Start</a>の手順に従いKuraをインストールします。</p><p>　dhcpcd5 パッケージはKuraと互換性がないため削除します。</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">$ sudo apt-<span class="builtin-name">get</span> purge -y dhcpcd5</span><br></pre></td></tr></table></figure><p>　NetworkManagerもKuraと競合するためインストールされていないことを確認します。</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">$ sudo apt-<span class="builtin-name">get</span> <span class="builtin-name">remove</span> -y network-manager</span><br></pre></td></tr></table></figure><p>　パッケージの依存関係を解決してKuraをインストールするために<a href="https://launchpad.net/gdebi">GDebi</a>をインストールします。</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">$ sudo apt-<span class="builtin-name">get</span> update &amp;&amp; sudo apt-<span class="builtin-name">get</span> install -y gdebi-core</span><br></pre></td></tr></table></figure><p>　<a href="https://projects.eclipse.org/projects/iot.kura/releases/2.0.2">Eclipse Kura 2.0.2</a>をダウンロードして使います。</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">$ wget http:<span class="regexp">//</span>eclipse.stu.edu.tw<span class="regexp">/kura/</span>releases<span class="regexp">/2.0.2/</span>kura_2.<span class="number">0.2</span>_raspberry-pi-<span class="number">2</span>_installer.deb</span><br><span class="line">$ sudo gdebi kura_2.<span class="number">0.2</span>_raspberry-pi-<span class="number">2</span>_installer.deb</span><br></pre></td></tr></table></figure><p>　rebootするとEclipse Kuraが起動します。</p><figure class="highlight elixir"><table><tr><td class="code"><pre><span class="line"><span class="variable">$ </span>sudo reboot</span><br></pre></td></tr></table></figure><p>　Eclipse Kuraの起動には時間がかかるためSSH接続したらログを</p><figure class="highlight gams"><table><tr><td class="code"><pre><span class="line"><span class="symbol">$</span> sudo tail /var/<span class="built_in">log</span>/kura.<span class="built_in">log</span></span><br></pre></td></tr></table></figure><h2 id="Eclipse-Kura-WebUI"><a href="#Eclipse-Kura-WebUI" class="headerlink" title="Eclipse Kura WebUI"></a>Eclipse Kura WebUI</h2><p>　Raspberry PiにWebブラウザから以下のURLに接続するとWebコンソールが表示されます。</p><p>Eclipse Kura WebUI<br><a href="http://raspberrypi.local/kura">http://raspberrypi.local/kura</a></p><p>　Basic認証のユーザー名とパスワードはadminです。</p><ul><li>username: admin</li><li>password: admin</li></ul><p>　Cloud ServiceやNetwork設定はこれからですが、とりあえずEclipse Kuraのインストールは終了です。</p><p><img src="/2017/01/29/eclipse-iot-kura-install/kapua-console.png" alt="kapua-console.png"></p>]]></content:encoded>
      
      <comments>https://masato.github.io/2017/01/29/eclipse-iot-kura-install/#disqus_thread</comments>
    </item>
    
    <item>
      <title>iPhoneのヘルスケアデータから歩数を日別に集計してCSVファイルにする</title>
      <link>https://masato.github.io/2016/12/12/iphone-health-data-steps-csv/</link>
      <guid>https://masato.github.io/2016/12/12/iphone-health-data-steps-csv/</guid>
      <pubDate>Mon, 12 Dec 2016 07:46:26 GMT</pubDate>
      <description>
      
        Android WearやApple Watchが出始めの頃は楽しんで着けていたのですが、やはり時計は気に入ったものをしたいので活動量計としても使わなくなってしまいました。
      
      </description>
      
      
      <content:encoded><![CDATA[<p>　Android WearやApple Watchが出始めの頃は楽しんで着けていたのですが、やはり時計は気に入ったものをしたいので活動量計としても使わなくなってしまいました。活動量計を着けなくても日常持ち歩いているiPhoneには標準でヘルスケアデータを記録できるアプリがインストールされています。データも溜まってきたのでiPhoneから書き出してデータ分析用に使ってみたいと思います。　</p><span id="more"></span><h2 id="iPhoneからヘルスケアデータを書き出す"><a href="#iPhoneからヘルスケアデータを書き出す" class="headerlink" title="iPhoneからヘルスケアデータを書き出す"></a>iPhoneからヘルスケアデータを書き出す</h2><p>　iPhoneアプリのヘルスケアを開き右上のプロファイルアイコンをタップします。</p><p><img src="/2016/12/12/iphone-health-data-steps-csv/health-1.png" alt="health-1.png"></p><p>　プロファイルページにある<code>ヘルスケアデータを書き出す</code>をタップします。<br>　<br><img src="/2016/12/12/iphone-health-data-steps-csv/health-2.png" alt="healt-2.png"><br>　<br>　確認ダイアログの<code>書き出す</code>をタップします。<br>　<br><img src="/2016/12/12/iphone-health-data-steps-csv/health-3.png" alt="healt-3.png"></p><p>　ヘルスケアデータを書き出したいサービスをタップします。<br>　<br><img src="/2016/12/12/iphone-health-data-steps-csv/health-4.png" alt="healt-4.png"></p><p>　<br>　iCloud Driveを選択すると同期しているPCのiCloud Driveフォルダに<code>書き出したデータ.zip</code>のファイル名でアーカイブが保存されます。　</p><h2 id="CSVコンバーター"><a href="#CSVコンバーター" class="headerlink" title="CSVコンバーター"></a>CSVコンバーター</h2><p>　ヘルスケアデータは<code>書き出したデータ.zip</code>の中にあるXML形式の<code>書き出したデータ.xml</code>ファイルです。歩数データはエクセルで管理しているのでコピー＆ペーストしやすいようにCSVにコンバートするスクリプトを書きました。<br>　<br>　<br>　使い方は最初に<a href="https://github.com/masato/health-data-csv.git">ここ</a>からリポジトリをcloneします。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ git <span class="built_in">clone</span> https://github.com/masato/health-data-csv.git</span><br><span class="line">$ <span class="built_in">cd</span> health-data-csv</span><br></pre></td></tr></table></figure><p>　<code>書き出したデータ.zip</code>ファイルをcloneしたディレクトリにコピーします。macOSの場合iCloud Driveは以下のディレクトリになります。パスに半角スペースがあるためダブルクォートします。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ cp <span class="string">&quot;<span class="variable">$HOME</span>/Library/Mobile Documents/com~apple~CloudDocs/書き出したデータ.zip&quot;</span> .</span><br></pre></td></tr></table></figure><p>　<code>convert.py</code>はZipファイルからヘルスケアデータのXMLを取り出し歩数を日別に集計してCSVファイルに出力するPythonスクリプトです。<code>type</code>を<code>HKQuantityTypeIdentifierStepCount</code>に指定して<code>Record</code>要素から歩数データだけ抽出しています。<a href="https://www.amazon.co.jp/dp/4873116554/">Pythonによるデータ分析入門 ―NumPy、pandasを使ったデータ処理</a>を勉強しているところなのでデータ分析ツールの<a href="http://pandas.pydata.org/">pandas</a>を使い集計とCSVへの書き出しを実装してみます。<br>　<br>　<a href="http://qiita.com/methane/items/8493c10c19ca3584d31d">Python 3 で日本語ファイル名が入った zip ファイルを扱う</a>の記事によると<code>書き出したデータ.xml</code>のように日本語ファイル名は<code>cp437</code>でデコードされるようです。</p><figure class="highlight python"><figcaption><span>convert.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> objectify</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> DataFrame</span><br><span class="line"><span class="keyword">from</span> dateutil.parser <span class="keyword">import</span> parse</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> sys, os</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">argv</span>):</span></span><br><span class="line"></span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;-f&#x27;</span>, <span class="string">&#x27;--file&#x27;</span>,</span><br><span class="line">                        default=<span class="string">&#x27;書き出した.zip&#x27;</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;zipファイル名 (書き出した.zip)&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;-s&#x27;</span>, <span class="string">&#x27;--start&#x27;</span>,</span><br><span class="line">                        action=<span class="string">&#x27;store&#x27;</span>,</span><br><span class="line">                        default=<span class="string">&#x27;2016-01-01&#x27;</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;開始日 (2016-12-01)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(args.file):</span><br><span class="line">        print(<span class="string">&#x27;zipファイル名を指定してください。&#x27;</span>)</span><br><span class="line">        parser.print_help()</span><br><span class="line">        sys.exit(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    zipfile.ZipFile(args.file).extractall()</span><br><span class="line"></span><br><span class="line">    parsed = objectify.parse(<span class="built_in">open</span>(<span class="string">&#x27;apple_health_export/書き出したデータ.xml&#x27;</span></span><br><span class="line">                                  .encode(<span class="string">&#x27;utf-8&#x27;</span>).decode(<span class="string">&#x27;cp437&#x27;</span>)))</span><br><span class="line"></span><br><span class="line">    root = parsed.getroot()</span><br><span class="line"></span><br><span class="line">    headers = [<span class="string">&#x27;type&#x27;</span>, <span class="string">&#x27;unit&#x27;</span>, <span class="string">&#x27;startDate&#x27;</span>, <span class="string">&#x27;endDate&#x27;</span>, <span class="string">&#x27;value&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    data = [(&#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> elt.attrib.items() <span class="keyword">if</span> k <span class="keyword">in</span> headers&#125;)</span><br><span class="line">            <span class="keyword">for</span> elt <span class="keyword">in</span> root.Record]</span><br><span class="line"></span><br><span class="line">    df = DataFrame(data)</span><br><span class="line">    df.index = pd.to_datetime(df[<span class="string">&#x27;startDate&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 歩数だけ</span></span><br><span class="line">    steps = df[df[<span class="string">&#x27;type&#x27;</span>] == <span class="string">&#x27;HKQuantityTypeIdentifierStepCount&#x27;</span>].copy()</span><br><span class="line">    steps[<span class="string">&#x27;value&#x27;</span>] = steps[<span class="string">&#x27;value&#x27;</span>].astype(<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 開始日が条件にある場合スライス</span></span><br><span class="line">    <span class="keyword">if</span> args.start:</span><br><span class="line">        steps = steps.loc[args.start:]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 日別にグループ化して集計</span></span><br><span class="line">    steps_sum = steps.groupby(pd.TimeGrouper(freq=<span class="string">&#x27;D&#x27;</span>)).<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">    steps_sum.T.to_csv(<span class="string">&#x27;./steps_&#123;0&#125;.csv&#x27;</span>.<span class="built_in">format</span>(datetime.now().strftime(<span class="string">&#x27;%Y%m%d%H%M%S&#x27;</span>)),</span><br><span class="line">                       index=<span class="literal">False</span>, float_format=<span class="string">&#x27;%.0f&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main(sys.argv[<span class="number">1</span>:])</span><br></pre></td></tr></table></figure><h2 id="Pythonスクリプトの実行"><a href="#Pythonスクリプトの実行" class="headerlink" title="Pythonスクリプトの実行"></a>Pythonスクリプトの実行</h2><p>　スクリプトの実行はDockerイメージは<a href="https://github.com/ContinuumIO/docker-images/tree/master/anaconda3">continuumio/anaconda3</a>を使います。データ分析に<a href="https://www.continuum.io/downloads">Anaconda</a>を使うDockerイメージです。<a href="http://jupyter.org/">Jupyter</a>もインストールされています。<br>　<br>　Pythonスクリプトは<code>-f</code>フラグでヘルスケアから書き出したカレントディレクトリにあるzipファイル名を指定します。<code>-s</code>フラグはCSVにコンバートするレコードの開始日を指定できます。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker pull continuumio/anaconda3</span><br><span class="line">$ docker run -it --rm \</span><br><span class="line">  -v <span class="variable">$PWD</span>:/app \</span><br><span class="line">  -w /app \</span><br><span class="line">  continuumio/anaconda3 \</span><br><span class="line">  python convert.py -f 書き出したデータ.zip -s 2016-12-01</span><br></pre></td></tr></table></figure><p>　カレントディレクトリに「steps_xxx.csv」のような歩数を日別に集計したCSVファイルが作成されました。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ cat steps_20161212013800.csv</span><br><span class="line">2016-12-01,2016-12-02,2016-12-03,2016-12-04,2016-12-05,2016-12-06,2016-12-07,2016-12-08,2016-12-09,2016-12-10,2016-12-11</span><br><span class="line">7217,8815,2260,1828,3711,6980,7839,5079,7197,7112,2958</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      <comments>https://masato.github.io/2016/12/12/iphone-health-data-steps-csv/#disqus_thread</comments>
    </item>
    
    <item>
      <title>myThingsをはじめよう - Part9: konashiをmyThingsのトリガーとアクションに使う</title>
      <link>https://masato.github.io/2015/09/22/mythings-idcfchannel-konashi/</link>
      <guid>https://masato.github.io/2015/09/22/mythings-idcfchannel-konashi/</guid>
      <pubDate>Tue, 22 Sep 2015 12:24:23 GMT</pubDate>
      <description>
      
        前回はkonashi.jsのアプリをFramework7で書いてHTML5でネイティブ風な画面を作成しました。このコードをForkしてフィジカル・コンピューティングのお試しをiPhoneアプリのmyThingsとkonashi.jsを使って書いてみます。
      
      </description>
      
      
      <content:encoded><![CDATA[<p><a href="http://qiita.com/masato/items/cfef50d16173db8aca42">前回</a>は<a href="http://konashi.ux-xu.com/kjs/">konashi.js</a>のアプリを<a href="http://www.idangero.us/framework7">Framework7</a>で書いてHTML5でネイティブ風な画面を作成しました。このコードをForkしてフィジカル・コンピューティングのお試しをiPhoneアプリのmyThingsとkonashi.jsを使って書いてみます。</p><span id="more"></span><h2 id="myThingsとkonashiのフィジカル・コンピューティング"><a href="#myThingsとkonashiのフィジカル・コンピューティング" class="headerlink" title="myThingsとkonashiのフィジカル・コンピューティング"></a>myThingsとkonashiのフィジカル・コンピューティング</h2><p><a href="https://en.wikipedia.org/wiki/Physical_computing">フィジカル・コンピューティング</a>とはニューヨーク大学 Dan O’Sullivan 教授が提案した、人間の行動や生活環境によりそったコンピュータとの意思疎通の方法を模索する考え方です。コンピュータにセンサーなどの入出力デバイスをつなぎ、人間と情報をやりとりすることで生活を便利にしたり新しいユーザー体験を生み出すことができるようです。</p><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ul><li><a href="http://konashi.ux-xu.com/documents/#specs-supportDevice">Hardware Introduction</a></li><li><a href="http://engineer.typemag.jp/article/konashijs">フィジカル・コンピューティングはここまで来た！ 「スマホで操作できるガジェット」をアプリで自作できるkonashi.jsを知る</a></li></ul><p><a href="http://mythings.yahoo.co.jp/">myThings</a>も<a href="http://konashi.ux-xu.com/">konashi</a>もコネクテッドデバイスをスマホから操作できるという共通した特徴を持っています。この2つをあわせて使ってみるときっと新しいユーザー体験を発見できると思います。</p><h2 id="trigger-1とaction-1の確認"><a href="#trigger-1とaction-1の確認" class="headerlink" title="trigger-1とaction-1の確認"></a>trigger-1とaction-1の確認</h2><p>IDCFチャンネルサーバーの仮想マシンにログインして<code>list</code>コマンドを実行します。今回使用するtrigger-1とaction-1のuuidとtokenを確認します。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> ~/iot_apps/meshblu-compose/</span><br><span class="line">$ docker-compose run --rm iotutil list</span><br><span class="line">...</span><br><span class="line">┌───────────┬──────────┬──────────────────────────────────────┐</span><br><span class="line">│ keyword   │ token    │ uuid                                 │</span><br><span class="line">├───────────┼──────────┼──────────────────────────────────────┤</span><br><span class="line">│ trigger-1 │ d74ebedf │ 21c83792-b25e-4ae7-a627-714af57a1a4b │</span><br><span class="line">├───────────┼──────────┼──────────────────────────────────────┤</span><br><span class="line">...</span><br><span class="line">│ action-1  │ 8a781e76 │ 3a78814a-6879-4543-bacf-9a206cd951a6 │</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h2 id="jsdo-it"><a href="#jsdo-it" class="headerlink" title="jsdo.it"></a>jsdo.it</h2><p><a href="http://jsdo.it/">jsdo.it</a>に<a href="http://jsdo.it/ma6ato/euTg">myThingsからLチカのアクションとスイッチのトリガー</a>という「コード」を作成しました。<a href="/2015/09/15/konashi20-framework7/">前回</a>作成した<a href="http://jsdo.it/ma6ato/mDsk">myThingsからLチカ</a>をForkしています。</p><p><img src="/2015/09/22/mythings-idcfchannel-konashi/konashi-f7-mythings.png" alt="konashi-f7-mythings.png"></p><h3 id="HTML"><a href="#HTML" class="headerlink" title="HTML"></a>HTML</h3><p><a href="http://www.idangero.us/framework7/#.VgFQXSDtmko">Framework7</a>のCSSとJavaScriptを<a href="http://rawgit.com/">Rawgit</a>からロードします。CDNに公開されていないパッケージをjsdo.itから使う場合に便利です。</p><p><a href="http://meshblu.octoblu.com/">Meshblu</a>のJavaScript用ライブラリは<a href="https://cdn.octoblu.com/js/meshblu/latest/meshblu.bundle.js">こちら</a>のCDNから利用できます。NPMの<a href="https://github.com/octoblu/meshblu-npm">meshblu-npm</a>を<a href="http://browserify.org/">browserify</a>したものが公開されています。</p><figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">&quot;utf-8&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">meta</span> <span class="attr">name</span>=<span class="string">&quot;viewport&quot;</span> <span class="attr">content</span>=<span class="string">&quot;width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">meta</span> <span class="attr">name</span>=<span class="string">&quot;apple-mobile-web-app-capable&quot;</span> <span class="attr">content</span>=<span class="string">&quot;yes&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">meta</span> <span class="attr">name</span>=<span class="string">&quot;apple-mobile-web-app-status-bar-style&quot;</span> <span class="attr">content</span>=<span class="string">&quot;black&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- Framework7 css --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span> <span class="attr">href</span>=<span class="string">&quot;https://rawgit.com/nolimits4web/Framework7/master/dist/css/framework7.ios.min.css&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span> <span class="attr">href</span>=<span class="string">&quot;https://rawgit.com/nolimits4web/Framework7/master/dist/css/framework7.ios.colors.min.css&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">title</span>&gt;</span>myThings F7<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;statusbar-overlay&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;panel-overlay&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;panel panel-left panel-reveal&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;content-block&quot;</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">p</span>&gt;</span>Left panel content goes here<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;views&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;view view-main&quot;</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;navbar&quot;</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;navbar-inner&quot;</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;center sliding&quot;</span>&gt;</span>myThings F7<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;right&quot;</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;#&quot;</span> <span class="attr">class</span>=<span class="string">&quot;link icon-only open-panel&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">&quot;icon icon-bars-blue&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;pages navbar-through toolbar-through&quot;</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">div</span> <span class="attr">data-page</span>=<span class="string">&quot;index&quot;</span> <span class="attr">class</span>=<span class="string">&quot;page&quot;</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;page-content&quot;</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;content-block&quot;</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;#&quot;</span> <span class="attr">id</span>=<span class="string">&quot;btn-find&quot;</span> <span class="attr">class</span>=<span class="string">&quot;find button button-big&quot;</span>&gt;</span>Find konashi<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;pio-setting&quot;</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;content-block-title&quot;</span>&gt;</span>PIO: Output Settings<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;list-block&quot;</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">ul</span>&gt;</span></span><br><span class="line">                                        <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">&quot;item-content&quot;</span>&gt;</span></span><br><span class="line">                                            <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;item-media&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">&quot;icon icon-form-toggle&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                                            <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;item-inner&quot;</span>&gt;</span></span><br><span class="line">                                                <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;item-title label&quot;</span>&gt;</span>LED2<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                                                <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;item-input&quot;</span>&gt;</span></span><br><span class="line">                                                    <span class="tag">&lt;<span class="name">label</span> <span class="attr">class</span>=<span class="string">&quot;label-switch&quot;</span>&gt;</span></span><br><span class="line">                                                        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;toggle&quot;</span> <span class="attr">data-pin</span>=<span class="string">&quot;1&quot;</span>&gt;</span></span><br><span class="line">                                                            <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;checkbox&quot;</span>&gt;</span></span><br><span class="line">                                                            <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;checkbox&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                                                        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                                                    <span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">                                                <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                                            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                                        <span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">                                        <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">&quot;item-content&quot;</span>&gt;</span></span><br><span class="line">                                            <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;item-media&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">&quot;icon icon-form-toggle&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                                            <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;item-inner&quot;</span>&gt;</span></span><br><span class="line">                                                <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;item-title label&quot;</span>&gt;</span>LED3<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                                                <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;item-input&quot;</span>&gt;</span></span><br><span class="line">                                                    <span class="tag">&lt;<span class="name">label</span> <span class="attr">class</span>=<span class="string">&quot;label-switch&quot;</span>&gt;</span></span><br><span class="line">                                                        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;toggle&quot;</span> <span class="attr">data-pin</span>=<span class="string">&quot;2&quot;</span>&gt;</span></span><br><span class="line">                                                            <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;checkbox&quot;</span>&gt;</span></span><br><span class="line">                                                            <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;checkbox&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                                                        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                                                    <span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">                                                <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                                            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                                        <span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;content-block-title&quot;</span>&gt;</span>PIO: Input Settings<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;list-block&quot;</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">ul</span>&gt;</span></span><br><span class="line">                                        <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">&quot;item-content&quot;</span>&gt;</span></span><br><span class="line">                                            <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;item-media&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">&quot;icon icon-form-settings&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                                            <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;item-inner&quot;</span>&gt;</span></span><br><span class="line">                                                <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;item-title label&quot;</span>&gt;</span>S1<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                                                <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;item-after&quot;</span> <span class="attr">id</span>=<span class="string">&quot;s1-status&quot;</span>&gt;</span>OFF<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                                            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                                        <span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- for Framework7 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;https://rawgit.com/nolimits4web/Framework7/master/dist/js/framework7.min.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- meshblu --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;text/javascript&quot;</span> <span class="attr">src</span>=<span class="string">&quot;https://cdn.octoblu.com/js/meshblu/latest/meshblu.bundle.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- for konashijs --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;http://konashi.ux-xu.com/kjs/konashi-bridge.min.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="JavaScript"><a href="#JavaScript" class="headerlink" title="JavaScript"></a>JavaScript</h3><p>最初にkonashi.jsからロードするJavaScriptの全文です。Meshbluのデバイスのuuidやtokenは環境に応じて変更します。</p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">(<span class="function"><span class="keyword">function</span>(<span class="params">Framework7, $$</span>)</span>&#123;</span><br><span class="line">    $$(<span class="string">&#x27;.toggle&#x27;</span>).on(<span class="string">&quot;click&quot;</span>, <span class="function"><span class="keyword">function</span>(<span class="params">e</span>)</span>&#123;</span><br><span class="line">        <span class="keyword">var</span> pin = $$(e.currentTarget).data(<span class="string">&quot;pin&quot;</span>);</span><br><span class="line">        <span class="keyword">var</span> value = $$(<span class="built_in">this</span>).find(<span class="string">&#x27;input&#x27;</span>).prop(<span class="string">&#x27;checked&#x27;</span>) ? k.HIGH : k.LOW;</span><br><span class="line">        k.digitalWrite(pin, value);</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    $$(<span class="string">&quot;#btn-find&quot;</span>).on(<span class="string">&quot;click&quot;</span>, <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">        <span class="keyword">if</span>($$(<span class="string">&quot;#btn-find&quot;</span>).hasClass(<span class="string">&quot;find&quot;</span>))&#123;</span><br><span class="line">            k.find();</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            k.disconnect();</span><br><span class="line"></span><br><span class="line">            <span class="comment">// change find button</span></span><br><span class="line">            $$(<span class="string">&quot;#btn-find&quot;</span>)</span><br><span class="line">              .addClass(<span class="string">&quot;find&quot;</span>)</span><br><span class="line">              .html(<span class="string">&quot;Find konashi&quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// hide pio list</span></span><br><span class="line">            $$(<span class="string">&quot;#pio-setting&quot;</span>).hide();</span><br><span class="line">            $$(<span class="string">&quot;#s1-status&quot;</span>).html(<span class="string">&quot;OFF&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> server = <span class="string">&#x27;210.140.162.58&#x27;</span>,</span><br><span class="line">        port = <span class="number">80</span>,</span><br><span class="line">        protocol = <span class="string">&#x27;websocket&#x27;</span>,</span><br><span class="line">        trigger_uuid = <span class="string">&#x27;21c83792-b25e-4ae7-a627-714af57a1a4b&#x27;</span>,</span><br><span class="line">        trigger_token = <span class="string">&#x27;d74ebedf&#x27;</span>,</span><br><span class="line">        action_uuid = <span class="string">&#x27;3a78814a-6879-4543-bacf-9a206cd951a6&#x27;</span>,</span><br><span class="line">        action_token = <span class="string">&#x27;8a781e76&#x27;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> conn;</span><br><span class="line"></span><br><span class="line">    k.on(<span class="string">&quot;ready&quot;</span>, <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// change find button</span></span><br><span class="line">        $$(<span class="string">&quot;#btn-find&quot;</span>)</span><br><span class="line">          .removeClass(<span class="string">&quot;find&quot;</span>)</span><br><span class="line">          .html(<span class="string">&quot;Disconnect konashi&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// show pio list</span></span><br><span class="line">        $$(<span class="string">&quot;#pio-setting&quot;</span>).show();</span><br><span class="line"></span><br><span class="line">        k.pinModeAll(<span class="number">254</span>);</span><br><span class="line"></span><br><span class="line">        conn = meshblu.createConnection(&#123;</span><br><span class="line">            <span class="string">&#x27;uuid&#x27;</span>: trigger_uuid,</span><br><span class="line">            <span class="string">&#x27;token&#x27;</span>: trigger_token,</span><br><span class="line">            <span class="string">&#x27;server&#x27;</span>: server,</span><br><span class="line">            <span class="string">&#x27;port&#x27;</span>: port</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        conn.on(<span class="string">&#x27;notReady&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params">data</span>)</span>&#123;</span><br><span class="line">            k.log(<span class="string">&#x27;UUID FAILED AUTHENTICATION!&#x27;</span>);</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        conn.on(<span class="string">&#x27;ready&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params">data</span>)</span>&#123;</span><br><span class="line">            k.log(<span class="string">&#x27;READY!!&#x27;</span>);</span><br><span class="line"></span><br><span class="line">            conn.subscribe(&#123;</span><br><span class="line">                <span class="string">&#x27;uuid&#x27;</span>: action_uuid,</span><br><span class="line">                <span class="string">&#x27;token&#x27;</span>: action_token</span><br><span class="line">            &#125;, <span class="function"><span class="keyword">function</span> (<span class="params">data</span>) </span>&#123;</span><br><span class="line">                k.log(data);</span><br><span class="line">            &#125;);</span><br><span class="line"></span><br><span class="line">            conn.on(<span class="string">&#x27;message&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params">message</span>)</span>&#123;</span><br><span class="line">                k.log(message.payload.message);</span><br><span class="line">                <span class="keyword">var</span> value = message.payload === <span class="string">&#x27;led-on&#x27;</span> ? k.HIGH : k.LOW;</span><br><span class="line"></span><br><span class="line">                k.digitalWrite(k.LED3, value);</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    k.updatePioInput( <span class="function"><span class="keyword">function</span>(<span class="params">data</span>)</span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(data % <span class="number">2</span>)&#123;</span><br><span class="line">            $$(<span class="string">&quot;#s1-status&quot;</span>).html(<span class="string">&quot;ON&quot;</span>);</span><br><span class="line">            conn.data(&#123;</span><br><span class="line">                <span class="string">&#x27;uuid&#x27;</span>: trigger_uuid,</span><br><span class="line">                <span class="string">&#x27;trigger&#x27;</span>: <span class="string">&#x27;on&#x27;</span></span><br><span class="line">            &#125;);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            $$(<span class="string">&quot;#s1-status&quot;</span>).html(<span class="string">&quot;OFF&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//k.showDebugLog();</span></span><br><span class="line">&#125;)(Framework7, Dom7);</span><br></pre></td></tr></table></figure><p><code>k.on(&quot;ready&quot;)</code>のコールバックでkonashiとiPhoneが接続できた後に、IDCFチャンネルサーバーのMeshbluにtrigger-1のuuidを使ってWebSocketで接続します。</p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">conn = meshblu.createConnection(&#123;</span><br><span class="line">    <span class="string">&#x27;uuid&#x27;</span>: trigger_uuid,</span><br><span class="line">    <span class="string">&#x27;token&#x27;</span>: trigger_token,</span><br><span class="line">    <span class="string">&#x27;server&#x27;</span>: server,</span><br><span class="line">    <span class="string">&#x27;port&#x27;</span>: port</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>Meshbluに接続すると次にaction-1のuuidでWebSocketのsubscribeをします。ここではmyThingsのトリガーから「led-on」のメッセージを受信した場合にLED3を点灯し、それ以外で消灯します。</p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">conn.on(<span class="string">&#x27;ready&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params">data</span>)</span>&#123;</span><br><span class="line">    k.log(<span class="string">&#x27;READY!!&#x27;</span>);</span><br><span class="line"></span><br><span class="line">    conn.subscribe(&#123;</span><br><span class="line">        <span class="string">&#x27;uuid&#x27;</span>: action_uuid,</span><br><span class="line">        <span class="string">&#x27;token&#x27;</span>: action_token</span><br><span class="line">    &#125;, <span class="function"><span class="keyword">function</span> (<span class="params">data</span>) </span>&#123;</span><br><span class="line">        k.log(data);</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    conn.on(<span class="string">&#x27;message&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params">message</span>)</span>&#123;</span><br><span class="line">        k.log(message.payload.message);</span><br><span class="line">        <span class="keyword">var</span> value = message.payload === <span class="string">&#x27;led-on&#x27;</span> ? k.HIGH : k.LOW;</span><br><span class="line"></span><br><span class="line">        k.digitalWrite(k.LED3, value);</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>konashiのタクトスイッチを押すと、WebSocketクライアントから<code>data</code>のAPIに任意のデータを送信します。myThingsの組合せに設定した「IDCF」チャンネルの<code>trigger-1</code>のトリガーが発火され、同様に組合せに設定されたアクションが実行されます。</p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">k.updatePioInput( <span class="function"><span class="keyword">function</span>(<span class="params">data</span>)</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(data % <span class="number">2</span>)&#123;</span><br><span class="line">        $$(<span class="string">&quot;#s1-status&quot;</span>).html(<span class="string">&quot;ON&quot;</span>);</span><br><span class="line">        conn.data(&#123;</span><br><span class="line">            <span class="string">&#x27;uuid&#x27;</span>: trigger_uuid,</span><br><span class="line">            <span class="string">&#x27;trigger&#x27;</span>: <span class="string">&#x27;on&#x27;</span></span><br><span class="line">        &#125;);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        $$(<span class="string">&quot;#s1-status&quot;</span>).html(<span class="string">&quot;OFF&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h3 id="CSS"><a href="#CSS" class="headerlink" title="CSS"></a>CSS</h3><p>スタイルシートはkonaashiがiPhoneと接続、切断に応じて画面のコントロール表示を切り替えます。</p><figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-id">#pio-setting</span> &#123;</span><br><span class="line">    <span class="attribute">display</span>: none;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="konashiをmyThingsのトリガーに使う"><a href="#konashiをmyThingsのトリガーに使う" class="headerlink" title="konashiをmyThingsのトリガーに使う"></a>konashiをmyThingsのトリガーに使う</h2><p>konashiのタクトスイッチを押す(ON)と、myThingsの組合せでトリガーに選択した「IDCF」チャンネルのtrigger-1が発火され、アクションに設定した「Twitter」チャンネルを実行するサンプルです。</p><h3 id="組合せの作成"><a href="#組合せの作成" class="headerlink" title="組合せの作成"></a>組合せの作成</h3><p>myThingsアプリでトリガーにIDCF、アクションにTwitterを選択して組み合わせを作成します。</p><p><img src="/2015/09/22/mythings-idcfchannel-konashi/konashi-idcf-recipe1.png" alt="konashi-idcf-recipe1.png"></p><h3 id="IDCFのトリガー"><a href="#IDCFのトリガー" class="headerlink" title="IDCFのトリガー"></a>IDCFのトリガー</h3><p>「IDCF」チャンネルのトリガーはtrigger-1を選択します。</p><p><img src="/2015/09/22/mythings-idcfchannel-konashi/konashi-idcf-trigger.png" alt="konashi-idcf-trigger.png"></p><p>trigger-1はkonashi.jsのJavaScriptからMeshbluへの接続に使っています。</p><figure class="highlight js"><table><tr><td class="code"><pre><span class="line">conn = meshblu.createConnection(&#123;</span><br><span class="line">    <span class="string">&#x27;uuid&#x27;</span>: trigger_uuid,</span><br><span class="line">    <span class="string">&#x27;token&#x27;</span>: trigger_token,</span><br><span class="line">    <span class="string">&#x27;server&#x27;</span>: server,</span><br><span class="line">    <span class="string">&#x27;port&#x27;</span>: port</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h3 id="Twitterのアクション"><a href="#Twitterのアクション" class="headerlink" title="Twitterのアクション"></a>Twitterのアクション</h3><p>ツイート内容は任意のメッセージを登録します。</p><p><img src="/2015/09/22/mythings-idcfchannel-konashi/konashi-twitter-action.png" alt="konashi-twitter-action.png"></p><h3 id="手動実行"><a href="#手動実行" class="headerlink" title="手動実行"></a>手動実行</h3><p>konashi.jsはバックグラウンドで実行できないので、myThingsアプリの「手動実行」ボタンと同時に使うことはできません。15分待つか別のスマホからmyThingsアプリを起動して使います。</p><p>konashiのタクトスイッチを押したあと、組み合わせの「手動実行」ボタンを押すとアクションに設定してあるメッセージがツイートされます。</p><p><img src="/2015/09/22/mythings-idcfchannel-konashi/konashi-tweet.png" alt="konashi-tweet.png"></p><h2 id="konashiをmyThingsのアクションに使う"><a href="#konashiをmyThingsのアクションに使う" class="headerlink" title="konashiをmyThingsのアクションに使う"></a>konashiをmyThingsのアクションに使う</h2><p>myThingsの組合せでトリガーの「Gmail」で設定するように、Gmailが特定の誰かからメールを受信すると、アクションに選択した「IDCF」チャンネルのaction-1が実行されます。メールの件名の応じてkonashiのLED3が点灯と消灯をするサンプルです。</p><h3 id="組合せの作成-1"><a href="#組合せの作成-1" class="headerlink" title="組合せの作成"></a>組合せの作成</h3><p>myThingsアプリでトリガーにGmail、アクションにIDCFを選択して組み合わせを作成します。</p><p><img src="/2015/09/22/mythings-idcfchannel-konashi/konashi-idcf-recipe2.png" alt="konashi-idcf-recipe2.png"></p><h3 id="Gmailのトリガー"><a href="#Gmailのトリガー" class="headerlink" title="Gmailのトリガー"></a>Gmailのトリガー</h3><p>Gmailのトリガー条件は「特定の誰かからメールを受信したら」を選択します。トリガーとして使うメールアドレスを登録します。</p><p><img src="/2015/09/22/mythings-idcfchannel-konashi/konashi-idcf-gmail.png" alt="konashi-idcf-gmail.png"></p><h3 id="IDCFのアクション"><a href="#IDCFのアクション" class="headerlink" title="IDCFのアクション"></a>IDCFのアクション</h3><p>IDCFのアクションはaction-1を選択します。メッセージは「候補選択」からGmailのを設定します。</p><p><img src="/2015/09/22/mythings-idcfchannel-konashi/konashi-idcf-action.png" alt="konashi-idcf-action.png"></p><h3 id="手動実行-1"><a href="#手動実行-1" class="headerlink" title="手動実行"></a>手動実行</h3><p>トリガー条件に設定したメールアドレスからmyThingsと連携したGmailのメールアドレスにメールを送信します。件名を「led-on」とするとLED3が点灯します。それ以外の場合はLED3が消灯します。</p><p><img src="/2015/09/22/mythings-idcfchannel-konashi/konashi-led-on.png" alt="konashi-led-on.png"></p><p>Gmailでメールの受信を確認したら、作成した組合せの「手動実行」ボタンを押すとLED3が点灯または消灯します。</p>]]></content:encoded>
      
      <comments>https://masato.github.io/2015/09/22/mythings-idcfchannel-konashi/#disqus_thread</comments>
    </item>
    
    <item>
      <title>DockerでIDCFクラウドのCLIを実行する</title>
      <link>https://masato.github.io/2015/09/19/docker-container-cli-pattern-idcf-cloud/</link>
      <guid>https://masato.github.io/2015/09/19/docker-container-cli-pattern-idcf-cloud/</guid>
      <pubDate>Sat, 19 Sep 2015 05:03:15 GMT</pubDate>
      <description>
      
        &lt;p&gt;&lt;a href=&quot;/2015/04/22/docker-container-cli-pattern/&quot;&gt;Dockerコンテナ上でCLIを実行するデザインパターン&lt;/a&gt;を以前調べましたが、今回は&lt;a href=&quot;http://www.idcf.jp/cloud/spec/api.html&quot;&gt;IDCFクラウドのCLI&lt;/a&gt;のイメージを作ってみます。&lt;a href=&quot;https://virtualenv.pypa.io/en/latest/&quot;&gt;virtuanemv&lt;/a&gt;で仮想環境を用意しても良いのですが、Dockerイメージでコマンドを配布するとホストマシンの環境を汚さずにお試しで実行できます。CLIの配布形式としてもDockerイメージは便利に使えます。&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p><a href="/2015/04/22/docker-container-cli-pattern/">Dockerコンテナ上でCLIを実行するデザインパターン</a>を以前調べましたが、今回は<a href="http://www.idcf.jp/cloud/spec/api.html">IDCFクラウドのCLI</a>のイメージを作ってみます。<a href="https://virtualenv.pypa.io/en/latest/">virtuanemv</a>で仮想環境を用意しても良いのですが、Dockerイメージでコマンドを配布するとホストマシンの環境を汚さずにお試しで実行できます。CLIの配布形式としてもDockerイメージは便利に使えます。</p><span id="more"></span><h2 id="プロジェクト"><a href="#プロジェクト" class="headerlink" title="プロジェクト"></a>プロジェクト</h2><p>今回作成したリポジトリは<a href="https://github.com/masato/docker-idcfcli">こちら</a>です。</p><h3 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a>Dockerfile</h3><p>ベースイメージはオフィシャルの<a href="https://hub.docker.com/_/python/">Python</a>の2.7 ONBUILDを使います。ONBUILDでビルドに必要な処理をするためDockerfileはとても簡単です。</p><figure class="highlight bash"><figcaption><span>Dockerfile</span></figcaption><table><tr><td class="code"><pre><span class="line">FROM python:2-onbuild</span><br></pre></td></tr></table></figure><h3 id="requirements-txt"><a href="#requirements-txt" class="headerlink" title="requirements.txt"></a>requirements.txt</h3><p>IDCFの<a href="https://github.com/idcf/cloudstack-api">リポジトリ</a>にはrequirements.txtが同梱されていません。依存するパッケージの追加と、cloudstack-apiもGitHub経由でインストールするように定義します。</p><figure class="highlight txt"><figcaption><span>requirements.txt</span></figcaption><table><tr><td class="code"><pre><span class="line">httplib2</span><br><span class="line">simplejson</span><br><span class="line">argparse</span><br><span class="line">prettytable==0.5</span><br><span class="line">parsedatetime==0.8.7</span><br><span class="line">lxml</span><br><span class="line">-e git+https://github.com/idcf/cloudstack-api#egg=cloudstack-api</span><br></pre></td></tr></table></figure><p>ONBUILDのベースイメージがrequirements.txtファイルのCOPYと<code>pip install</code>をしてくれます。</p><figure class="highlight bash"><figcaption><span>Dockerfile</span></figcaption><table><tr><td class="code"><pre><span class="line">FROM python:2.7</span><br><span class="line"></span><br><span class="line">RUN mkdir -p /usr/src/app</span><br><span class="line">WORKDIR /usr/src/app</span><br><span class="line"></span><br><span class="line">ONBUILD COPY requirements.txt /usr/src/app/</span><br><span class="line">ONBUILD RUN pip install --no-cache-dir -r requirements.txt</span><br><span class="line"></span><br><span class="line">ONBUILD COPY . /usr/src/app</span><br></pre></td></tr></table></figure><h3 id="docker-compose-yml"><a href="#docker-compose-yml" class="headerlink" title="docker-compose.yml"></a>docker-compose.yml</h3><p>IDCFクラウドコンソールの<a href="https://console.idcfcloud.com/user/apikey">API Key</a>から環境変数を設定します。</p><ul><li>IDCF_COMPUTE_HOST: エンドポイント</li><li>IDCF_COMPUTE_API_KEY: API Key</li><li>IDCF_COMPUTE_SECRET_KEY: Secret Key</li></ul><figure class="highlight yaml"><figcaption><span>docker-compose.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">idcfcli:</span></span><br><span class="line">  <span class="attr">build:</span> <span class="string">.</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">/etc/localtime:/etc/localtime:ro</span></span><br><span class="line">  <span class="attr">environment:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">IDCF_COMPUTE_HOST=</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">IDCF_COMPUTE_API_KEY=</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">IDCF_COMPUTE_SECRET_KEY=</span></span><br><span class="line">  <span class="attr">command:</span> [<span class="string">&quot;/usr/local/bin/cloudstack-api&quot;</span>,<span class="string">&quot;listVirtualMachines&quot;</span>,<span class="string">&quot;-t=id,name,state&quot;</span>]</span><br></pre></td></tr></table></figure><h2 id="使い方"><a href="#使い方" class="headerlink" title="使い方"></a>使い方</h2><p>リポジトリから<code>git clone</code>します。docker-compose.yml.defaultをdocker-compose.ymlにリネームして環境変数を設定します。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ git <span class="built_in">clone</span> https://github.com/masato/docker-idcfcli.git idcfcli</span><br><span class="line">$ <span class="built_in">cd</span> idcfcli</span><br><span class="line">$ mv docker-compose.yml.default docker-compose.yml</span><br><span class="line">$ vi docker-compose.yml</span><br></pre></td></tr></table></figure><p>Docker Composeからコンテナを起動します。デフォルトのコマンドは<a href="http://docs.idcf.jp/cloud/api/virtual-machine/#listvirtualmachines">listVirtualMachines</a>を実行しています。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker-compose build</span><br><span class="line">$ docker-compose run --rm idcfcli</span><br><span class="line">+--------------------------------------+------+---------+</span><br><span class="line">|                  id                  | name |  state  |</span><br><span class="line">+--------------------------------------+------+---------+</span><br><span class="line">| xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx | seed | Running |</span><br><span class="line">+--------------------------------------+------+---------+</span><br></pre></td></tr></table></figure><p>任意のコマンドは以下のように実行します。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker-compose run --rm idcfcli cloudstack-api listVirtualMachines -t=id,name,state</span><br><span class="line">+--------------------------------------+------+---------+</span><br><span class="line">|                  id                  | name |  state  |</span><br><span class="line">+--------------------------------------+------+---------+</span><br><span class="line">| xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx | seed | Running |</span><br><span class="line">+--------------------------------------+------+---------+</span><br></pre></td></tr></table></figure><h3 id="エイリアスの作成"><a href="#エイリアスの作成" class="headerlink" title="エイリアスの作成"></a>エイリアスの作成</h3><p><code> ~/.bashrc</code>などにエイリアスを定義しておきます。</p><figure class="highlight bash"><figcaption><span>~/.bashrc</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="built_in">alias</span> idcf-cli=<span class="string">&#x27;docker-compose run --rm idcfcli cloudstack-api&#x27;</span></span><br></pre></td></tr></table></figure><p>エイリアスを使うとよりCLIらしくなります。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ idcf-cli listVirtualMachines -t=id,name,state</span><br><span class="line">+--------------------------------------+------+---------+</span><br><span class="line">|                  id                  | name |  state  |</span><br><span class="line">+--------------------------------------+------+---------+</span><br><span class="line">| xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx | seed | Running |</span><br><span class="line">+--------------------------------------+------+---------+</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      <comments>https://masato.github.io/2015/09/19/docker-container-cli-pattern-idcf-cloud/#disqus_thread</comments>
    </item>
    
  </channel>
</rss>
